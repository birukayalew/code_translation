{
  "cat": [
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (ToDO) nonprint nonblank nonprinting ELOOP\nuse std::fs::{File, metadata};\nuse std::io::{self, BufWriter, IsTerminal, Read, Write};\n/// Unix domain socket support\n#[cfg(unix)]\nuse std::net::Shutdown;\n#[cfg(unix)]\nuse std::os::fd::AsFd;\n#[cfg(unix)]\nuse std::os::unix::fs::FileTypeExt;\n#[cfg(unix)]\nuse std::os::unix::net::UnixStream;\nuse clap::{Arg, ArgAction, Command};\nuse memchr::memchr2;\n#[cfg(unix)]\nuse nix::fcntl::{FcntlArg, fcntl};\nuse thiserror::Error;\nuse uucore::display::Quotable;\nuse uucore::error::UResult;\nuse uucore::fs::FileInformation;\nuse uucore::{fast_inc::fast_inc_one, format_usage, help_about, help_usage};\n/// Linux splice support\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\nmod splice;\nconst USAGE: &str = help_usage!(\"cat.md\");\nconst ABOUT: &str = help_about!(\"cat.md\");\n// Allocate 32 digits for the line number.\n// An estimate is that we can print about 1e8 lines/seconds, so 32 digits\n// would be enough for billions of universe lifetimes.\nconst LINE_NUMBER_BUF_SIZE: usize = 32;\nstruct LineNumber {\n    buf: [u8; LINE_NUMBER_BUF_SIZE],\n    print_start: usize,\n    num_start: usize,\n    num_end: usize,\n}\n// Logic to store a string for the line number. Manually incrementing the value\n// represented in a buffer like this is significantly faster than storing\n// a `usize` and using the standard Rust formatting macros to format a `usize`\n// to a string each time it's needed.\n// Buffer is initialized to \"     1\\t\" and incremented each time `increment` is\n// called, using uucore's fast_inc function that operates on strings.\nimpl LineNumber {\n    fn new() -> Self {\n        let mut buf = [b'0'; LINE_NUMBER_BUF_SIZE];\n\n        let init_str = \"     1\\t\";\n        let print_start = buf.len() - init_str.len();\n        let num_start = buf.len() - 2;\n        let num_end = buf.len() - 1;\n\n        buf[print_start..].copy_from_slice(init_str.as_bytes());\n\n        LineNumber {\n            buf,\n            print_start,\n            num_start,\n            num_end,\n        }\n    }\n\n    fn increment(&mut self) {\n        fast_inc_one(&mut self.buf, &mut self.num_start, self.num_end);\n        self.print_start = self.print_start.min(self.num_start);\n    }\n\n    #[inline]\n    fn to_str(&self) -> &[u8] {\n        &self.buf[self.print_start..]\n    }\n\n    fn write(&self, writer: &mut impl Write) -> io::Result<()> {\n        writer.write_all(self.to_str())\n    }\n}\n#[derive(Error, Debug)]\nenum CatError {\n    /// Wrapper around `io::Error`\n    #[error(\"{0}\")]\n    Io(#[from] io::Error),\n    /// Wrapper around `nix::Error`\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    #[error(\"{0}\")]\n    Nix(#[from] nix::Error),\n    /// Unknown file type; it's not a regular file, socket, etc.\n    #[error(\"unknown filetype: {ft_debug}\")]\n    UnknownFiletype {\n        /// A debug print of the file type\n        ft_debug: String,\n    },\n    #[error(\"Is a directory\")]\n    IsDirectory,\n    #[error(\"input file is output file\")]\n    OutputIsInput,\n    #[error(\"Too many levels of symbolic links\")]\n    TooManySymlinks,\n}\ntype CatResult<T> = Result<T, CatError>;\n#[derive(PartialEq)]\nenum NumberingMode {\n    None,\n    NonEmpty,\n    All,\n}\nstruct OutputOptions {\n    /// Line numbering mode\n    number: NumberingMode,\n\n    /// Suppress repeated empty output lines\n    squeeze_blank: bool,\n\n    /// display TAB characters as `tab`\n    show_tabs: bool,\n\n    /// Show end of lines\n    show_ends: bool,\n\n    /// use ^ and M- notation, except for LF (\\\\n) and TAB (\\\\t)\n    show_nonprint: bool,\n}\nimpl OutputOptions {\n    fn tab(&self) -> &'static str {\n        if self.show_tabs { \"^I\" } else { \"\\t\" }\n    }\n\n    fn end_of_line(&self) -> &'static str {\n        if self.show_ends { \"$\\n\" } else { \"\\n\" }\n    }\n\n    /// We can write fast if we can simply copy the contents of the file to\n    /// stdout, without augmenting the output with e.g. line numbers.\n    fn can_write_fast(&self) -> bool {\n        !(self.show_tabs\n            || self.show_nonprint\n            || self.show_ends\n            || self.squeeze_blank\n            || self.number != NumberingMode::None)\n    }\n}\n/// State that persists between output of each file. This struct is only used\n/// when we can't write fast.\nstruct OutputState {\n    /// The current line number\n    line_number: LineNumber,\n\n    /// Whether the output cursor is at the beginning of a new line\n    at_line_start: bool,\n\n    /// Whether we skipped a \\r, which still needs to be printed\n    skipped_carriage_return: bool,\n\n    /// Whether we have already printed a blank line\n    one_blank_kept: bool,\n}\n#[cfg(unix)]\ntrait FdReadable: Read + AsFd {}\n#[cfg(not(unix))]\ntrait FdReadable: Read {}\n#[cfg(unix)]\nimpl<T> FdReadable for T where T: Read + AsFd {}\n#[cfg(not(unix))]\nimpl<T> FdReadable for T where T: Read {}\n/// Represents an open file handle, stream, or other device\nstruct InputHandle<R: FdReadable> {\n    reader: R,\n    is_interactive: bool,\n}\n/// Concrete enum of recognized file types.\n///\n/// *Note*: `cat`-ing a directory should result in an\n/// CatError::IsDirectory\nenum InputType {\n    Directory,\n    File,\n    StdIn,\n    SymLink,\n    #[cfg(unix)]\n    BlockDevice,\n    #[cfg(unix)]\n    CharacterDevice,\n    #[cfg(unix)]\n    Fifo,\n    #[cfg(unix)]\n    Socket,\n}\nmod options {\n    pub static FILE: &str = \"file\";\n    pub static SHOW_ALL: &str = \"show-all\";\n    pub static NUMBER_NONBLANK: &str = \"number-nonblank\";\n    pub static SHOW_NONPRINTING_ENDS: &str = \"e\";\n    pub static SHOW_ENDS: &str = \"show-ends\";\n    pub static NUMBER: &str = \"number\";\n    pub static SQUEEZE_BLANK: &str = \"squeeze-blank\";\n    pub static SHOW_NONPRINTING_TABS: &str = \"t\";\n    pub static SHOW_TABS: &str = \"show-tabs\";\n    pub static SHOW_NONPRINTING: &str = \"show-nonprinting\";\n    pub static IGNORED_U: &str = \"ignored-u\";\n}\n#[uucore::main]\npub fn uumain(args: impl uucore::Args) -> UResult<()> {\n    let matches = uu_app().try_get_matches_from(args)?;\n\n    let number_mode = if matches.get_flag(options::NUMBER_NONBLANK) {\n        NumberingMode::NonEmpty\n    } else if matches.get_flag(options::NUMBER) {\n        NumberingMode::All\n    } else {\n        NumberingMode::None\n    };\n\n    let show_nonprint = [\n        options::SHOW_ALL.to_owned(),\n        options::SHOW_NONPRINTING_ENDS.to_owned(),\n        options::SHOW_NONPRINTING_TABS.to_owned(),\n        options::SHOW_NONPRINTING.to_owned(),\n    ]\n    .iter()\n    .any(|v| matches.get_flag(v));\n\n    let show_ends = [\n        options::SHOW_ENDS.to_owned(),\n        options::SHOW_ALL.to_owned(),\n        options::SHOW_NONPRINTING_ENDS.to_owned(),\n    ]\n    .iter()\n    .any(|v| matches.get_flag(v));\n\n    let show_tabs = [\n        options::SHOW_ALL.to_owned(),\n        options::SHOW_TABS.to_owned(),\n        options::SHOW_NONPRINTING_TABS.to_owned(),\n    ]\n    .iter()\n    .any(|v| matches.get_flag(v));\n\n    let squeeze_blank = matches.get_flag(options::SQUEEZE_BLANK);\n    let files: Vec<String> = match matches.get_many::<String>(options::FILE) {\n        Some(v) => v.cloned().collect(),\n        None => vec![\"-\".to_owned()],\n    };\n\n    let options = OutputOptions {\n        show_ends,\n        number: number_mode,\n        show_nonprint,\n        show_tabs,\n        squeeze_blank,\n    };\n    cat_files(&files, &options)\n}",
      "file_name": "coreutils/src/uu\\cat\\src\\cat.rs"
    },
    {
      "chunk": "pub fn uu_app() -> Command {\n    Command::new(uucore::util_name())\n        .version(uucore::crate_version!())\n        .override_usage(format_usage(USAGE))\n        .about(ABOUT)\n        .infer_long_args(true)\n        .args_override_self(true)\n        .arg(\n            Arg::new(options::FILE)\n                .hide(true)\n                .action(ArgAction::Append)\n                .value_hint(clap::ValueHint::FilePath),\n        )\n        .arg(\n            Arg::new(options::SHOW_ALL)\n                .short('A')\n                .long(options::SHOW_ALL)\n                .help(\"equivalent to -vET\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::NUMBER_NONBLANK)\n                .short('b')\n                .long(options::NUMBER_NONBLANK)\n                .help(\"number nonempty output lines, overrides -n\")\n                // Note: This MUST NOT .overrides_with(options::NUMBER)!\n                // In clap, overriding is symmetric, so \"-b -n\" counts as \"-n\", which is not what we want.\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SHOW_NONPRINTING_ENDS)\n                .short('e')\n                .help(\"equivalent to -vE\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SHOW_ENDS)\n                .short('E')\n                .long(options::SHOW_ENDS)\n                .help(\"display $ at end of each line\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::NUMBER)\n                .short('n')\n                .long(options::NUMBER)\n                .help(\"number all output lines\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SQUEEZE_BLANK)\n                .short('s')\n                .long(options::SQUEEZE_BLANK)\n                .help(\"suppress repeated empty output lines\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SHOW_NONPRINTING_TABS)\n                .short('t')\n                .help(\"equivalent to -vT\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SHOW_TABS)\n                .short('T')\n                .long(options::SHOW_TABS)\n                .help(\"display TAB characters at ^I\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SHOW_NONPRINTING)\n                .short('v')\n                .long(options::SHOW_NONPRINTING)\n                .help(\"use ^ and M- notation, except for LF (\\\\n) and TAB (\\\\t)\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::IGNORED_U)\n                .short('u')\n                .help(\"(ignored)\")\n                .action(ArgAction::SetTrue),\n        )\n}\nfn cat_handle<R: FdReadable>(\n    handle: &mut InputHandle<R>,\n    options: &OutputOptions,\n    state: &mut OutputState,\n) -> CatResult<()> {\n    if options.can_write_fast() {\n        write_fast(handle)\n    } else {\n        write_lines(handle, options, state)\n    }\n}\n/// Whether this process is appending to stdout.\n#[cfg(unix)]\nfn is_appending() -> bool {\n    let stdout = io::stdout();\n    let Ok(flags) = fcntl(stdout.as_fd(), FcntlArg::F_GETFL) else {\n        return false;\n    };\n    // TODO Replace `1 << 10` with `nix::fcntl::Oflag::O_APPEND`.\n    let o_append = 1 << 10;\n    (flags & o_append) > 0\n}\n#[cfg(not(unix))]\nfn is_appending() -> bool {\n    false\n}\nfn cat_path(\n    path: &str,\n    options: &OutputOptions,\n    state: &mut OutputState,\n    out_info: Option<&FileInformation>,\n) -> CatResult<()> {\n    match get_input_type(path)? {\n        InputType::StdIn => {\n            let stdin = io::stdin();\n            let in_info = FileInformation::from_file(&stdin)?;\n            let mut handle = InputHandle {\n                reader: stdin,\n                is_interactive: io::stdin().is_terminal(),\n            };\n            if let Some(out_info) = out_info {\n                if in_info == *out_info && is_appending() {\n                    return Err(CatError::OutputIsInput);\n                }\n            }\n            cat_handle(&mut handle, options, state)\n        }\n        InputType::Directory => Err(CatError::IsDirectory),\n        #[cfg(unix)]\n        InputType::Socket => {\n            let socket = UnixStream::connect(path)?;\n            socket.shutdown(Shutdown::Write)?;\n            let mut handle = InputHandle {\n                reader: socket,\n                is_interactive: false,\n            };\n            cat_handle(&mut handle, options, state)\n        }\n        _ => {\n            let file = File::open(path)?;\n\n            if let Some(out_info) = out_info {\n                if out_info.file_size() != 0\n                    && FileInformation::from_file(&file).ok().as_ref() == Some(out_info)\n                {\n                    return Err(CatError::OutputIsInput);\n                }\n            }\n\n            let mut handle = InputHandle {\n                reader: file,\n                is_interactive: false,\n            };\n            cat_handle(&mut handle, options, state)\n        }\n    }\n}\nfn cat_files(files: &[String], options: &OutputOptions) -> UResult<()> {\n    let out_info = FileInformation::from_file(&io::stdout()).ok();\n\n    let mut state = OutputState {\n        line_number: LineNumber::new(),\n        at_line_start: true,\n        skipped_carriage_return: false,\n        one_blank_kept: false,\n    };\n    let mut error_messages: Vec<String> = Vec::new();\n\n    for path in files {\n        if let Err(err) = cat_path(path, options, &mut state, out_info.as_ref()) {\n            error_messages.push(format!(\"{}: {err}\", path.maybe_quote()));\n        }\n    }\n    if state.skipped_carriage_return {\n        print!(\"\\r\");\n    }\n    if error_messages.is_empty() {\n        Ok(())\n    } else {\n        // each next line is expected to display \"cat: \u2026\"\n        let line_joiner = format!(\"\\n{}: \", uucore::util_name());\n\n        Err(uucore::error::USimpleError::new(\n            error_messages.len() as i32,\n            error_messages.join(&line_joiner),\n        ))\n    }\n}\n/// Classifies the `InputType` of file at `path` if possible\n///\n/// # Arguments\n///\n/// * `path` - Path on a file system to classify metadata\nfn get_input_type(path: &str) -> CatResult<InputType> {\n    if path == \"-\" {\n        return Ok(InputType::StdIn);\n    }\n\n    let ft = match metadata(path) {\n        Ok(md) => md.file_type(),\n        Err(e) => {\n            if let Some(raw_error) = e.raw_os_error() {\n                // On Unix-like systems, the error code for \"Too many levels of symbolic links\" is 40 (ELOOP).\n                // we want to provide a proper error message in this case.\n                #[cfg(not(any(target_os = \"macos\", target_os = \"freebsd\")))]\n                let too_many_symlink_code = 40;\n                #[cfg(any(target_os = \"macos\", target_os = \"freebsd\"))]\n                let too_many_symlink_code = 62;\n                if raw_error == too_many_symlink_code {\n                    return Err(CatError::TooManySymlinks);\n                }\n            }\n            return Err(CatError::Io(e));\n        }\n    };\n    match ft {\n        #[cfg(unix)]\n        ft if ft.is_block_device() => Ok(InputType::BlockDevice),\n        #[cfg(unix)]\n        ft if ft.is_char_device() => Ok(InputType::CharacterDevice),\n        #[cfg(unix)]\n        ft if ft.is_fifo() => Ok(InputType::Fifo),\n        #[cfg(unix)]\n        ft if ft.is_socket() => Ok(InputType::Socket),\n        ft if ft.is_dir() => Ok(InputType::Directory),\n        ft if ft.is_file() => Ok(InputType::File),\n        ft if ft.is_symlink() => Ok(InputType::SymLink),\n        _ => Err(CatError::UnknownFiletype {\n            ft_debug: format!(\"{ft:?}\"),\n        }),\n    }\n}\n/// Writes handle to stdout with no configuration. This allows a\n/// simple memory copy.\nfn write_fast<R: FdReadable>(handle: &mut InputHandle<R>) -> CatResult<()> {\n    let stdout = io::stdout();\n    let mut stdout_lock = stdout.lock();\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        // If we're on Linux or Android, try to use the splice() system call\n        // for faster writing. If it works, we're done.\n        if !splice::write_fast_using_splice(handle, &stdout_lock)? {\n            return Ok(());\n        }\n    }\n    // If we're not on Linux or Android, or the splice() call failed,\n    // fall back on slower writing.\n    let mut buf = [0; 1024 * 64];\n    while let Ok(n) = handle.reader.read(&mut buf) {\n        if n == 0 {\n            break;\n        }\n        stdout_lock.write_all(&buf[..n])?;\n    }\n\n    // If the splice() call failed and there has been some data written to\n    // stdout via while loop above AND there will be second splice() call\n    // that will succeed, data pushed through splice will be output before\n    // the data buffered in stdout.lock. Therefore additional explicit flush\n    // is required here.\n    stdout_lock.flush()?;\n    Ok(())\n}\n/// Outputs file contents to stdout in a line-by-line fashion,\n/// propagating any errors that might occur.",
      "file_name": "coreutils/src/uu\\cat\\src\\cat.rs"
    },
    {
      "chunk": "fn write_lines<R: FdReadable>(\n    handle: &mut InputHandle<R>,\n    options: &OutputOptions,\n    state: &mut OutputState,\n) -> CatResult<()> {\n    let mut in_buf = [0; 1024 * 31];\n    let stdout = io::stdout();\n    let stdout = stdout.lock();\n    // Add a 32K buffer for stdout - this greatly improves performance.\n    let mut writer = BufWriter::with_capacity(32 * 1024, stdout);\n\n    while let Ok(n) = handle.reader.read(&mut in_buf) {\n        if n == 0 {\n            break;\n        }\n        let in_buf = &in_buf[..n];\n        let mut pos = 0;\n        while pos < n {\n            // skip empty line_number enumerating them if needed\n            if in_buf[pos] == b'\\n' {\n                write_new_line(&mut writer, options, state, handle.is_interactive)?;\n                state.at_line_start = true;\n                pos += 1;\n                continue;\n            }\n            if state.skipped_carriage_return {\n                writer.write_all(b\"\\r\")?;\n                state.skipped_carriage_return = false;\n                state.at_line_start = false;\n            }\n            state.one_blank_kept = false;\n            if state.at_line_start && options.number != NumberingMode::None {\n                state.line_number.write(&mut writer)?;\n                state.line_number.increment();\n            }\n\n            // print to end of line or end of buffer\n            let offset = write_end(&mut writer, &in_buf[pos..], options);\n\n            // end of buffer?\n            if offset + pos == in_buf.len() {\n                state.at_line_start = false;\n                break;\n            }\n            if in_buf[pos + offset] == b'\\r' {\n                state.skipped_carriage_return = true;\n            } else {\n                assert_eq!(in_buf[pos + offset], b'\\n');\n                // print suitable end of line\n                write_end_of_line(\n                    &mut writer,\n                    options.end_of_line().as_bytes(),\n                    handle.is_interactive,\n                )?;\n                state.at_line_start = true;\n            }\n            pos += offset + 1;\n        }\n        // We need to flush the buffer each time around the loop in order to pass GNU tests.\n        // When we are reading the input from a pipe, the `handle.reader.read` call at the top\n        // of this loop will block (indefinitely) whist waiting for more data. The expectation\n        // however is that anything that's ready for output should show up in the meantime,\n        // and not be buffered internally to the `cat` process.\n        // Hence it's necessary to flush our buffer before every time we could potentially block\n        // on a `std::io::Read::read` call.\n        writer.flush()?;\n    }\n\n    Ok(())\n}\n// \\r followed by \\n is printed as ^M when show_ends is enabled, so that \\r\\n prints as ^M$\nfn write_new_line<W: Write>(\n    writer: &mut W,\n    options: &OutputOptions,\n    state: &mut OutputState,\n    is_interactive: bool,\n) -> CatResult<()> {\n    if state.skipped_carriage_return {\n        if options.show_ends {\n            writer.write_all(b\"^M\")?;\n        } else {\n            writer.write_all(b\"\\r\")?;\n        }\n        state.skipped_carriage_return = false;\n\n        write_end_of_line(writer, options.end_of_line().as_bytes(), is_interactive)?;\n        return Ok(());\n    }\n    if !state.at_line_start || !options.squeeze_blank || !state.one_blank_kept {\n        state.one_blank_kept = true;\n        if state.at_line_start && options.number == NumberingMode::All {\n            state.line_number.write(writer)?;\n            state.line_number.increment();\n        }\n        write_end_of_line(writer, options.end_of_line().as_bytes(), is_interactive)?;\n    }\n    Ok(())\n}\nfn write_end<W: Write>(writer: &mut W, in_buf: &[u8], options: &OutputOptions) -> usize {\n    if options.show_nonprint {\n        write_nonprint_to_end(in_buf, writer, options.tab().as_bytes())\n    } else if options.show_tabs {\n        write_tab_to_end(in_buf, writer)\n    } else {\n        write_to_end(in_buf, writer)\n    }\n}\n// write***_to_end methods\n// Write all symbols till \\n or \\r or end of buffer is reached\n// We need to stop at \\r because it may be written as ^M depending on the byte after and settings;\n// however, write_nonprint_to_end doesn't need to stop at \\r because it will always write \\r as ^M.\n// Return the number of written symbols\nfn write_to_end<W: Write>(in_buf: &[u8], writer: &mut W) -> usize {\n    // using memchr2 significantly improves performances\n    match memchr2(b'\\n', b'\\r', in_buf) {\n        Some(p) => {\n            writer.write_all(&in_buf[..p]).unwrap();\n            p\n        }\n        None => {\n            writer.write_all(in_buf).unwrap();\n            in_buf.len()\n        }\n    }\n}\nfn write_tab_to_end<W: Write>(mut in_buf: &[u8], writer: &mut W) -> usize {\n    let mut count = 0;\n    loop {\n        match in_buf\n            .iter()\n            .position(|c| *c == b'\\n' || *c == b'\\t' || *c == b'\\r')\n        {\n            Some(p) => {\n                writer.write_all(&in_buf[..p]).unwrap();\n                if in_buf[p] == b'\\t' {\n                    writer.write_all(b\"^I\").unwrap();\n                    in_buf = &in_buf[p + 1..];\n                    count += p + 1;\n                } else {\n                    // b'\\n' or b'\\r'\n                    return count + p;\n                }\n            }\n            None => {\n                writer.write_all(in_buf).unwrap();\n                return in_buf.len() + count;\n            }\n        };\n    }\n}\nfn write_nonprint_to_end<W: Write>(in_buf: &[u8], writer: &mut W, tab: &[u8]) -> usize {\n    let mut count = 0;\n\n    for byte in in_buf.iter().copied() {\n        if byte == b'\\n' {\n            break;\n        }\n        match byte {\n            9 => writer.write_all(tab),\n            0..=8 | 10..=31 => writer.write_all(&[b'^', byte + 64]),\n            32..=126 => writer.write_all(&[byte]),\n            127 => writer.write_all(b\"^?\"),\n            128..=159 => writer.write_all(&[b'M', b'-', b'^', byte - 64]),\n            160..=254 => writer.write_all(&[b'M', b'-', byte - 128]),\n            _ => writer.write_all(b\"M-^?\"),\n        }\n        .unwrap();\n        count += 1;\n    }\n    count\n}\nfn write_end_of_line<W: Write>(\n    writer: &mut W,\n    end_of_line: &[u8],\n    is_interactive: bool,\n) -> CatResult<()> {\n    writer.write_all(end_of_line)?;\n    if is_interactive {\n        writer.flush()?;\n    }\n    Ok(())\n}\n#[cfg(test)]\nmod tests {\n    use std::io::{BufWriter, stdout};\n\n    #[test]\n    fn test_write_tab_to_end_with_newline() {\n        let mut writer = BufWriter::with_capacity(1024 * 64, stdout());\n        let in_buf = b\"a\\tb\\tc\\n\";\n        assert_eq!(super::write_tab_to_end(in_buf, &mut writer), 5);\n    }\n\n    #[test]\n    fn test_write_tab_to_end_no_newline() {\n        let mut writer = BufWriter::with_capacity(1024 * 64, stdout());\n        let in_buf = b\"a\\tb\\tc\";\n        assert_eq!(super::write_tab_to_end(in_buf, &mut writer), 5);\n    }\n\n    #[test]\n    fn test_write_nonprint_to_end_new_line() {\n        let mut writer = BufWriter::with_capacity(1024 * 64, stdout());\n        let in_buf = b\"\\n\";\n        let tab = b\"\";\n        super::write_nonprint_to_end(in_buf, &mut writer, tab);\n        assert_eq!(writer.buffer().len(), 0);\n    }\n\n    #[test]\n    fn test_write_nonprint_to_end_9() {\n        let mut writer = BufWriter::with_capacity(1024 * 64, stdout());\n        let in_buf = &[9u8];\n        let tab = b\"tab\";\n        super::write_nonprint_to_end(in_buf, &mut writer, tab);\n        assert_eq!(writer.buffer(), tab);\n    }\n\n    #[test]\n    fn test_write_nonprint_to_end_0_to_8() {\n        for byte in 0u8..=8u8 {\n            let mut writer = BufWriter::with_capacity(1024 * 64, stdout());\n            let in_buf = &[byte];\n            let tab = b\"\";\n            super::write_nonprint_to_end(in_buf, &mut writer, tab);\n            assert_eq!(writer.buffer(), [b'^', byte + 64]);\n        }\n    }\n\n    #[test]\n    fn test_write_nonprint_to_end_10_to_31() {\n        for byte in 11u8..=31u8 {\n            let mut writer = BufWriter::with_capacity(1024 * 64, stdout());\n            let in_buf = &[byte];\n            let tab = b\"\";\n            super::write_nonprint_to_end(in_buf, &mut writer, tab);\n            assert_eq!(writer.buffer(), [b'^', byte + 64]);\n        }\n    }\n\n    #[test]\n    fn test_incrementing_string() {\n        let mut incrementing_string = super::LineNumber::new();\n        assert_eq!(b\"     1\\t\", incrementing_string.to_str());\n        incrementing_string.increment();\n        assert_eq!(b\"     2\\t\", incrementing_string.to_str());\n        // Run through to 100\n        for _ in 3..=100 {\n            incrementing_string.increment();\n        }\n        assert_eq!(b\"   100\\t\", incrementing_string.to_str());\n        // Run through until we overflow the original size.\n        for _ in 101..=1_000_000 {\n            incrementing_string.increment();\n        }\n        // Confirm that the start position moves when we overflow the original size.\n        assert_eq!(b\"1000000\\t\", incrementing_string.to_str());\n        incrementing_string.increment();\n        assert_eq!(b\"1000001\\t\", incrementing_string.to_str());\n    }\n}",
      "file_name": "coreutils/src/uu\\cat\\src\\cat.rs"
    },
    {
      "chunk": "uucore::bin!(uu_cat);",
      "file_name": "coreutils/src/uu\\cat\\src\\main.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nuse super::{CatResult, FdReadable, InputHandle};\nuse nix::unistd;\nuse std::os::{fd::AsFd, unix::io::AsRawFd};\nuse uucore::pipes::{pipe, splice, splice_exact};\nconst SPLICE_SIZE: usize = 1024 * 128;\nconst BUF_SIZE: usize = 1024 * 16;\n/// This function is called from `write_fast()` on Linux and Android. The\n/// function `splice()` is used to move data between two file descriptors\n/// without copying between kernel and user spaces. This results in a large\n/// speedup.\n///\n/// The `bool` in the result value indicates if we need to fall back to normal\n/// copying or not. False means we don't have to.\n#[inline]\npub(super) fn write_fast_using_splice<R: FdReadable, S: AsRawFd + AsFd>(\n    handle: &InputHandle<R>,\n    write_fd: &S,\n) -> CatResult<bool> {\n    let (pipe_rd, pipe_wr) = pipe()?;\n\n    loop {\n        match splice(&handle.reader, &pipe_wr, SPLICE_SIZE) {\n            Ok(n) => {\n                if n == 0 {\n                    return Ok(false);\n                }\n                if splice_exact(&pipe_rd, write_fd, n).is_err() {\n                    // If the first splice manages to copy to the intermediate\n                    // pipe, but the second splice to stdout fails for some reason\n                    // we can recover by copying the data that we have from the\n                    // intermediate pipe to stdout using normal read/write. Then\n                    // we tell the caller to fall back.\n                    copy_exact(&pipe_rd, write_fd, n)?;\n                    return Ok(true);\n                }\n            }\n            Err(_) => {\n                return Ok(true);\n            }\n        }\n    }\n}\n/// Move exactly `num_bytes` bytes from `read_fd` to `write_fd`.\n///\n/// Panics if not enough bytes can be read.\nfn copy_exact(read_fd: &impl AsFd, write_fd: &impl AsFd, num_bytes: usize) -> nix::Result<()> {\n    let mut left = num_bytes;\n    let mut buf = [0; BUF_SIZE];\n    while left > 0 {\n        let read = unistd::read(read_fd, &mut buf)?;\n        assert_ne!(read, 0, \"unexpected end of pipe\");\n        let mut written = 0;\n        while written < read {\n            match unistd::write(write_fd, &buf[written..read])? {\n                0 => panic!(),\n                n => written += n,\n            }\n        }\n        left -= read;\n    }\n    Ok(())\n}",
      "file_name": "coreutils/src/uu\\cat\\src\\splice.rs"
    }
  ],
  "head": [
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (vars) seekable\nuse clap::{Arg, ArgAction, ArgMatches, Command};\nuse std::ffi::OsString;\nuse std::fs::File;\nuse std::io::{self, BufWriter, Read, Seek, SeekFrom, Write};\nuse std::num::TryFromIntError;\n#[cfg(unix)]\nuse std::os::fd::{AsRawFd, FromRawFd};\nuse thiserror::Error;\nuse uucore::display::Quotable;\nuse uucore::error::{FromIo, UError, UResult};\nuse uucore::line_ending::LineEnding;\nuse uucore::{format_usage, help_about, help_usage, show};\nconst BUF_SIZE: usize = 65536;\nconst ABOUT: &str = help_about!(\"head.md\");\nconst USAGE: &str = help_usage!(\"head.md\");\nmod options {\n    pub const BYTES_NAME: &str = \"BYTES\";\n    pub const LINES_NAME: &str = \"LINES\";\n    pub const QUIET_NAME: &str = \"QUIET\";\n    pub const VERBOSE_NAME: &str = \"VERBOSE\";\n    pub const ZERO_NAME: &str = \"ZERO\";\n    pub const FILES_NAME: &str = \"FILE\";\n    pub const PRESUME_INPUT_PIPE: &str = \"-PRESUME-INPUT-PIPE\";\n}\nmod parse;\nmod take;\nuse take::copy_all_but_n_bytes;\nuse take::copy_all_but_n_lines;\nuse take::take_lines;\n#[derive(Error, Debug)]\nenum HeadError {\n    /// Wrapper around `io::Error`\n    #[error(\"error reading {name}: {err}\")]\n    Io { name: String, err: io::Error },\n\n    #[error(\"parse error: {0}\")]\n    ParseError(String),\n\n    #[error(\"bad argument encoding\")]\n    BadEncoding,\n\n    #[error(\"{0}: number of -bytes or -lines is too large\")]\n    NumTooLarge(#[from] TryFromIntError),\n\n    #[error(\"clap error: {0}\")]\n    Clap(#[from] clap::Error),\n\n    #[error(\"{0}\")]\n    MatchOption(String),\n}\nimpl UError for HeadError {\n    fn code(&self) -> i32 {\n        1\n    }\n}\ntype HeadResult<T> = Result<T, HeadError>;\npub fn uu_app() -> Command {\n    Command::new(uucore::util_name())\n        .version(uucore::crate_version!())\n        .about(ABOUT)\n        .override_usage(format_usage(USAGE))\n        .infer_long_args(true)\n        .arg(\n            Arg::new(options::BYTES_NAME)\n                .short('c')\n                .long(\"bytes\")\n                .value_name(\"[-]NUM\")\n                .help(\n                    \"\\\n                     print the first NUM bytes of each file;\\n\\\n                     with the leading '-', print all but the last\\n\\\n                     NUM bytes of each file\\\n                     \",\n                )\n                .overrides_with_all([options::BYTES_NAME, options::LINES_NAME])\n                .allow_hyphen_values(true),\n        )\n        .arg(\n            Arg::new(options::LINES_NAME)\n                .short('n')\n                .long(\"lines\")\n                .value_name(\"[-]NUM\")\n                .help(\n                    \"\\\n                     print the first NUM lines instead of the first 10;\\n\\\n                     with the leading '-', print all but the last\\n\\\n                     NUM lines of each file\\\n                     \",\n                )\n                .overrides_with_all([options::LINES_NAME, options::BYTES_NAME])\n                .allow_hyphen_values(true),\n        )\n        .arg(\n            Arg::new(options::QUIET_NAME)\n                .short('q')\n                .long(\"quiet\")\n                .visible_alias(\"silent\")\n                .help(\"never print headers giving file names\")\n                .overrides_with_all([options::VERBOSE_NAME, options::QUIET_NAME])\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::VERBOSE_NAME)\n                .short('v')\n                .long(\"verbose\")\n                .help(\"always print headers giving file names\")\n                .overrides_with_all([options::QUIET_NAME, options::VERBOSE_NAME])\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::PRESUME_INPUT_PIPE)\n                .long(\"presume-input-pipe\")\n                .alias(\"-presume-input-pipe\")\n                .hide(true)\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::ZERO_NAME)\n                .short('z')\n                .long(\"zero-terminated\")\n                .help(\"line delimiter is NUL, not newline\")\n                .overrides_with(options::ZERO_NAME)\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::FILES_NAME)\n                .action(ArgAction::Append)\n                .value_hint(clap::ValueHint::FilePath),\n        )\n}\n#[derive(Debug, PartialEq)]\nenum Mode {\n    FirstLines(u64),\n    AllButLastLines(u64),\n    FirstBytes(u64),\n    AllButLastBytes(u64),\n}\nimpl Default for Mode {\n    fn default() -> Self {\n        Self::FirstLines(10)\n    }\n}\nimpl Mode {\n    fn from(matches: &ArgMatches) -> Result<Self, String> {\n        if let Some(v) = matches.get_one::<String>(options::BYTES_NAME) {\n            let (n, all_but_last) =\n                parse::parse_num(v).map_err(|err| format!(\"invalid number of bytes: {err}\"))?;\n            if all_but_last {\n                Ok(Self::AllButLastBytes(n))\n            } else {\n                Ok(Self::FirstBytes(n))\n            }\n        } else if let Some(v) = matches.get_one::<String>(options::LINES_NAME) {\n            let (n, all_but_last) =\n                parse::parse_num(v).map_err(|err| format!(\"invalid number of lines: {err}\"))?;\n            if all_but_last {\n                Ok(Self::AllButLastLines(n))\n            } else {\n                Ok(Self::FirstLines(n))\n            }\n        } else {\n            Ok(Self::default())\n        }\n    }\n}\nfn arg_iterate<'a>(\n    mut args: impl uucore::Args + 'a,\n) -> HeadResult<Box<dyn Iterator<Item = OsString> + 'a>> {\n    // argv[0] is always present\n    let first = args.next().unwrap();\n    if let Some(second) = args.next() {\n        if let Some(s) = second.to_str() {\n            match parse::parse_obsolete(s) {\n                Some(Ok(iter)) => Ok(Box::new(vec![first].into_iter().chain(iter).chain(args))),\n                Some(Err(parse::ParseError)) => Err(HeadError::ParseError(format!(\n                    \"bad argument format: {}\",\n                    s.quote()\n                ))),\n                None => Ok(Box::new(vec![first, second].into_iter().chain(args))),\n            }\n        } else {\n            Err(HeadError::BadEncoding)\n        }\n    } else {\n        Ok(Box::new(vec![first].into_iter()))\n    }\n}\n#[derive(Debug, PartialEq, Default)]\nstruct HeadOptions {\n    pub quiet: bool,\n    pub verbose: bool,\n    pub line_ending: LineEnding,\n    pub presume_input_pipe: bool,\n    pub mode: Mode,\n    pub files: Vec<String>,\n}\nimpl HeadOptions {\n    ///Construct options from matches\n    pub fn get_from(matches: &ArgMatches) -> Result<Self, String> {\n        let mut options = Self::default();\n\n        options.quiet = matches.get_flag(options::QUIET_NAME);\n        options.verbose = matches.get_flag(options::VERBOSE_NAME);\n        options.line_ending = LineEnding::from_zero_flag(matches.get_flag(options::ZERO_NAME));\n        options.presume_input_pipe = matches.get_flag(options::PRESUME_INPUT_PIPE);\n\n        options.mode = Mode::from(matches)?;\n\n        options.files = match matches.get_many::<String>(options::FILES_NAME) {\n            Some(v) => v.cloned().collect(),\n            None => vec![\"-\".to_owned()],\n        };\n\n        Ok(options)\n    }\n}\n#[inline]\nfn wrap_in_stdout_error(err: io::Error) -> io::Error {\n    io::Error::new(\n        err.kind(),\n        format!(\"error writing 'standard output': {err}\"),\n    )\n}\nfn read_n_bytes(input: impl Read, n: u64) -> io::Result<u64> {\n    // Read the first `n` bytes from the `input` reader.\n    let mut reader = input.take(n);\n\n    // Write those bytes to `stdout`.\n    let stdout = io::stdout();\n    let mut stdout = stdout.lock();\n\n    let bytes_written = io::copy(&mut reader, &mut stdout).map_err(wrap_in_stdout_error)?;\n\n    // Make sure we finish writing everything to the target before\n    // exiting. Otherwise, when Rust is implicitly flushing, any\n    // error will be silently ignored.\n    stdout.flush().map_err(wrap_in_stdout_error)?;\n\n    Ok(bytes_written)\n}\nfn read_n_lines(input: &mut impl io::BufRead, n: u64, separator: u8) -> io::Result<u64> {\n    // Read the first `n` lines from the `input` reader.\n    let mut reader = take_lines(input, n, separator);\n\n    // Write those bytes to `stdout`.\n    let stdout = io::stdout();\n    let stdout = stdout.lock();\n    let mut writer = BufWriter::with_capacity(BUF_SIZE, stdout);\n\n    let bytes_written = io::copy(&mut reader, &mut writer).map_err(wrap_in_stdout_error)?;\n\n    // Make sure we finish writing everything to the target before\n    // exiting. Otherwise, when Rust is implicitly flushing, any\n    // error will be silently ignored.\n    writer.flush().map_err(wrap_in_stdout_error)?;\n\n    Ok(bytes_written)\n}\nfn catch_too_large_numbers_in_backwards_bytes_or_lines(n: u64) -> Option<usize> {\n    usize::try_from(n).ok()\n}\nfn read_but_last_n_bytes(mut input: impl Read, n: u64) -> io::Result<u64> {\n    let mut bytes_written: u64 = 0;\n    if let Some(n) = catch_too_large_numbers_in_backwards_bytes_or_lines(n) {\n        let stdout = io::stdout();\n        let mut stdout = stdout.lock();\n\n        bytes_written = copy_all_but_n_bytes(&mut input, &mut stdout, n)\n            .map_err(wrap_in_stdout_error)?\n            .try_into()\n            .unwrap();\n\n        // Make sure we finish writing everything to the target before\n        // exiting. Otherwise, when Rust is implicitly flushing, any\n        // error will be silently ignored.\n        stdout.flush().map_err(wrap_in_stdout_error)?;\n    }\n    Ok(bytes_written)\n}",
      "file_name": "coreutils/src/uu\\head\\src\\head.rs"
    },
    {
      "chunk": "fn read_but_last_n_lines(mut input: impl Read, n: u64, separator: u8) -> io::Result<u64> {\n    let stdout = io::stdout();\n    let mut stdout = stdout.lock();\n    if n == 0 {\n        return io::copy(&mut input, &mut stdout).map_err(wrap_in_stdout_error);\n    }\n    let mut bytes_written: u64 = 0;\n    if let Some(n) = catch_too_large_numbers_in_backwards_bytes_or_lines(n) {\n        bytes_written = copy_all_but_n_lines(input, &mut stdout, n, separator)\n            .map_err(wrap_in_stdout_error)?\n            .try_into()\n            .unwrap();\n        // Make sure we finish writing everything to the target before\n        // exiting. Otherwise, when Rust is implicitly flushing, any\n        // error will be silently ignored.\n        stdout.flush().map_err(wrap_in_stdout_error)?;\n    }\n    Ok(bytes_written)\n}\n/// Return the index in `input` just after the `n`th line from the end.\n///\n/// If `n` exceeds the number of lines in this file, then return 0.\n/// This function rewinds the cursor to the\n/// beginning of the input just before returning unless there is an\n/// I/O error.\n///\n/// # Errors\n///\n/// This function returns an error if there is a problem seeking\n/// through or reading the input.\n///\n/// # Examples\n///\n/// The function returns the index of the byte immediately following\n/// the line ending character of the `n`th line from the end of the\n/// input:\n///\n/// ```rust,ignore\n/// let mut input = Cursor::new(\"x\\ny\\nz\\n\");\n/// assert_eq!(find_nth_line_from_end(&mut input, 0, false).unwrap(), 6);\n/// assert_eq!(find_nth_line_from_end(&mut input, 1, false).unwrap(), 4);\n/// assert_eq!(find_nth_line_from_end(&mut input, 2, false).unwrap(), 2);\n/// ```\n///\n/// If `n` exceeds the number of lines in the file, always return 0:\n///\n/// ```rust,ignore\n/// let mut input = Cursor::new(\"x\\ny\\nz\\n\");\n/// assert_eq!(find_nth_line_from_end(&mut input, 3, false).unwrap(), 0);\n/// assert_eq!(find_nth_line_from_end(&mut input, 4, false).unwrap(), 0);\n/// assert_eq!(find_nth_line_from_end(&mut input, 1000, false).unwrap(), 0);\n/// ```\nfn find_nth_line_from_end<R>(input: &mut R, n: u64, separator: u8) -> io::Result<u64>\nwhere\n    R: Read + Seek,\n{\n    let file_size = input.seek(SeekFrom::End(0))?;\n\n    let mut buffer = [0u8; BUF_SIZE];\n\n    let mut i = 0u64;\n    let mut lines = 0u64;\n\n    loop {\n        // the casts here are ok, `buffer.len()` should never be above a few k\n        let bytes_remaining_to_search = file_size - i;\n        let bytes_to_read_this_loop = bytes_remaining_to_search.min(BUF_SIZE.try_into().unwrap());\n        let read_start_offset = bytes_remaining_to_search - bytes_to_read_this_loop;\n        let buffer = &mut buffer[..bytes_to_read_this_loop.try_into().unwrap()];\n\n        input.seek(SeekFrom::Start(read_start_offset))?;\n        input.read_exact(buffer)?;\n        for byte in buffer.iter().rev() {\n            if byte == &separator {\n                lines += 1;\n            }\n            // if it were just `n`,\n            if lines == n + 1 {\n                input.rewind()?;\n                return Ok(file_size - i);\n            }\n            i += 1;\n        }\n        if file_size - i == 0 {\n            input.rewind()?;\n            return Ok(0);\n        }\n    }\n}\nfn is_seekable(input: &mut File) -> bool {\n    let current_pos = input.stream_position();\n    current_pos.is_ok()\n        && input.seek(SeekFrom::End(0)).is_ok()\n        && input.seek(SeekFrom::Start(current_pos.unwrap())).is_ok()\n}\nfn head_backwards_file(input: &mut File, options: &HeadOptions) -> io::Result<u64> {\n    let st = input.metadata()?;\n    let seekable = is_seekable(input);\n    let blksize_limit = uucore::fs::sane_blksize::sane_blksize_from_metadata(&st);\n    if !seekable || st.len() <= blksize_limit {\n        head_backwards_without_seek_file(input, options)\n    } else {\n        head_backwards_on_seekable_file(input, options)\n    }\n}\nfn head_backwards_without_seek_file(input: &mut File, options: &HeadOptions) -> io::Result<u64> {\n    match options.mode {\n        Mode::AllButLastBytes(n) => read_but_last_n_bytes(input, n),\n        Mode::AllButLastLines(n) => read_but_last_n_lines(input, n, options.line_ending.into()),\n        _ => unreachable!(),\n    }\n}\nfn head_backwards_on_seekable_file(input: &mut File, options: &HeadOptions) -> io::Result<u64> {\n    match options.mode {\n        Mode::AllButLastBytes(n) => {\n            let size = input.metadata()?.len();\n            if n >= size {\n                Ok(0)\n            } else {\n                read_n_bytes(input, size - n)\n            }\n        }\n        Mode::AllButLastLines(n) => {\n            let found = find_nth_line_from_end(input, n, options.line_ending.into())?;\n            read_n_bytes(input, found)\n        }\n        _ => unreachable!(),\n    }\n}\nfn head_file(input: &mut File, options: &HeadOptions) -> io::Result<u64> {\n    match options.mode {\n        Mode::FirstBytes(n) => read_n_bytes(input, n),\n        Mode::FirstLines(n) => read_n_lines(\n            &mut io::BufReader::with_capacity(BUF_SIZE, input),\n            n,\n            options.line_ending.into(),\n        ),\n        Mode::AllButLastBytes(_) | Mode::AllButLastLines(_) => head_backwards_file(input, options),\n    }\n}\n#[allow(clippy::cognitive_complexity)]\nfn uu_head(options: &HeadOptions) -> UResult<()> {\n    let mut first = true;\n    for file in &options.files {\n        let res = match (file.as_str(), options.presume_input_pipe) {\n            (_, true) | (\"-\", false) => {\n                if (options.files.len() > 1 && !options.quiet) || options.verbose {\n                    if !first {\n                        println!();\n                    }\n                    println!(\"==> standard input <==\");\n                }\n                let stdin = io::stdin();\n\n                #[cfg(unix)]\n                {\n                    let stdin_raw_fd = stdin.as_raw_fd();\n                    let mut stdin_file = unsafe { File::from_raw_fd(stdin_raw_fd) };\n                    let current_pos = stdin_file.stream_position();\n                    if let Ok(current_pos) = current_pos {\n                        // We have a seekable file. Ensure we set the input stream to the\n                        // last byte read so that any tools that parse the remainder of\n                        // the stdin stream read from the correct place.\n\n                        let bytes_read = head_file(&mut stdin_file, options)?;\n                        stdin_file.seek(SeekFrom::Start(current_pos + bytes_read))?;\n                    } else {\n                        let _bytes_read = head_file(&mut stdin_file, options)?;\n                    }\n                }\n\n                #[cfg(not(unix))]\n                {\n                    let mut stdin = stdin.lock();\n\n                    match options.mode {\n                        Mode::FirstBytes(n) => read_n_bytes(&mut stdin, n),\n                        Mode::AllButLastBytes(n) => read_but_last_n_bytes(&mut stdin, n),\n                        Mode::FirstLines(n) => {\n                            read_n_lines(&mut stdin, n, options.line_ending.into())\n                        }\n                        Mode::AllButLastLines(n) => {\n                            read_but_last_n_lines(&mut stdin, n, options.line_ending.into())\n                        }\n                    }?;\n                }\n\n                Ok(())\n            }\n            (name, false) => {\n                let mut file = match File::open(name) {\n                    Ok(f) => f,\n                    Err(err) => {\n                        show!(err.map_err_context(|| format!(\n                            \"cannot open {} for reading\",\n                            name.quote()\n                        )));\n                        continue;\n                    }\n                };\n                if (options.files.len() > 1 && !options.quiet) || options.verbose {\n                    if !first {\n                        println!();\n                    }\n                    println!(\"==> {name} <==\");\n                }\n                head_file(&mut file, options)?;\n                Ok(())\n            }\n        };\n        if let Err(e) = res {\n            let name = if file.as_str() == \"-\" {\n                \"standard input\"\n            } else {\n                file\n            };\n            return Err(HeadError::Io {\n                name: name.to_string(),\n                err: e,\n            }\n            .into());\n        }\n        first = false;\n    }\n    // Even though this is returning `Ok`, it is possible that a call\n    // to `show!()` and thus a call to `set_exit_code()` has been\n    // called above. If that happens, then this process will exit with\n    // a non-zero exit code.\n    Ok(())\n}\n#[uucore::main]\npub fn uumain(args: impl uucore::Args) -> UResult<()> {\n    let matches = uu_app().try_get_matches_from(arg_iterate(args)?)?;\n    let args = match HeadOptions::get_from(&matches) {\n        Ok(o) => o,\n        Err(s) => {\n            return Err(HeadError::MatchOption(s).into());\n        }\n    };\n    uu_head(&args)\n}\n#[cfg(test)]",
      "file_name": "coreutils/src/uu\\head\\src\\head.rs"
    },
    {
      "chunk": "mod tests {\n    use io::Cursor;\n    use std::ffi::OsString;\n\n    use super::*;\n\n    fn options(args: &str) -> Result<HeadOptions, String> {\n        let combined = \"head \".to_owned() + args;\n        let args = combined.split_whitespace().map(OsString::from);\n        let matches = uu_app()\n            .get_matches_from(arg_iterate(args).map_err(|_| String::from(\"Arg iterate failed\"))?);\n        HeadOptions::get_from(&matches)\n    }\n\n    #[test]\n    fn test_args_modes() {\n        let args = options(\"-n -10M -vz\").unwrap();\n        assert_eq!(args.line_ending, LineEnding::Nul);\n        assert!(args.verbose);\n        assert_eq!(args.mode, Mode::AllButLastLines(10 * 1024 * 1024));\n    }\n\n    #[test]\n    fn test_gnu_compatibility() {\n        let args = options(\"-n 1 -c 1 -n 5 -c kiB -vqvqv\").unwrap(); // spell-checker:disable-line\n        assert_eq!(args.mode, Mode::FirstBytes(1024));\n        assert!(args.verbose);\n        assert_eq!(options(\"-5\").unwrap().mode, Mode::FirstLines(5));\n        assert_eq!(options(\"-2b\").unwrap().mode, Mode::FirstBytes(1024));\n        assert_eq!(options(\"-5 -c 1\").unwrap().mode, Mode::FirstBytes(1));\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn all_args_test() {\n        assert!(options(\"--silent\").unwrap().quiet);\n        assert!(options(\"--quiet\").unwrap().quiet);\n        assert!(options(\"-q\").unwrap().quiet);\n        assert!(options(\"--verbose\").unwrap().verbose);\n        assert!(options(\"-v\").unwrap().verbose);\n        assert_eq!(\n            options(\"--zero-terminated\").unwrap().line_ending,\n            LineEnding::Nul\n        );\n        assert_eq!(options(\"-z\").unwrap().line_ending, LineEnding::Nul);\n        assert_eq!(options(\"--lines 15\").unwrap().mode, Mode::FirstLines(15));\n        assert_eq!(options(\"-n 15\").unwrap().mode, Mode::FirstLines(15));\n        assert_eq!(options(\"--bytes 15\").unwrap().mode, Mode::FirstBytes(15));\n        assert_eq!(options(\"-c 15\").unwrap().mode, Mode::FirstBytes(15));\n    }\n\n    #[test]\n    fn test_options_errors() {\n        assert!(options(\"-n IsThisTheRealLife?\").is_err());\n        assert!(options(\"-c IsThisJustFantasy\").is_err());\n    }\n\n    #[test]\n    fn test_options_correct_defaults() {\n        let opts = HeadOptions::default();\n\n        assert!(!opts.verbose);\n        assert!(!opts.quiet);\n        assert_eq!(opts.line_ending, LineEnding::Newline);\n        assert_eq!(opts.mode, Mode::FirstLines(10));\n        assert!(opts.files.is_empty());\n    }\n\n    fn arg_outputs(src: &str) -> Result<String, ()> {\n        let split = src.split_whitespace().map(OsString::from);\n        match arg_iterate(split) {\n            Ok(args) => {\n                let vec = args\n                    .map(|s| s.to_str().unwrap().to_owned())\n                    .collect::<Vec<_>>();\n                Ok(vec.join(\" \"))\n            }\n            Err(_) => Err(()),\n        }\n    }\n\n    #[test]\n    fn test_arg_iterate() {\n        // test that normal args remain unchanged\n        assert_eq!(\n            arg_outputs(\"head -n -5 -zv\"),\n            Ok(\"head -n -5 -zv\".to_owned())\n        );\n        // tests that nonsensical args are unchanged\n        assert_eq!(\n            arg_outputs(\"head -to_be_or_not_to_be,...\"),\n            Ok(\"head -to_be_or_not_to_be,...\".to_owned())\n        );\n        //test that the obsolete syntax is unrolled\n        assert_eq!(\n            arg_outputs(\"head -123qvqvqzc\"), // spell-checker:disable-line\n            Ok(\"head -q -z -c 123\".to_owned())\n        );\n        //test that bad obsoletes are an error\n        assert!(arg_outputs(\"head -123FooBar\").is_err());\n        //test overflow\n        assert!(arg_outputs(\"head -100000000000000000000000000000000000000000\").is_ok());\n        //test that empty args remain unchanged\n        assert_eq!(arg_outputs(\"head\"), Ok(\"head\".to_owned()));\n    }\n\n    #[test]\n    #[cfg(target_os = \"linux\")]\n    fn test_arg_iterate_bad_encoding() {\n        use std::os::unix::ffi::OsStringExt;\n        let invalid = OsString::from_vec(vec![b'\\x80', b'\\x81']);\n        // this arises from a conversion from OsString to &str\n        assert!(arg_iterate(vec![OsString::from(\"head\"), invalid].into_iter()).is_err());\n    }\n\n    #[test]\n    fn read_early_exit() {\n        let mut empty = io::BufReader::new(Cursor::new(Vec::new()));\n        assert!(read_n_bytes(&mut empty, 0).is_ok());\n        assert!(read_n_lines(&mut empty, 0, b'\\n').is_ok());\n    }\n\n    #[test]\n    fn test_find_nth_line_from_end() {\n        // Make sure our input buffer is several multiples of BUF_SIZE in size\n        // such that we can be reasonably confident we've exercised all logic paths.\n        // Make the contents of the buffer look like...\n        // aaaa\\n\n        // aaaa\\n\n        // aaaa\\n\n        // aaaa\\n\n        // aaaa\\n\n        // ...\n        // This will make it easier to validate the results since each line will have\n        // 5 bytes in it.\n\n        let minimum_buffer_size = BUF_SIZE * 4;\n        let mut input_buffer = vec![];\n        let mut loop_iteration: u64 = 0;\n        while input_buffer.len() < minimum_buffer_size {\n            for _n in 0..4 {\n                input_buffer.push(b'a');\n            }\n            loop_iteration += 1;\n            input_buffer.push(b'\\n');\n        }\n\n        let lines_in_input_file = loop_iteration;\n        let input_length = lines_in_input_file * 5;\n        assert_eq!(input_length, input_buffer.len().try_into().unwrap());\n        let mut input = Cursor::new(input_buffer);\n        // We now have loop_iteration lines in the buffer Now walk backwards through the buffer\n        // to confirm everything parses correctly.\n        // Use a large step size to prevent the test from taking too long, but don't use a power\n        // of 2 in case we miss some corner case.\n        let step_size = 511;\n        for n in (0..lines_in_input_file).filter(|v| v % step_size == 0) {\n            // The 5*n comes from 5-bytes per row.\n            assert_eq!(\n                find_nth_line_from_end(&mut input, n, b'\\n').unwrap(),\n                input_length - 5 * n\n            );\n        }\n\n        // Now confirm that if we query with a value >= lines_in_input_file we get an offset\n        // of 0\n        assert_eq!(\n            find_nth_line_from_end(&mut input, lines_in_input_file, b'\\n').unwrap(),\n            0\n        );\n        assert_eq!(\n            find_nth_line_from_end(&mut input, lines_in_input_file + 1, b'\\n').unwrap(),\n            0\n        );\n        assert_eq!(\n            find_nth_line_from_end(&mut input, lines_in_input_file + 1000, b'\\n').unwrap(),\n            0\n        );\n    }\n}",
      "file_name": "coreutils/src/uu\\head\\src\\head.rs"
    },
    {
      "chunk": "uucore::bin!(uu_head);",
      "file_name": "coreutils/src/uu\\head\\src\\main.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nuse std::ffi::OsString;\nuse uucore::parser::parse_size::{ParseSizeError, parse_size_u64_max};\n#[derive(PartialEq, Eq, Debug)]\npub struct ParseError;\n/// Parses obsolete syntax\n/// head -NUM\\[kmzv\\] // spell-checker:disable-line\npub fn parse_obsolete(src: &str) -> Option<Result<Vec<OsString>, ParseError>> {\n    let mut chars = src.char_indices();\n    if let Some((mut num_start, '-')) = chars.next() {\n        num_start += 1;\n        let mut num_end = src.len();\n        let mut has_num = false;\n        let mut plus_possible = false;\n        let mut last_char = 0 as char;\n        for (n, c) in &mut chars {\n            if c.is_ascii_digit() {\n                has_num = true;\n                plus_possible = false;\n            } else if c == '+' && plus_possible {\n                plus_possible = false;\n                num_start += 1;\n                continue;\n            } else {\n                num_end = n;\n                last_char = c;\n                break;\n            }\n        }\n        if has_num {\n            process_num_block(&src[num_start..num_end], last_char, &mut chars)\n        } else {\n            None\n        }\n    } else {\n        None\n    }\n}\n/// Processes the numeric block of the input string to generate the appropriate options.\nfn process_num_block(\n    src: &str,\n    last_char: char,\n    chars: &mut std::str::CharIndices,\n) -> Option<Result<Vec<OsString>, ParseError>> {\n    let num = match src.parse::<usize>() {\n        Ok(n) => n,\n        Err(e) if *e.kind() == std::num::IntErrorKind::PosOverflow => usize::MAX,\n        _ => return Some(Err(ParseError)),\n    };\n    let mut quiet = false;\n    let mut verbose = false;\n    let mut zero_terminated = false;\n    let mut multiplier = None;\n    let mut c = last_char;\n    loop {\n        // note that here, we only match lower case 'k', 'c', and 'm'\n        match c {\n            // we want to preserve order\n            // this also saves us 1 heap allocation\n            'q' => {\n                quiet = true;\n                verbose = false;\n            }\n            'v' => {\n                verbose = true;\n                quiet = false;\n            }\n            'z' => zero_terminated = true,\n            'c' => multiplier = Some(1),\n            'b' => multiplier = Some(512),\n            'k' => multiplier = Some(1024),\n            'm' => multiplier = Some(1024 * 1024),\n            '\\0' => {}\n            _ => return Some(Err(ParseError)),\n        }\n        if let Some((_, next)) = chars.next() {\n            c = next;\n        } else {\n            break;\n        }\n    }\n    let mut options = Vec::new();\n    if quiet {\n        options.push(OsString::from(\"-q\"));\n    }\n    if verbose {\n        options.push(OsString::from(\"-v\"));\n    }\n    if zero_terminated {\n        options.push(OsString::from(\"-z\"));\n    }\n    if let Some(n) = multiplier {\n        options.push(OsString::from(\"-c\"));\n        let num = num.saturating_mul(n);\n        options.push(OsString::from(format!(\"{num}\")));\n    } else {\n        options.push(OsString::from(\"-n\"));\n        options.push(OsString::from(format!(\"{num}\")));\n    }\n    Some(Ok(options))\n}\n/// Parses an -c or -n argument,\n/// the bool specifies whether to read from the end\npub fn parse_num(src: &str) -> Result<(u64, bool), ParseSizeError> {\n    let mut size_string = src.trim();\n    let mut all_but_last = false;\n\n    if let Some(c) = size_string.chars().next() {\n        if c == '+' || c == '-' {\n            // head: '+' is not documented (8.32 man pages)\n            size_string = &size_string[1..];\n            if c == '-' {\n                all_but_last = true;\n            }\n        }\n    } else {\n        return Err(ParseSizeError::ParseFailure(src.to_string()));\n    }\n\n    // remove leading zeros so that size is interpreted as decimal, not octal\n    let trimmed_string = size_string.trim_start_matches('0');\n    if trimmed_string.is_empty() {\n        Ok((0, all_but_last))\n    } else {\n        parse_size_u64_max(trimmed_string).map(|n| (n, all_but_last))\n    }\n}\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn obsolete(src: &str) -> Option<Result<Vec<String>, ParseError>> {\n        let r = parse_obsolete(src);\n        match r {\n            Some(s) => match s {\n                Ok(v) => Some(Ok(v\n                    .into_iter()\n                    .map(|s| s.to_str().unwrap().to_owned())\n                    .collect())),\n                Err(e) => Some(Err(e)),\n            },\n            None => None,\n        }\n    }\n\n    fn obsolete_result(src: &[&str]) -> Option<Result<Vec<String>, ParseError>> {\n        Some(Ok(src.iter().map(|s| s.to_string()).collect()))\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn test_parse_numbers_obsolete() {\n        assert_eq!(obsolete(\"-5\"), obsolete_result(&[\"-n\", \"5\"]));\n        assert_eq!(obsolete(\"-100\"), obsolete_result(&[\"-n\", \"100\"]));\n        assert_eq!(obsolete(\"-5m\"), obsolete_result(&[\"-c\", \"5242880\"]));\n        assert_eq!(obsolete(\"-1k\"), obsolete_result(&[\"-c\", \"1024\"]));\n        assert_eq!(obsolete(\"-2b\"), obsolete_result(&[\"-c\", \"1024\"]));\n        assert_eq!(obsolete(\"-1mmk\"), obsolete_result(&[\"-c\", \"1024\"]));\n        assert_eq!(obsolete(\"-1vz\"), obsolete_result(&[\"-v\", \"-z\", \"-n\", \"1\"]));\n        assert_eq!(\n            obsolete(\"-1vzqvq\"), // spell-checker:disable-line\n            obsolete_result(&[\"-q\", \"-z\", \"-n\", \"1\"])\n        );\n        assert_eq!(obsolete(\"-1vzc\"), obsolete_result(&[\"-v\", \"-z\", \"-c\", \"1\"]));\n        assert_eq!(\n            obsolete(\"-105kzm\"),\n            obsolete_result(&[\"-z\", \"-c\", \"110100480\"])\n        );\n    }\n\n    #[test]\n    fn test_parse_errors_obsolete() {\n        assert_eq!(obsolete(\"-5n\"), Some(Err(ParseError)));\n        assert_eq!(obsolete(\"-5c5\"), Some(Err(ParseError)));\n    }\n\n    #[test]\n    fn test_parse_obsolete_no_match() {\n        assert_eq!(obsolete(\"-k\"), None);\n        assert_eq!(obsolete(\"asd\"), None);\n    }\n\n    #[test]\n    #[cfg(target_pointer_width = \"64\")]\n    fn test_parse_obsolete_overflow_x64() {\n        assert_eq!(\n            obsolete(\"-1000000000000000m\"),\n            obsolete_result(&[\"-c\", \"18446744073709551615\"])\n        );\n        assert_eq!(\n            obsolete(\"-10000000000000000000000\"),\n            obsolete_result(&[\"-n\", \"18446744073709551615\"])\n        );\n    }\n\n    #[test]\n    #[cfg(target_pointer_width = \"32\")]\n    fn test_parse_obsolete_overflow_x32() {\n        assert_eq!(\n            obsolete(\"-42949672960\"),\n            obsolete_result(&[\"-n\", \"4294967295\"])\n        );\n        assert_eq!(\n            obsolete(\"-42949672k\"),\n            obsolete_result(&[\"-c\", \"4294967295\"])\n        );\n    }\n}",
      "file_name": "coreutils/src/uu\\head\\src\\parse.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n//! Take all but the last elements of an iterator.\nuse memchr::memchr_iter;\nuse std::collections::VecDeque;\nuse std::io::{ErrorKind, Read, Write};\nconst BUF_SIZE: usize = 65536;\nstruct TakeAllBuffer {\n    buffer: Vec<u8>,\n    start_index: usize,\n}\nimpl TakeAllBuffer {\n    fn new() -> Self {\n        TakeAllBuffer {\n            buffer: vec![],\n            start_index: 0,\n        }\n    }\n\n    fn fill_buffer(&mut self, reader: &mut impl Read) -> std::io::Result<usize> {\n        self.buffer.resize(BUF_SIZE, 0);\n        self.start_index = 0;\n        loop {\n            match reader.read(&mut self.buffer[..]) {\n                Ok(n) => {\n                    self.buffer.truncate(n);\n                    return Ok(n);\n                }\n                Err(e) if e.kind() == ErrorKind::Interrupted => continue,\n                Err(e) => return Err(e),\n            }\n        }\n    }\n\n    fn write_bytes_exact(&mut self, writer: &mut impl Write, bytes: usize) -> std::io::Result<()> {\n        let buffer_to_write = &self.remaining_buffer()[..bytes];\n        writer.write_all(buffer_to_write)?;\n        self.start_index += bytes;\n        assert!(self.start_index <= self.buffer.len());\n        Ok(())\n    }\n\n    fn write_all(&mut self, writer: &mut impl Write) -> std::io::Result<usize> {\n        let remaining_bytes = self.remaining_bytes();\n        self.write_bytes_exact(writer, remaining_bytes)?;\n        Ok(remaining_bytes)\n    }\n\n    fn write_bytes_limit(\n        &mut self,\n        writer: &mut impl Write,\n        max_bytes: usize,\n    ) -> std::io::Result<usize> {\n        let bytes_to_write = self.remaining_bytes().min(max_bytes);\n        self.write_bytes_exact(writer, bytes_to_write)?;\n        Ok(bytes_to_write)\n    }\n\n    fn remaining_buffer(&self) -> &[u8] {\n        &self.buffer[self.start_index..]\n    }\n\n    fn remaining_bytes(&self) -> usize {\n        self.remaining_buffer().len()\n    }\n\n    fn is_empty(&self) -> bool {\n        assert!(self.start_index <= self.buffer.len());\n        self.start_index == self.buffer.len()\n    }\n}\n/// Function to copy all but `n` bytes from the reader to the writer.\n///\n/// If `n` exceeds the number of bytes in the input file then nothing is copied.\n/// If no errors are encountered then the function returns the number of bytes\n/// copied.\n///\n/// Algorithm for this function is as follows...\n/// 1 - Chunks of the input file are read into a queue of TakeAllBuffer instances.\n///     Chunks are read until at least we have enough data to write out the entire contents of the\n///     first TakeAllBuffer in the queue whilst still retaining at least `n` bytes in the queue.\n///     If we hit EoF at any point, stop reading.\n/// 2 - Assess whether we managed to queue up greater-than `n` bytes. If not, we must be done, in\n///     which case break and return.\n/// 3 - Write either the full first buffer of data, or just enough bytes to get back down to having\n///     the required `n` bytes of data queued.\n/// 4 - Go back to (1).\npub fn copy_all_but_n_bytes(\n    reader: &mut impl Read,\n    writer: &mut impl Write,\n    n: usize,\n) -> std::io::Result<usize> {\n    let mut buffers: VecDeque<TakeAllBuffer> = VecDeque::new();\n    let mut empty_buffer_pool: Vec<TakeAllBuffer> = vec![];\n    let mut buffered_bytes: usize = 0;\n    let mut total_bytes_copied = 0;\n    loop {\n        loop {\n            // Try to buffer at least enough to write the entire first buffer.\n            let front_buffer = buffers.front();\n            if let Some(front_buffer) = front_buffer {\n                if buffered_bytes >= n + front_buffer.remaining_bytes() {\n                    break;\n                }\n            }\n            let mut new_buffer = empty_buffer_pool.pop().unwrap_or_else(TakeAllBuffer::new);\n            let filled_bytes = new_buffer.fill_buffer(reader)?;\n            if filled_bytes == 0 {\n                // filled_bytes==0 => Eof\n                break;\n            }\n            buffers.push_back(new_buffer);\n            buffered_bytes += filled_bytes;\n        }\n\n        // If we've got <=n bytes buffered here we have nothing left to do.\n        if buffered_bytes <= n {\n            break;\n        }\n\n        let excess_buffered_bytes = buffered_bytes - n;\n        // Since we have some data buffered, can assume we have >=1 buffer - i.e. safe to unwrap.\n        let front_buffer = buffers.front_mut().unwrap();\n        let bytes_written = front_buffer.write_bytes_limit(writer, excess_buffered_bytes)?;\n        buffered_bytes -= bytes_written;\n        total_bytes_copied += bytes_written;\n        // If the front buffer is empty (which it probably is), push it into the empty-buffer-pool.\n        if front_buffer.is_empty() {\n            empty_buffer_pool.push(buffers.pop_front().unwrap());\n        }\n    }\n    Ok(total_bytes_copied)\n}\nstruct TakeAllLinesBuffer {\n    inner: TakeAllBuffer,\n    terminated_lines: usize,\n    partial_line: bool,\n}\nstruct BytesAndLines {\n    bytes: usize,\n    terminated_lines: usize,\n}\nimpl TakeAllLinesBuffer {\n    fn new() -> Self {\n        TakeAllLinesBuffer {\n            inner: TakeAllBuffer::new(),\n            terminated_lines: 0,\n            partial_line: false,\n        }\n    }\n\n    fn fill_buffer(\n        &mut self,\n        reader: &mut impl Read,\n        separator: u8,\n    ) -> std::io::Result<BytesAndLines> {\n        let bytes_read = self.inner.fill_buffer(reader)?;\n        // Count the number of lines...\n        self.terminated_lines = memchr_iter(separator, self.inner.remaining_buffer()).count();\n        if let Some(last_char) = self.inner.remaining_buffer().last() {\n            if *last_char != separator {\n                self.partial_line = true;\n            }\n        }\n        Ok(BytesAndLines {\n            bytes: bytes_read,\n            terminated_lines: self.terminated_lines,\n        })\n    }\n\n    fn write_lines(\n        &mut self,\n        writer: &mut impl Write,\n        max_lines: usize,\n        separator: u8,\n    ) -> std::io::Result<BytesAndLines> {\n        assert!(max_lines > 0, \"Must request at least 1 line.\");\n        let ret;\n        if max_lines > self.terminated_lines {\n            ret = BytesAndLines {\n                bytes: self.inner.write_all(writer)?,\n                terminated_lines: self.terminated_lines,\n            };\n            self.terminated_lines = 0;\n        } else {\n            let index = memchr_iter(separator, self.inner.remaining_buffer()).nth(max_lines - 1);\n            assert!(\n                index.is_some(),\n                \"Somehow we're being asked to write more lines than we have, that's a bug in copy_all_but_lines.\"\n            );\n            let index = index.unwrap();\n            // index is the offset of the separator character, zero indexed. Need to add 1 to get the number\n            // of bytes to write.\n            let bytes_to_write = index + 1;\n            self.inner.write_bytes_exact(writer, bytes_to_write)?;\n            ret = BytesAndLines {\n                bytes: bytes_to_write,\n                terminated_lines: max_lines,\n            };\n            self.terminated_lines -= max_lines;\n        }\n        Ok(ret)\n    }\n\n    fn is_empty(&self) -> bool {\n        self.inner.is_empty()\n    }\n\n    fn terminated_lines(&self) -> usize {\n        self.terminated_lines\n    }\n\n    fn partial_line(&self) -> bool {\n        self.partial_line\n    }\n}\n/// Function to copy all but `n` lines from the reader to the writer.\n///\n/// Lines are inferred from the `separator` value passed in by the client.\n/// If `n` exceeds the number of lines in the input file then nothing is copied.\n/// The last line in the file is not required to end with a `separator` character.\n/// If no errors are encountered then they function returns the number of bytes\n/// copied.\n///\n/// Algorithm for this function is as follows...\n/// 1 - Chunks of the input file are read into a queue of TakeAllLinesBuffer instances.\n///     Chunks are read until at least we have enough lines that we can write out the entire\n///     contents of the first TakeAllLinesBuffer in the queue whilst still retaining at least\n///     `n` lines in the queue.\n///     If we hit EoF at any point, stop reading.\n/// 2 - Asses whether we managed to queue up greater-than `n` lines. If not, we must be done, in\n///     which case break and return.\n/// 3 - Write either the full first buffer of data, or just enough lines to get back down to\n///     having the required `n` lines of data queued.\n/// 4 - Go back to (1).\n///\n/// Note that lines will regularly straddle multiple TakeAllLinesBuffer instances. The partial_line\n/// flag on TakeAllLinesBuffer tracks this, and we use that to ensure that we write out enough\n/// lines in the case that the input file doesn't end with a `separator` character.\npub fn copy_all_but_n_lines<R: Read, W: Write>(\n    mut reader: R,\n    writer: &mut W,\n    n: usize,\n    separator: u8,\n) -> std::io::Result<usize> {\n    // This function requires `n` > 0. Assert it!\n    assert!(n > 0);\n    let mut buffers: VecDeque<TakeAllLinesBuffer> = VecDeque::new();\n    let mut buffered_terminated_lines: usize = 0;\n    let mut empty_buffers = vec![];\n    let mut total_bytes_copied = 0;\n    loop {\n        // Try to buffer enough such that we can write out the entire first buffer.\n        loop {\n            // First check if we have enough lines buffered that we can write out the entire\n            // front buffer. If so, break.\n            let front_buffer = buffers.front();\n            if let Some(front_buffer) = front_buffer {\n                if buffered_terminated_lines > n + front_buffer.terminated_lines() {\n                    break;\n                }\n            }\n            // Else we need to try to buffer more data...\n            let mut new_buffer = empty_buffers.pop().unwrap_or_else(TakeAllLinesBuffer::new);\n            let fill_result = new_buffer.fill_buffer(&mut reader, separator)?;\n            if fill_result.bytes == 0 {\n                // fill_result.bytes == 0 => EoF.\n                break;\n            }\n            buffered_terminated_lines += fill_result.terminated_lines;\n            buffers.push_back(new_buffer);\n        }\n\n        // If we've not buffered more lines than we need to hold back we must be done.\n        if buffered_terminated_lines < n\n            || (buffered_terminated_lines == n && !buffers.back().unwrap().partial_line())\n        {\n            break;\n        }\n\n        let excess_buffered_terminated_lines = buffered_terminated_lines - n;\n        // Since we have some data buffered can assume we have at least 1 buffer, so safe to unwrap.\n        let lines_to_write = if buffers.back().unwrap().partial_line() {\n            excess_buffered_terminated_lines + 1\n        } else {\n            excess_buffered_terminated_lines\n        };\n        let front_buffer = buffers.front_mut().unwrap();\n        let write_result = front_buffer.write_lines(writer, lines_to_write, separator)?;\n        buffered_terminated_lines -= write_result.terminated_lines;\n        total_bytes_copied += write_result.bytes;\n        // If the front buffer is empty (which it probably is), push it into the empty-buffer-pool.\n        if front_buffer.is_empty() {\n            empty_buffers.push(buffers.pop_front().unwrap());\n        }\n    }\n    Ok(total_bytes_copied)\n}",
      "file_name": "coreutils/src/uu\\head\\src\\take.rs"
    },
    {
      "chunk": "/// Like `std::io::Take`, but for lines instead of bytes.\n///\n/// This struct is generally created by calling [`take_lines`] on a\n/// reader. Please see the documentation of [`take_lines`] for more\n/// details.\npub struct TakeLines<T> {\n    inner: T,\n    limit: u64,\n    separator: u8,\n}\nimpl<T: Read> Read for TakeLines<T> {\n    /// Read bytes from a buffer up to the requested number of lines.\n    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {\n        if self.limit == 0 {\n            return Ok(0);\n        }\n        match self.inner.read(buf) {\n            Ok(0) => Ok(0),\n            Ok(n) => {\n                for i in memchr_iter(self.separator, &buf[..n]) {\n                    self.limit -= 1;\n                    if self.limit == 0 {\n                        return Ok(i + 1);\n                    }\n                }\n                Ok(n)\n            }\n            Err(e) => Err(e),\n        }\n    }\n}\n/// Create an adaptor that will read at most `limit` lines from a given reader.\n///\n/// This function returns a new instance of `Read` that will read at\n/// most `limit` lines, after which it will always return EOF\n/// (`Ok(0)`).\n///\n/// The `separator` defines the character to interpret as the line\n/// ending. For the usual notion of \"line\", set this to `b'\\n'`.\npub fn take_lines<R>(reader: R, limit: u64, separator: u8) -> TakeLines<R> {\n    TakeLines {\n        inner: reader,\n        limit,\n        separator,\n    }\n}\n#[cfg(test)]",
      "file_name": "coreutils/src/uu\\head\\src\\take.rs"
    },
    {
      "chunk": "mod tests {\n\n    use std::io::{BufRead, BufReader};\n\n    use crate::take::{\n        TakeAllBuffer, TakeAllLinesBuffer, copy_all_but_n_bytes, copy_all_but_n_lines, take_lines,\n    };\n\n    #[test]\n    fn test_take_all_buffer_exact_bytes() {\n        let input_buffer = \"abc\";\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut take_all_buffer = TakeAllBuffer::new();\n        let bytes_read = take_all_buffer.fill_buffer(&mut input_reader).unwrap();\n        assert_eq!(bytes_read, input_buffer.len());\n        assert_eq!(take_all_buffer.remaining_bytes(), input_buffer.len());\n        assert_eq!(take_all_buffer.remaining_buffer(), input_buffer.as_bytes());\n        assert!(!take_all_buffer.is_empty());\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        for (index, c) in input_buffer.bytes().enumerate() {\n            take_all_buffer\n                .write_bytes_exact(&mut output_reader, 1)\n                .unwrap();\n            let buf_ref = output_reader.get_ref();\n            assert_eq!(buf_ref.len(), index + 1);\n            assert_eq!(buf_ref[index], c);\n            assert_eq!(\n                take_all_buffer.remaining_bytes(),\n                input_buffer.len() - (index + 1)\n            );\n            assert_eq!(\n                take_all_buffer.remaining_buffer(),\n                &input_buffer.as_bytes()[index + 1..]\n            );\n        }\n\n        assert!(take_all_buffer.is_empty());\n        assert_eq!(take_all_buffer.remaining_bytes(), 0);\n        assert_eq!(take_all_buffer.remaining_buffer(), \"\".as_bytes());\n    }\n\n    #[test]\n    fn test_take_all_buffer_all_bytes() {\n        let input_buffer = \"abc\";\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut take_all_buffer = TakeAllBuffer::new();\n        let bytes_read = take_all_buffer.fill_buffer(&mut input_reader).unwrap();\n        assert_eq!(bytes_read, input_buffer.len());\n        assert_eq!(take_all_buffer.remaining_bytes(), input_buffer.len());\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_written = take_all_buffer.write_all(&mut output_reader).unwrap();\n        assert_eq!(bytes_written, input_buffer.len());\n        assert_eq!(output_reader.get_ref().as_slice(), input_buffer.as_bytes());\n\n        assert!(take_all_buffer.is_empty());\n        assert_eq!(take_all_buffer.remaining_bytes(), 0);\n        assert_eq!(take_all_buffer.remaining_buffer(), \"\".as_bytes());\n\n        // Now do a write_all on an empty TakeAllBuffer. Confirm correct behavior.\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_written = take_all_buffer.write_all(&mut output_reader).unwrap();\n        assert_eq!(bytes_written, 0);\n        assert_eq!(output_reader.get_ref().as_slice().len(), 0);\n    }\n\n    #[test]\n    fn test_take_all_buffer_limit_bytes() {\n        let input_buffer = \"abc\";\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut take_all_buffer = TakeAllBuffer::new();\n        let bytes_read = take_all_buffer.fill_buffer(&mut input_reader).unwrap();\n        assert_eq!(bytes_read, input_buffer.len());\n        assert_eq!(take_all_buffer.remaining_bytes(), input_buffer.len());\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        // Write all but 1 bytes.\n        let bytes_to_write = input_buffer.len() - 1;\n        let bytes_written = take_all_buffer\n            .write_bytes_limit(&mut output_reader, bytes_to_write)\n            .unwrap();\n        assert_eq!(bytes_written, bytes_to_write);\n        assert_eq!(\n            output_reader.get_ref().as_slice(),\n            &input_buffer.as_bytes()[..bytes_to_write]\n        );\n        assert!(!take_all_buffer.is_empty());\n        assert_eq!(take_all_buffer.remaining_bytes(), 1);\n        assert_eq!(\n            take_all_buffer.remaining_buffer(),\n            &input_buffer.as_bytes()[bytes_to_write..]\n        );\n\n        // Write 1 more byte - i.e. last byte in buffer.\n        let bytes_to_write = 1;\n        let bytes_written = take_all_buffer\n            .write_bytes_limit(&mut output_reader, bytes_to_write)\n            .unwrap();\n        assert_eq!(bytes_written, bytes_to_write);\n        assert_eq!(output_reader.get_ref().as_slice(), input_buffer.as_bytes());\n        assert!(take_all_buffer.is_empty());\n        assert_eq!(take_all_buffer.remaining_bytes(), 0);\n        assert_eq!(take_all_buffer.remaining_buffer(), \"\".as_bytes());\n\n        // Write 1 more byte - i.e. confirm behavior on already empty buffer.\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_to_write = 1;\n        let bytes_written = take_all_buffer\n            .write_bytes_limit(&mut output_reader, bytes_to_write)\n            .unwrap();\n        assert_eq!(bytes_written, 0);\n        assert_eq!(output_reader.get_ref().as_slice().len(), 0);\n        assert!(take_all_buffer.is_empty());\n        assert_eq!(take_all_buffer.remaining_bytes(), 0);\n        assert_eq!(take_all_buffer.remaining_buffer(), \"\".as_bytes());\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn test_take_all_lines_buffer() {\n        // 3 lines with new-lines and one partial line.\n        let input_buffer = \"a\\nb\\nc\\ndef\";\n        let separator = b'\\n';\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut take_all_lines_buffer = TakeAllLinesBuffer::new();\n        let fill_result = take_all_lines_buffer\n            .fill_buffer(&mut input_reader, separator)\n            .unwrap();\n        assert_eq!(fill_result.bytes, input_buffer.len());\n        assert_eq!(fill_result.terminated_lines, 3);\n        assert_eq!(take_all_lines_buffer.terminated_lines(), 3);\n        assert!(!take_all_lines_buffer.is_empty());\n        assert!(take_all_lines_buffer.partial_line());\n\n        // Write 1st line.\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let lines_to_write = 1;\n        let write_result = take_all_lines_buffer\n            .write_lines(&mut output_reader, lines_to_write, separator)\n            .unwrap();\n        assert_eq!(write_result.bytes, 2);\n        assert_eq!(write_result.terminated_lines, lines_to_write);\n        assert_eq!(output_reader.get_ref().as_slice(), \"a\\n\".as_bytes());\n        assert!(!take_all_lines_buffer.is_empty());\n        assert_eq!(take_all_lines_buffer.terminated_lines(), 2);\n\n        // Write 2nd line.\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let lines_to_write = 1;\n        let write_result = take_all_lines_buffer\n            .write_lines(&mut output_reader, lines_to_write, separator)\n            .unwrap();\n        assert_eq!(write_result.bytes, 2);\n        assert_eq!(write_result.terminated_lines, lines_to_write);\n        assert_eq!(output_reader.get_ref().as_slice(), \"b\\n\".as_bytes());\n        assert!(!take_all_lines_buffer.is_empty());\n        assert_eq!(take_all_lines_buffer.terminated_lines(), 1);\n\n        // Now try to write 3 lines even though we have only 1 line remaining. Should write everything left in the buffer.\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let lines_to_write = 3;\n        let write_result = take_all_lines_buffer\n            .write_lines(&mut output_reader, lines_to_write, separator)\n            .unwrap();\n        assert_eq!(write_result.bytes, 5);\n        assert_eq!(write_result.terminated_lines, 1);\n        assert_eq!(output_reader.get_ref().as_slice(), \"c\\ndef\".as_bytes());\n        assert!(take_all_lines_buffer.is_empty());\n        assert_eq!(take_all_lines_buffer.terminated_lines(), 0);\n\n        // Test empty buffer.\n        let input_buffer = \"\";\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut take_all_lines_buffer = TakeAllLinesBuffer::new();\n        let fill_result = take_all_lines_buffer\n            .fill_buffer(&mut input_reader, separator)\n            .unwrap();\n        assert_eq!(fill_result.bytes, 0);\n        assert_eq!(fill_result.terminated_lines, 0);\n        assert_eq!(take_all_lines_buffer.terminated_lines(), 0);\n        assert!(take_all_lines_buffer.is_empty());\n        assert!(!take_all_lines_buffer.partial_line());\n\n        // Test buffer that ends with newline.\n        let input_buffer = \"\\n\";\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut take_all_lines_buffer = TakeAllLinesBuffer::new();\n        let fill_result = take_all_lines_buffer\n            .fill_buffer(&mut input_reader, separator)\n            .unwrap();\n        assert_eq!(fill_result.bytes, 1);\n        assert_eq!(fill_result.terminated_lines, 1);\n        assert_eq!(take_all_lines_buffer.terminated_lines(), 1);\n        assert!(!take_all_lines_buffer.is_empty());\n        assert!(!take_all_lines_buffer.partial_line());\n    }\n\n    #[test]\n    fn test_copy_all_but_n_bytes() {\n        // Test the copy_all_but_bytes fn. Test several scenarios...\n        // 1 - Hold back more bytes than the input will provide. Should have nothing written to output.\n        let input_buffer = \"a\\nb\\nc\\ndef\";\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied = copy_all_but_n_bytes(\n            &mut input_reader,\n            &mut output_reader,\n            input_buffer.len() + 1,\n        )\n        .unwrap();\n        assert_eq!(bytes_copied, 0);\n\n        // 2 - Hold back exactly the number of bytes the input will provide. Should have nothing written to output.\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied =\n            copy_all_but_n_bytes(&mut input_reader, &mut output_reader, input_buffer.len())\n                .unwrap();\n        assert_eq!(bytes_copied, 0);\n\n        // 3 - Hold back 1 fewer byte than input will provide. Should have one byte written to output.\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied = copy_all_but_n_bytes(\n            &mut input_reader,\n            &mut output_reader,\n            input_buffer.len() - 1,\n        )\n        .unwrap();\n        assert_eq!(bytes_copied, 1);\n        assert_eq!(output_reader.get_ref()[..], input_buffer.as_bytes()[0..1]);\n    }\n\n    #[test]\n    fn test_copy_all_but_n_lines() {\n        // Test the copy_all_but_lines fn. Test several scenarios...\n        // 1 - Hold back more lines than the input will provide. Should have nothing written to output.\n        let input_buffer = \"a\\nb\\nc\\ndef\";\n        let separator = b'\\n';\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied =\n            copy_all_but_n_lines(&mut input_reader, &mut output_reader, 5, separator).unwrap();\n        assert_eq!(bytes_copied, 0);\n\n        // 2 - Hold back exactly the number of lines the input will provide. Should have nothing written to output.\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied =\n            copy_all_but_n_lines(&mut input_reader, &mut output_reader, 4, separator).unwrap();\n        assert_eq!(bytes_copied, 0);\n\n        // 3 - Hold back 1 fewer lines than input will provide. Should have one line written to output.\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied =\n            copy_all_but_n_lines(&mut input_reader, &mut output_reader, 3, separator).unwrap();\n        assert_eq!(bytes_copied, 2);\n        assert_eq!(output_reader.get_ref()[..], input_buffer.as_bytes()[0..2]);\n\n        // Now test again with an input that has a new-line ending...\n        // 4 - Hold back more lines than the input will provide. Should have nothing written to output.\n        let input_buffer = \"a\\nb\\nc\\ndef\\n\";\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied =\n            copy_all_but_n_lines(&mut input_reader, &mut output_reader, 5, separator).unwrap();\n        assert_eq!(bytes_copied, 0);\n\n        // 5 - Hold back exactly the number of lines the input will provide. Should have nothing written to output.\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied =\n            copy_all_but_n_lines(&mut input_reader, &mut output_reader, 4, separator).unwrap();\n        assert_eq!(bytes_copied, 0);\n\n        // 6 - Hold back 1 fewer lines than input will provide. Should have one line written to output.\n        let mut input_reader = std::io::Cursor::new(input_buffer);\n        let mut output_reader = std::io::Cursor::new(vec![0x10; 0]);\n        let bytes_copied =\n            copy_all_but_n_lines(&mut input_reader, &mut output_reader, 3, separator).unwrap();\n        assert_eq!(bytes_copied, 2);\n        assert_eq!(output_reader.get_ref()[..], input_buffer.as_bytes()[0..2]);\n    }\n\n    #[test]\n    fn test_zero_lines() {\n        let input_reader = std::io::Cursor::new(\"a\\nb\\nc\\n\");\n        let output_reader = BufReader::new(take_lines(input_reader, 0, b'\\n'));\n        let mut iter = output_reader.lines().map(|l| l.unwrap());\n        assert_eq!(None, iter.next());\n    }\n\n    #[test]\n    fn test_fewer_lines() {\n        let input_reader = std::io::Cursor::new(\"a\\nb\\nc\\n\");\n        let output_reader = BufReader::new(take_lines(input_reader, 2, b'\\n'));\n        let mut iter = output_reader.lines().map(|l| l.unwrap());\n        assert_eq!(Some(String::from(\"a\")), iter.next());\n        assert_eq!(Some(String::from(\"b\")), iter.next());\n        assert_eq!(None, iter.next());\n    }",
      "file_name": "coreutils/src/uu\\head\\src\\take.rs"
    },
    {
      "chunk": "\n    #[test]\n    fn test_more_lines() {\n        let input_reader = std::io::Cursor::new(\"a\\nb\\nc\\n\");\n        let output_reader = BufReader::new(take_lines(input_reader, 4, b'\\n'));\n        let mut iter = output_reader.lines().map(|l| l.unwrap());\n        assert_eq!(Some(String::from(\"a\")), iter.next());\n        assert_eq!(Some(String::from(\"b\")), iter.next());\n        assert_eq!(Some(String::from(\"c\")), iter.next());\n        assert_eq!(None, iter.next());\n    }\n}",
      "file_name": "coreutils/src/uu\\head\\src\\take.rs"
    }
  ],
  "pwd": [
    {
      "chunk": "uucore::bin!(uu_pwd);",
      "file_name": "coreutils/src/uu\\pwd\\src\\main.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nuse clap::ArgAction;\nuse clap::{Arg, Command};\nuse std::env;\nuse std::io;\nuse std::path::PathBuf;\nuse uucore::{format_usage, help_about, help_usage};\nuse uucore::display::println_verbatim;\nuse uucore::error::{FromIo, UResult};\nconst ABOUT: &str = help_about!(\"pwd.md\");\nconst USAGE: &str = help_usage!(\"pwd.md\");\nconst OPT_LOGICAL: &str = \"logical\";\nconst OPT_PHYSICAL: &str = \"physical\";\nfn physical_path() -> io::Result<PathBuf> {\n    // std::env::current_dir() is a thin wrapper around libc::getcwd().\n\n    // On Unix, getcwd() must return the physical path:\n    // https://pubs.opengroup.org/onlinepubs/9699919799/functions/getcwd.html\n    #[cfg(unix)]\n    {\n        env::current_dir()\n    }\n\n    // On Windows we have to resolve it.\n    // On other systems we also resolve it, just in case.\n    #[cfg(not(unix))]\n    {\n        env::current_dir().and_then(|path| path.canonicalize())\n    }\n}\nfn logical_path() -> io::Result<PathBuf> {\n    // getcwd() on Windows seems to include symlinks, so this is easy.\n    #[cfg(windows)]\n    {\n        env::current_dir()\n    }\n\n    // If we're not on Windows we do things Unix-style.\n    //\n    // Typical Unix-like kernels don't actually keep track of the logical working\n    // directory. They know the precise directory a process is in, and the getcwd()\n    // syscall reconstructs a path from that.\n    //\n    // The logical working directory is maintained by the shell, in the $PWD\n    // environment variable. So we check carefully if that variable looks\n    // reasonable, and if not then we fall back to the physical path.\n    //\n    // POSIX: https://pubs.opengroup.org/onlinepubs/9699919799/utilities/pwd.html\n    #[cfg(not(windows))]\n    {\n        use std::path::Path;\n        fn looks_reasonable(path: &Path) -> bool {\n            // First, check if it's an absolute path.\n            if !path.has_root() {\n                return false;\n            }\n\n            // Then, make sure there are no . or .. components.\n            // Path::components() isn't useful here, it normalizes those out.\n\n            // to_string_lossy() may allocate, but that's fine, we call this\n            // only once per run. It may also lose information, but not any\n            // information that we need for this check.\n            if path\n                .to_string_lossy()\n                .split(std::path::is_separator)\n                .any(|piece| piece == \".\" || piece == \"..\")\n            {\n                return false;\n            }\n\n            // Finally, check if it matches the directory we're in.\n            #[cfg(unix)]\n            {\n                use std::fs::metadata;\n                use std::os::unix::fs::MetadataExt;\n                match (metadata(path), metadata(\".\")) {\n                    (Ok(info1), Ok(info2)) => {\n                        info1.dev() == info2.dev() && info1.ino() == info2.ino()\n                    }\n                    _ => false,\n                }\n            }\n\n            #[cfg(not(unix))]\n            {\n                use std::fs::canonicalize;\n                match (canonicalize(path), canonicalize(\".\")) {\n                    (Ok(path1), Ok(path2)) => path1 == path2,\n                    _ => false,\n                }\n            }\n        }\n\n        match env::var_os(\"PWD\").map(PathBuf::from) {\n            Some(value) if looks_reasonable(&value) => Ok(value),\n            _ => env::current_dir(),\n        }\n    }\n}\n#[uucore::main]\npub fn uumain(args: impl uucore::Args) -> UResult<()> {\n    let matches = uu_app().try_get_matches_from(args)?;\n    // if POSIXLY_CORRECT is set, we want to a logical resolution.\n    // This produces a different output when doing mkdir -p a/b && ln -s a/b c && cd c && pwd\n    // We should get c in this case instead of a/b at the end of the path\n    let cwd = if matches.get_flag(OPT_PHYSICAL) {\n        physical_path()\n    } else if matches.get_flag(OPT_LOGICAL) || env::var(\"POSIXLY_CORRECT\").is_ok() {\n        logical_path()\n    } else {\n        physical_path()\n    }\n    .map_err_context(|| \"failed to get current directory\".to_owned())?;\n\n    // \\\\?\\ is a prefix Windows gives to paths under certain circumstances,\n    // including when canonicalizing them.\n    // With the right extension trait we can remove it non-lossily, but\n    // we print it lossily anyway, so no reason to bother.\n    #[cfg(windows)]\n    let cwd = cwd\n        .to_string_lossy()\n        .strip_prefix(r\"\\\\?\\\")\n        .map(Into::into)\n        .unwrap_or(cwd);\n\n    println_verbatim(cwd).map_err_context(|| \"failed to print current directory\".to_owned())?;\n\n    Ok(())\n}\npub fn uu_app() -> Command {\n    Command::new(uucore::util_name())\n        .version(uucore::crate_version!())\n        .about(ABOUT)\n        .override_usage(format_usage(USAGE))\n        .infer_long_args(true)\n        .arg(\n            Arg::new(OPT_LOGICAL)\n                .short('L')\n                .long(OPT_LOGICAL)\n                .help(\"use PWD from environment, even if it contains symlinks\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(OPT_PHYSICAL)\n                .short('P')\n                .long(OPT_PHYSICAL)\n                .overrides_with(OPT_LOGICAL)\n                .help(\"avoid all symlinks\")\n                .action(ArgAction::SetTrue),\n        )\n}",
      "file_name": "coreutils/src/uu\\pwd\\src\\pwd.rs"
    }
  ],
  "split": [
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore zaaa zaab stype\n//! Compute filenames from a given index.\n//!\n//! The [`FilenameIterator`] yields filenames for use with ``split``.\n//!\n//! # Examples\n//!\n//! Create filenames of the form `chunk_??.txt`:\n//!\n//! ```rust,ignore\n//! use crate::filenames::FilenameIterator;\n//! use crate::filenames::SuffixType;\n//!\n//! let prefix = \"chunk_\".to_string();\n//! let suffix = Suffix {\n//!     stype: SuffixType::Alphabetic,\n//!     length: 2,\n//!     start: 0,\n//!     auto_widening: true,\n//!     additional: \".txt\".to_string(),\n//! };\n//! let it = FilenameIterator::new(prefix, suffix);\n//!\n//! assert_eq!(it.next().unwrap(), \"chunk_aa.txt\");\n//! assert_eq!(it.next().unwrap(), \"chunk_ab.txt\");\n//! assert_eq!(it.next().unwrap(), \"chunk_ac.txt\");\n//! ```\nuse crate::number::DynamicWidthNumber;\nuse crate::number::FixedWidthNumber;\nuse crate::number::Number;\nuse crate::strategy::Strategy;\nuse crate::{\n    OPT_ADDITIONAL_SUFFIX, OPT_HEX_SUFFIXES, OPT_HEX_SUFFIXES_SHORT, OPT_NUMERIC_SUFFIXES,\n    OPT_NUMERIC_SUFFIXES_SHORT, OPT_SUFFIX_LENGTH,\n};\nuse clap::ArgMatches;\nuse std::path::is_separator;\nuse thiserror::Error;\nuse uucore::display::Quotable;\nuse uucore::error::{UResult, USimpleError};\n/// The format to use for suffixes in the filename for each output chunk.\n#[derive(Clone, Copy)]\npub enum SuffixType {\n    /// Lowercase ASCII alphabetic characters.\n    Alphabetic,\n\n    /// Decimal numbers.\n    Decimal,\n\n    /// Hexadecimal numbers.\n    Hexadecimal,\n}\nimpl SuffixType {\n    /// The radix to use when representing the suffix string as digits.\n    pub fn radix(&self) -> u8 {\n        match self {\n            Self::Alphabetic => 26,\n            Self::Decimal => 10,\n            Self::Hexadecimal => 16,\n        }\n    }\n}\n/// Filename suffix parameters\n#[derive(Clone)]\npub struct Suffix {\n    stype: SuffixType,\n    length: usize,\n    start: usize,\n    auto_widening: bool,\n    additional: String,\n}\n/// An error when parsing suffix parameters from command-line arguments.\n#[derive(Debug, Error)]\npub enum SuffixError {\n    /// Invalid suffix length parameter.\n    #[error(\"invalid suffix length: {}\", .0.quote())]\n    NotParsable(String),\n\n    /// Suffix contains a directory separator, which is not allowed.\n    #[error(\"invalid suffix {}, contains directory separator\", .0.quote())]\n    ContainsSeparator(String),\n\n    /// Suffix is not large enough to split into specified chunks\n    #[error(\"the suffix length needs to be at least {0}\")]\n    TooSmall(usize),\n}\nimpl Suffix {\n    /// Parse the suffix type, start, length and additional suffix from the command-line arguments\n    /// as well process suffix length auto-widening and auto-width scenarios\n    ///\n    /// Suffix auto-widening: Determine if the output file names suffix is allowed to dynamically auto-widen,\n    /// i.e. change (increase) suffix length dynamically as more files need to be written into.\n    /// Suffix length auto-widening rules are (in the order they are applied):\n    /// - ON by default\n    /// - OFF when suffix start N is specified via long option with a value\n    ///   `--numeric-suffixes=N` or `--hex-suffixes=N`\n    /// - OFF when suffix length N is specified, except for N=0 (see edge cases below)\n    ///   `-a N` or `--suffix-length=N`\n    /// - OFF if suffix length is auto pre-calculated (auto-width)\n    ///\n    /// Suffix auto-width: Determine if the the output file names suffix length should be automatically pre-calculated\n    /// based on number of files that need to written into, having number of files known upfront\n    /// Suffix length auto pre-calculation rules:\n    /// - Pre-calculate new suffix length when `-n`/`--number` option (N, K/N, l/N, l/K/N, r/N, r/K/N)\n    ///   is used, where N is number of chunks = number of files to write into\n    ///   and suffix start < N number of files\n    ///   as in `split --numeric-suffixes=1 --number=r/100 file`\n    /// - Do NOT pre-calculate new suffix length otherwise, i.e. when\n    ///   suffix start >= N number of files\n    ///   as in `split --numeric-suffixes=100 --number=r/100 file`\n    ///   OR when suffix length N is specified, except for N=0 (see edge cases below)\n    ///   `-a N` or `--suffix-length=N`\n    ///\n    /// Edge case:\n    /// - If suffix length is specified as 0 in a command line,\n    ///   first apply auto-width calculations and if still 0\n    ///   set it to default value.\n    ///   Do NOT change auto-widening value\n    ///\n    pub fn from(matches: &ArgMatches, strategy: &Strategy) -> Result<Self, SuffixError> {\n        let stype: SuffixType;\n\n        // Defaults\n        let mut start = 0;\n        let mut auto_widening = true;\n        let default_length: usize = 2;\n\n        // Check if the user is specifying one or more than one suffix\n        // Any combination of suffixes is allowed\n        // Since all suffixes are setup with 'overrides_with_all()' against themselves and each other,\n        // last one wins, all others are ignored\n        match (\n            matches.contains_id(OPT_NUMERIC_SUFFIXES),\n            matches.contains_id(OPT_HEX_SUFFIXES),\n            matches.get_flag(OPT_NUMERIC_SUFFIXES_SHORT),\n            matches.get_flag(OPT_HEX_SUFFIXES_SHORT),\n        ) {\n            (true, _, _, _) => {\n                stype = SuffixType::Decimal;\n                // if option was specified, but without value - this will return None as there is no default value\n                if let Some(opt) = matches.get_one::<String>(OPT_NUMERIC_SUFFIXES) {\n                    start = opt\n                        .parse::<usize>()\n                        .map_err(|_| SuffixError::NotParsable(opt.to_string()))?;\n                    auto_widening = false;\n                }\n            }\n            (_, true, _, _) => {\n                stype = SuffixType::Hexadecimal;\n                // if option was specified, but without value - this will return None as there is no default value\n                if let Some(opt) = matches.get_one::<String>(OPT_HEX_SUFFIXES) {\n                    start = usize::from_str_radix(opt, 16)\n                        .map_err(|_| SuffixError::NotParsable(opt.to_string()))?;\n                    auto_widening = false;\n                }\n            }\n            (_, _, true, _) => stype = SuffixType::Decimal, // short numeric suffix '-d'\n            (_, _, _, true) => stype = SuffixType::Hexadecimal, // short hex suffix '-x'\n            _ => stype = SuffixType::Alphabetic, // no numeric/hex suffix, using default alphabetic\n        }\n\n        // Get suffix length and a flag to indicate if it was specified with command line option\n        let (mut length, is_length_cmd_opt) =\n            if let Some(v) = matches.get_one::<String>(OPT_SUFFIX_LENGTH) {\n                // suffix length was specified in command line\n                (\n                    v.parse::<usize>()\n                        .map_err(|_| SuffixError::NotParsable(v.to_string()))?,\n                    true,\n                )\n            } else {\n                // no suffix length option was specified in command line\n                // set to default value\n                (default_length, false)\n            };\n\n        // Disable dynamic auto-widening if suffix length was specified in command line with value > 0\n        if is_length_cmd_opt && length > 0 {\n            auto_widening = false;\n        }\n\n        // Auto pre-calculate new suffix length (auto-width) if necessary\n        if let Strategy::Number(number_type) = strategy {\n            let chunks = number_type.num_chunks();\n            let required_length = ((start as u64 + chunks) as f64)\n                .log(stype.radix() as f64)\n                .ceil() as usize;\n\n            if (start as u64) < chunks && !(is_length_cmd_opt && length > 0) {\n                // with auto-width ON the auto-widening is OFF\n                auto_widening = false;\n\n                // do not reduce suffix length with auto-width\n                if length < required_length {\n                    length = required_length;\n                }\n            }\n\n            if length < required_length {\n                return Err(SuffixError::TooSmall(required_length));\n            }\n        }\n\n        // Check edge case when suffix length == 0 was specified in command line\n        // Set it to default value\n        if is_length_cmd_opt && length == 0 {\n            length = default_length;\n        }\n\n        let additional = matches\n            .get_one::<String>(OPT_ADDITIONAL_SUFFIX)\n            .unwrap()\n            .to_string();\n        if additional.chars().any(is_separator) {\n            return Err(SuffixError::ContainsSeparator(additional));\n        }\n\n        let result = Self {\n            stype,\n            length,\n            start,\n            auto_widening,\n            additional,\n        };\n\n        Ok(result)\n    }\n}\n/// Compute filenames from a given index.\n///\n/// This iterator yields filenames for use with ``split``.\n///\n/// The `prefix` is prepended to each filename and the\n/// `suffix.additional` is appended to each filename.\n///\n/// If `suffix.auto_widening` is true, then the variable portion of the filename\n/// that identifies the current chunk will have a dynamically\n/// increasing width. If `suffix.auto_widening` is false, then\n/// the variable portion of the filename will always be exactly `suffix.length`\n/// width in characters. In that case, after the iterator yields each\n/// string of that width, the iterator is exhausted.\n///\n/// Finally, `suffix.stype` controls which type of suffix to produce,\n/// alphabetic or numeric.\n///\n/// # Examples\n///\n/// Create filenames of the form `chunk_??.txt`, where the `?`\n/// characters are lowercase ASCII alphabetic characters:\n///\n/// ```rust,ignore\n/// use crate::filenames::FilenameIterator;\n/// use crate::filenames::SuffixType;\n///\n/// let prefix = \"chunk_\".to_string();\n/// let suffix = Suffix {\n///     stype: SuffixType::Alphabetic,\n///     length: 2,\n///     start: 0,\n///     auto_widening: true,\n///     additional: \".txt\".to_string(),\n/// };\n/// let it = FilenameIterator::new(prefix, suffix);\n///\n/// assert_eq!(it.next().unwrap(), \"chunk_aa.txt\");\n/// assert_eq!(it.next().unwrap(), \"chunk_ab.txt\");\n/// assert_eq!(it.next().unwrap(), \"chunk_ac.txt\");\n/// ```\n///\n/// For decimal numeric filenames, use `SuffixType::Decimal`:\n///\n/// ```rust,ignore\n/// use crate::filenames::FilenameIterator;\n/// use crate::filenames::SuffixType;\n///\n/// let prefix = \"chunk_\".to_string();\n/// let suffix = Suffix {\n///     stype: SuffixType::Decimal,\n///     length: 2,\n///     start: 0,\n///     auto_widening: true,\n///     additional: \".txt\".to_string(),\n/// };\n/// let it = FilenameIterator::new(prefix, suffix);\n///\n/// assert_eq!(it.next().unwrap(), \"chunk_00.txt\");\n/// assert_eq!(it.next().unwrap(), \"chunk_01.txt\");\n/// assert_eq!(it.next().unwrap(), \"chunk_02.txt\");\n/// ```\npub struct FilenameIterator<'a> {\n    prefix: &'a str,\n    additional_suffix: &'a str,\n    number: Number,\n    first_iteration: bool,\n}",
      "file_name": "coreutils/src/uu\\split\\src\\filenames.rs"
    },
    {
      "chunk": "impl<'a> FilenameIterator<'a> {\n    pub fn new(prefix: &'a str, suffix: &'a Suffix) -> UResult<Self> {\n        let radix = suffix.stype.radix();\n        let number = if suffix.auto_widening {\n            Number::DynamicWidth(DynamicWidthNumber::new(radix, suffix.start))\n        } else {\n            Number::FixedWidth(\n                FixedWidthNumber::new(radix, suffix.length, suffix.start).map_err(|_| {\n                    USimpleError::new(\n                        1,\n                        \"numerical suffix start value is too large for the suffix length\",\n                    )\n                })?,\n            )\n        };\n        let additional_suffix = suffix.additional.as_str();\n\n        Ok(FilenameIterator {\n            prefix,\n            additional_suffix,\n            number,\n            first_iteration: true,\n        })\n    }\n}\nimpl Iterator for FilenameIterator<'_> {\n    type Item = String;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        if self.first_iteration {\n            self.first_iteration = false;\n        } else {\n            self.number.increment().ok()?;\n        }\n        // The first and third parts are just taken directly from the\n        // struct parameters unchanged.\n        Some(format!(\n            \"{}{}{}\",\n            self.prefix, self.number, self.additional_suffix\n        ))\n    }\n}\n#[cfg(test)]\nmod tests {\n\n    use crate::filenames::FilenameIterator;\n    use crate::filenames::Suffix;\n    use crate::filenames::SuffixType;\n\n    #[test]\n    fn test_filename_iterator_alphabetic_fixed_width() {\n        let suffix = Suffix {\n            stype: SuffixType::Alphabetic,\n            length: 2,\n            start: 0,\n            auto_widening: false,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_aa.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_ab.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_ac.txt\");\n\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.nth(26 * 26 - 1).unwrap(), \"chunk_zz.txt\");\n        assert_eq!(it.next(), None);\n    }\n\n    #[test]\n    fn test_filename_iterator_numeric_fixed_width() {\n        let suffix = Suffix {\n            stype: SuffixType::Decimal,\n            length: 2,\n            start: 0,\n            auto_widening: false,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_00.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_01.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_02.txt\");\n\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.nth(10 * 10 - 1).unwrap(), \"chunk_99.txt\");\n        assert_eq!(it.next(), None);\n    }\n\n    #[test]\n    fn test_filename_iterator_alphabetic_dynamic_width() {\n        let suffix = Suffix {\n            stype: SuffixType::Alphabetic,\n            length: 2,\n            start: 0,\n            auto_widening: true,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_aa.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_ab.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_ac.txt\");\n\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.nth(26 * 25 - 1).unwrap(), \"chunk_yz.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_zaaa.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_zaab.txt\");\n    }\n\n    #[test]\n    fn test_filename_iterator_numeric_dynamic_width() {\n        let suffix = Suffix {\n            stype: SuffixType::Decimal,\n            length: 2,\n            start: 0,\n            auto_widening: true,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_00.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_01.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_02.txt\");\n\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.nth(10 * 9 - 1).unwrap(), \"chunk_89.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_9000.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_9001.txt\");\n    }\n\n    #[test]\n    fn test_filename_iterator_numeric_decimal() {\n        let suffix = Suffix {\n            stype: SuffixType::Decimal,\n            length: 2,\n            start: 5,\n            auto_widening: true,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_05.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_06.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_07.txt\");\n    }\n\n    #[test]\n    fn test_filename_iterator_numeric_hex() {\n        let suffix = Suffix {\n            stype: SuffixType::Hexadecimal,\n            length: 2,\n            start: 9,\n            auto_widening: true,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_09.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_0a.txt\");\n        assert_eq!(it.next().unwrap(), \"chunk_0b.txt\");\n    }\n\n    #[test]\n    fn test_filename_iterator_numeric_err() {\n        let suffix = Suffix {\n            stype: SuffixType::Decimal,\n            length: 3,\n            start: 999,\n            auto_widening: false,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_999.txt\");\n        assert!(it.next().is_none());\n\n        let suffix = Suffix {\n            stype: SuffixType::Decimal,\n            length: 3,\n            start: 1000,\n            auto_widening: false,\n            additional: \".txt\".to_string(),\n        };\n        let it = FilenameIterator::new(\"chunk_\", &suffix);\n        assert!(it.is_err());\n\n        let suffix = Suffix {\n            stype: SuffixType::Hexadecimal,\n            length: 3,\n            start: 0xfff,\n            auto_widening: false,\n            additional: \".txt\".to_string(),\n        };\n        let mut it = FilenameIterator::new(\"chunk_\", &suffix).unwrap();\n        assert_eq!(it.next().unwrap(), \"chunk_fff.txt\");\n        assert!(it.next().is_none());\n\n        let suffix = Suffix {\n            stype: SuffixType::Hexadecimal,\n            length: 3,\n            start: 0x1000,\n            auto_widening: false,\n            additional: \".txt\".to_string(),\n        };\n        let it = FilenameIterator::new(\"chunk_\", &suffix);\n        assert!(it.is_err());\n    }\n}",
      "file_name": "coreutils/src/uu\\split\\src\\filenames.rs"
    },
    {
      "chunk": "uucore::bin!(uu_split);",
      "file_name": "coreutils/src/uu\\split\\src\\main.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore zaaa zaab feff\n//! A number in arbitrary radix expressed in a positional notation.\n//!\n//! Use the [`Number`] enum to represent an arbitrary number in an\n//! arbitrary radix. A number can be incremented and can be\n//! displayed. See the [`Number`] documentation for more information.\n//!\n//! See the Wikipedia articles on [radix] and [positional notation]\n//! for more background information on those topics.\n//!\n//! [radix]: https://en.wikipedia.org/wiki/Radix\n//! [positional notation]: https://en.wikipedia.org/wiki/Positional_notation\nuse std::error::Error;\nuse std::fmt::{self, Display, Formatter};\n/// An overflow due to incrementing a number beyond its representable limit.\n#[derive(Debug)]\npub struct Overflow;\nimpl Display for Overflow {\n    fn fmt(&self, f: &mut Formatter) -> fmt::Result {\n        write!(f, \"Overflow\")\n    }\n}\nimpl Error for Overflow {}\n/// A number in arbitrary radix expressed in a positional notation.\n///\n/// Use the [`Number`] enum to represent an arbitrary number in an\n/// arbitrary radix. A number can be incremented with\n/// [`Number::increment`].  The [`FixedWidthNumber`] overflows when\n/// attempting to increment it beyond the maximum number that can be\n/// represented in the specified width. The [`DynamicWidthNumber`]\n/// follows a non-standard incrementing procedure that is used\n/// specifically for the `split` program. See the\n/// [`DynamicWidthNumber`] documentation for more information.\n///\n/// Numbers of radix\n///\n/// * 10 are displayable and rendered as decimal numbers (for example,\n///   \"00\" or \"917\"),\n/// * 16 are displayable and rendered as hexadecimal numbers (for example,\n///   \"00\" or \"e7f\"),\n/// * 26 are displayable and rendered as lowercase ASCII alphabetic\n///   characters (for example, \"aa\" or \"zax\").\n///\n/// Numbers of other radices cannot be displayed. The display of a\n/// [`DynamicWidthNumber`] includes a prefix whose length depends on\n/// the width of the number. See the [`DynamicWidthNumber`]\n/// documentation for more information.\n///\n/// The digits of a number are accessible via the [`Number::digits`]\n/// method. The digits are represented as a [`Vec<u8>`] with the most\n/// significant digit on the left and the least significant digit on\n/// the right. Each digit is a nonnegative integer less than the\n/// radix. For example, if the radix is 3, then `vec![1, 0, 2]`\n/// represents the decimal number 11:\n///\n/// ```ignore\n/// 1 * 3^2 + 0 * 3^1 + 2 * 3^0 = 9 + 0 + 2 = 11\n/// ```\n///\n/// For the [`DynamicWidthNumber`], the digits are not unique in the\n/// sense that repeatedly incrementing the number will eventually\n/// yield `vec![0, 0]`, `vec![0, 0, 0]`, `vec![0, 0, 0, 0]`, etc.\n/// That's okay because each of these numbers will be displayed\n/// differently and we only intend to use these numbers for display\n/// purposes and not for mathematical purposes.\n#[derive(Clone)]\npub enum Number {\n    /// A fixed-width representation of a number.\n    FixedWidth(FixedWidthNumber),\n\n    /// A representation of a number with a dynamically growing width.\n    DynamicWidth(DynamicWidthNumber),\n}\nimpl Number {\n    /// The digits of this number in decreasing order of significance.\n    ///\n    /// The digits are represented as a [`Vec<u8>`] with the most\n    /// significant digit on the left and the least significant digit\n    /// on the right. Each digit is a nonnegative integer less than\n    /// the radix. For example, if the radix is 3, then `vec![1, 0,\n    /// 2]` represents the decimal number 11:\n    ///\n    /// ```ignore\n    /// 1 * 3^2 + 0 * 3^1 + 2 * 3^0 = 9 + 0 + 2 = 11\n    /// ```\n    ///\n    /// For the [`DynamicWidthNumber`], the digits are not unique in the\n    /// sense that repeatedly incrementing the number will eventually\n    /// yield `vec![0, 0]`, `vec![0, 0, 0]`, `vec![0, 0, 0, 0]`, etc.\n    /// That's okay because each of these numbers will be displayed\n    /// differently and we only intend to use these numbers for display\n    /// purposes and not for mathematical purposes.\n    #[allow(dead_code)]\n    fn digits(&self) -> Vec<u8> {\n        match self {\n            Self::FixedWidth(number) => number.digits.clone(),\n            Self::DynamicWidth(number) => number.digits(),\n        }\n    }\n\n    /// Increment this number to its successor.\n    ///\n    /// If incrementing this number would result in an overflow beyond\n    /// the maximum representable number, then return\n    /// [`Err(Overflow)`]. The [`FixedWidthNumber`] overflows, but\n    /// [`DynamicWidthNumber`] does not.\n    ///\n    /// The [`DynamicWidthNumber`] follows a non-standard incrementing\n    /// procedure that is used specifically for the `split` program.\n    /// See the [`DynamicWidthNumber`] documentation for more\n    /// information.\n    ///\n    /// # Errors\n    ///\n    /// This method returns [`Err(Overflow)`] when attempting to\n    /// increment beyond the largest representable number.\n    ///\n    /// # Examples\n    ///\n    /// Overflowing:\n    ///\n    /// ```rust,ignore\n    ///\n    /// use crate::number::FixedWidthNumber;\n    /// use crate::number::Number;\n    /// use crate::number::Overflow;\n    ///\n    /// // Radix 3, width of 1 digit.\n    /// let mut number = Number::FixedWidth(FixedWidthNumber::new(3, 1));\n    /// number.increment().unwrap();  // from 0 to 1\n    /// number.increment().unwrap();  // from 1 to 2\n    /// assert!(number.increment().is_err());\n    /// ```\n    pub fn increment(&mut self) -> Result<(), Overflow> {\n        match self {\n            Self::FixedWidth(number) => number.increment(),\n            Self::DynamicWidth(number) => number.increment(),\n        }\n    }\n}\nimpl Display for Number {\n    fn fmt(&self, f: &mut Formatter) -> fmt::Result {\n        match self {\n            Self::FixedWidth(number) => number.fmt(f),\n            Self::DynamicWidth(number) => number.fmt(f),\n        }\n    }\n}\n/// A positional notation representation of a fixed-width number.\n///\n/// The digits are represented as a [`Vec<u8>`] with the most\n/// significant digit on the left and the least significant digit on\n/// the right. Each digit is a nonnegative integer less than the\n/// radix.\n///\n/// # Incrementing\n///\n/// This number starts at `vec![0; width]`, representing the number 0\n/// width the specified number of digits. Incrementing this number\n/// with [`Number::increment`] causes it to increase its value by 1 in\n/// the usual sense. If the digits are `vec![radix - 1; width]`, then\n/// an overflow would occur and the [`Number::increment`] method\n/// returns an error.\n///\n/// # Displaying\n///\n/// This number is only displayable if `radix` is 10, 16, or 26. If\n/// `radix` is 10 or 16, then the digits are concatenated and\n/// displayed as a fixed-width decimal or hexadecimal number,\n/// respectively. If `radix` is 26, then each digit is translated to\n/// the corresponding lowercase ASCII alphabetic character (that is,\n/// 'a', 'b', 'c', etc.) and concatenated.\n#[derive(Clone)]\npub struct FixedWidthNumber {\n    radix: u8,\n    digits: Vec<u8>,\n}\nimpl FixedWidthNumber {\n    /// Instantiate a number of the given radix and width.\n    pub fn new(radix: u8, width: usize, mut suffix_start: usize) -> Result<Self, Overflow> {\n        let mut digits = vec![0_u8; width];\n\n        for i in (0..digits.len()).rev() {\n            let remainder = (suffix_start % (radix as usize)) as u8;\n            suffix_start /= radix as usize;\n            digits[i] = remainder;\n            if suffix_start == 0 {\n                break;\n            }\n        }\n        if suffix_start == 0 {\n            Ok(Self { radix, digits })\n        } else {\n            Err(Overflow)\n        }\n    }\n\n    /// Increment this number.\n    ///\n    /// This method adds one to this number. If incrementing this\n    /// number would require more digits than are available with the\n    /// specified width, then this method returns [`Err(Overflow)`].\n    fn increment(&mut self) -> Result<(), Overflow> {\n        for i in (0..self.digits.len()).rev() {\n            // Increment the current digit.\n            self.digits[i] += 1;\n\n            // If the digit overflows, then set it to 0 and continue\n            // to the next iteration to increment the next most\n            // significant digit. Otherwise, terminate the loop, since\n            // there will be no further changes to any higher order\n            // digits.\n            if self.digits[i] == self.radix {\n                self.digits[i] = 0;\n            } else {\n                break;\n            }\n        }\n\n        // Return an error on overflow, which is signified by all zeros.\n        if self.digits == vec![0; self.digits.len()] {\n            Err(Overflow)\n        } else {\n            Ok(())\n        }\n    }\n}\nimpl Display for FixedWidthNumber {\n    fn fmt(&self, f: &mut Formatter) -> fmt::Result {\n        let digits: String = self\n            .digits\n            .iter()\n            .map(|d| map_digit(self.radix, *d))\n            .collect();\n        write!(f, \"{digits}\")\n    }\n}\n/// A positional notation representation of a number of dynamically growing width.\n///\n/// The digits are represented as a [`Vec<u8>`] with the most\n/// significant digit on the left and the least significant digit on\n/// the right. Each digit is a nonnegative integer less than the\n/// radix.\n///\n/// # Incrementing\n///\n/// This number starts at `vec![0, 0]`, representing the number 0 with\n/// a width of 2 digits. Incrementing this number with\n/// [`Number::increment`] causes it to increase its value by 1. When\n/// incrementing the number would have caused it to change from\n/// `vec![radix - 2, radix - 1]` to `vec![radix - 1, 0]`, it instead\n/// increases its width by one and resets its value to 0. For example,\n/// if the radix were 3, the digits were `vec![1, 2]`, and we called\n/// [`Number::increment`], then the digits would become `vec![0, 0,\n/// 0]`. In this way, the width grows by one each time the most\n/// significant digit would have achieved its maximum value.\n///\n/// This notion of \"incrementing\" here does not match the notion of\n/// incrementing the *value* of the number, it is just an abstract way\n/// of updating the representation of the number in a way that is only\n/// useful for the purposes of the `split` program.\n///\n/// # Displaying\n///\n/// This number is only displayable if `radix` is 10, 16, or 26. If\n/// `radix` is 10 or 16, then the digits are concatenated and\n/// displayed as a fixed-width decimal or hexadecimal number,\n/// respectively, with a prefix of `n - 2` instances of the character\n/// '9' of 'f', respectively, where `n` is the number of digits.  If\n/// `radix` is 26, then each digit is translated to the corresponding\n/// lowercase ASCII alphabetic character (that is, 'a', 'b', 'c',\n/// etc.) and concatenated with a prefix of `n - 2` instances of the\n/// character 'z'.\n///\n/// This notion of displaying the number is specific to the `split`\n/// program.\n#[derive(Clone)]\npub struct DynamicWidthNumber {\n    radix: u8,\n    current: usize,\n}",
      "file_name": "coreutils/src/uu\\split\\src\\number.rs"
    },
    {
      "chunk": "impl DynamicWidthNumber {\n    pub fn new(radix: u8, suffix_start: usize) -> Self {\n        Self {\n            radix,\n            current: suffix_start,\n        }\n    }\n\n    fn increment(&mut self) -> Result<(), Overflow> {\n        self.current += 1;\n        Ok(())\n    }\n\n    fn digits(&self) -> Vec<u8> {\n        let radix = self.radix as usize;\n        let mut remaining = self.current;\n        let mut sub_value = (radix - 1) * radix;\n        let mut num_fill_chars = 2;\n\n        // Convert the number into \"num_fill_chars\" and \"remaining\"\n        while remaining >= sub_value {\n            remaining -= sub_value;\n            sub_value *= radix;\n            num_fill_chars += 1;\n        }\n\n        // Convert the \"remainder\" to digits\n        let mut digits = Vec::new();\n        while remaining > 0 {\n            digits.push((remaining % radix) as u8);\n            remaining /= radix;\n        }\n        // Left pad the vec\n        digits.resize(num_fill_chars, 0);\n        digits.reverse();\n        digits\n    }\n}\nfn map_digit(radix: u8, d: u8) -> char {\n    (match radix {\n        10 => b'0' + d,\n        16 => {\n            if d < 10 {\n                b'0' + d\n            } else {\n                b'a' + (d - 10)\n            }\n        }\n        26 => b'a' + d,\n        _ => 0,\n    }) as char\n}\nimpl Display for DynamicWidthNumber {\n    fn fmt(&self, f: &mut Formatter) -> fmt::Result {\n        let digits: String = self\n            .digits()\n            .iter()\n            .map(|d| map_digit(self.radix, *d))\n            .collect();\n        let fill: String = (0..digits.len() - 2)\n            .map(|_| map_digit(self.radix, self.radix - 1))\n            .collect();\n        write!(f, \"{fill}{digits}\")\n    }\n}\n#[cfg(test)]\nmod tests {\n    use crate::number::DynamicWidthNumber;\n    use crate::number::FixedWidthNumber;\n    use crate::number::Number;\n    use crate::number::Overflow;\n\n    #[test]\n    fn test_dynamic_width_number_increment() {\n        println!(\"Here\");\n        let mut n = Number::DynamicWidth(DynamicWidthNumber::new(3, 0));\n        assert_eq!(n.digits(), vec![0, 0]);\n\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![0, 1]);\n\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![0, 2]);\n\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![1, 0]);\n\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![1, 1]);\n\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![1, 2]);\n\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![0, 0, 0]);\n\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![0, 0, 1]);\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn test_dynamic_width_number_display_alphabetic() {\n        fn num(n: usize) -> Number {\n            let mut number = Number::DynamicWidth(DynamicWidthNumber::new(26, 0));\n            for _ in 0..n {\n                number.increment().unwrap();\n            }\n            number\n        }\n\n        assert_eq!(format!(\"{}\", num(0)), \"aa\");\n        assert_eq!(format!(\"{}\", num(1)), \"ab\");\n        assert_eq!(format!(\"{}\", num(2)), \"ac\");\n        assert_eq!(format!(\"{}\", num(25)), \"az\");\n        assert_eq!(format!(\"{}\", num(26)), \"ba\");\n        assert_eq!(format!(\"{}\", num(27)), \"bb\");\n        assert_eq!(format!(\"{}\", num(28)), \"bc\");\n        assert_eq!(format!(\"{}\", num(26 + 25)), \"bz\");\n        assert_eq!(format!(\"{}\", num(26 + 26)), \"ca\");\n        assert_eq!(format!(\"{}\", num(26 * 25 - 1)), \"yz\");\n        assert_eq!(format!(\"{}\", num(26 * 25)), \"zaaa\");\n        assert_eq!(format!(\"{}\", num(26 * 25 + 1)), \"zaab\");\n    }\n\n    #[test]\n    fn test_dynamic_width_number_display_numeric_decimal() {\n        fn num(n: usize) -> Number {\n            let mut number = Number::DynamicWidth(DynamicWidthNumber::new(10, 0));\n            for _ in 0..n {\n                number.increment().unwrap();\n            }\n            number\n        }\n\n        assert_eq!(format!(\"{}\", num(0)), \"00\");\n        assert_eq!(format!(\"{}\", num(9)), \"09\");\n        assert_eq!(format!(\"{}\", num(17)), \"17\");\n        assert_eq!(format!(\"{}\", num(10 * 9 - 1)), \"89\");\n        assert_eq!(format!(\"{}\", num(10 * 9)), \"9000\");\n        assert_eq!(format!(\"{}\", num(10 * 9 + 1)), \"9001\");\n        assert_eq!(format!(\"{}\", num(10 * 99 - 1)), \"9899\");\n        assert_eq!(format!(\"{}\", num(10 * 99)), \"990000\");\n        assert_eq!(format!(\"{}\", num(10 * 99 + 1)), \"990001\");\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn test_dynamic_width_number_display_numeric_hexadecimal() {\n        fn num(n: usize) -> Number {\n            let mut number = Number::DynamicWidth(DynamicWidthNumber::new(16, 0));\n            for _ in 0..n {\n                number.increment().unwrap();\n            }\n            number\n        }\n\n        assert_eq!(format!(\"{}\", num(0)), \"00\");\n        assert_eq!(format!(\"{}\", num(15)), \"0f\");\n        assert_eq!(format!(\"{}\", num(16)), \"10\");\n        assert_eq!(format!(\"{}\", num(17)), \"11\");\n        assert_eq!(format!(\"{}\", num(18)), \"12\");\n\n        assert_eq!(format!(\"{}\", num(16 * 15 - 1)), \"ef\");\n        assert_eq!(format!(\"{}\", num(16 * 15)), \"f000\");\n        assert_eq!(format!(\"{}\", num(16 * 15 + 1)), \"f001\");\n        assert_eq!(format!(\"{}\", num(16 * 255 - 1)), \"feff\");\n        assert_eq!(format!(\"{}\", num(16 * 255)), \"ff0000\");\n        assert_eq!(format!(\"{}\", num(16 * 255 + 1)), \"ff0001\");\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn test_fixed_width_number_increment() {\n        let mut n = Number::FixedWidth(FixedWidthNumber::new(3, 2, 0).unwrap());\n        assert_eq!(n.digits(), vec![0, 0]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![0, 1]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![0, 2]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![1, 0]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![1, 1]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![1, 2]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![2, 0]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![2, 1]);\n        n.increment().unwrap();\n        assert_eq!(n.digits(), vec![2, 2]);\n        assert!(n.increment().is_err());\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn test_fixed_width_number_display_alphabetic() {\n        fn num(n: usize) -> Result<Number, Overflow> {\n            let mut number = Number::FixedWidth(FixedWidthNumber::new(26, 2, 0).unwrap());\n            for _ in 0..n {\n                number.increment()?;\n            }\n            Ok(number)\n        }\n\n        assert_eq!(format!(\"{}\", num(0).unwrap()), \"aa\");\n        assert_eq!(format!(\"{}\", num(1).unwrap()), \"ab\");\n        assert_eq!(format!(\"{}\", num(2).unwrap()), \"ac\");\n        assert_eq!(format!(\"{}\", num(25).unwrap()), \"az\");\n        assert_eq!(format!(\"{}\", num(26).unwrap()), \"ba\");\n        assert_eq!(format!(\"{}\", num(27).unwrap()), \"bb\");\n        assert_eq!(format!(\"{}\", num(28).unwrap()), \"bc\");\n        assert_eq!(format!(\"{}\", num(26 + 25).unwrap()), \"bz\");\n        assert_eq!(format!(\"{}\", num(26 + 26).unwrap()), \"ca\");\n        assert_eq!(format!(\"{}\", num(26 * 25 - 1).unwrap()), \"yz\");\n        assert_eq!(format!(\"{}\", num(26 * 25).unwrap()), \"za\");\n        assert_eq!(format!(\"{}\", num(26 * 26 - 1).unwrap()), \"zz\");\n        assert!(num(26 * 26).is_err());\n    }\n\n    #[test]\n    fn test_fixed_width_number_display_numeric_decimal() {\n        fn num(n: usize) -> Result<Number, Overflow> {\n            let mut number = Number::FixedWidth(FixedWidthNumber::new(10, 2, 0).unwrap());\n            for _ in 0..n {\n                number.increment()?;\n            }\n            Ok(number)\n        }\n\n        assert_eq!(format!(\"{}\", num(0).unwrap()), \"00\");\n        assert_eq!(format!(\"{}\", num(9).unwrap()), \"09\");\n        assert_eq!(format!(\"{}\", num(17).unwrap()), \"17\");\n        assert_eq!(format!(\"{}\", num(10 * 9 - 1).unwrap()), \"89\");\n        assert_eq!(format!(\"{}\", num(10 * 9).unwrap()), \"90\");\n        assert_eq!(format!(\"{}\", num(10 * 10 - 1).unwrap()), \"99\");\n        assert!(num(10 * 10).is_err());\n    }\n\n    #[test]\n    fn test_fixed_width_number_display_numeric_hexadecimal() {\n        fn num(n: usize) -> Result<Number, Overflow> {\n            let mut number = Number::FixedWidth(FixedWidthNumber::new(16, 2, 0).unwrap());\n            for _ in 0..n {\n                number.increment()?;\n            }\n            Ok(number)\n        }\n\n        assert_eq!(format!(\"{}\", num(0).unwrap()), \"00\");\n        assert_eq!(format!(\"{}\", num(15).unwrap()), \"0f\");\n        assert_eq!(format!(\"{}\", num(17).unwrap()), \"11\");\n        assert_eq!(format!(\"{}\", num(16 * 15 - 1).unwrap()), \"ef\");\n        assert_eq!(format!(\"{}\", num(16 * 15).unwrap()), \"f0\");\n        assert_eq!(format!(\"{}\", num(16 * 16 - 1).unwrap()), \"ff\");\n        assert!(num(16 * 16).is_err());\n    }\n\n    #[test]\n    fn test_fixed_width_number_start_suffix() {\n        fn num(n: usize) -> Result<Number, Overflow> {\n            let mut number = Number::FixedWidth(FixedWidthNumber::new(16, 2, 0x14)?);\n            for _ in 0..n {\n                number.increment()?;\n            }\n            Ok(number)\n        }\n\n        assert_eq!(format!(\"{}\", num(0).unwrap()), \"14\");\n        assert_eq!(format!(\"{}\", num(0xf).unwrap()), \"23\");\n    }\n\n    #[test]\n    fn test_dynamic_width_number_start_suffix() {\n        fn num(n: usize) -> Result<Number, Overflow> {\n            let mut number = Number::DynamicWidth(DynamicWidthNumber::new(10, 8));\n            for _ in 0..n {\n                number.increment()?;\n            }\n            Ok(number)\n        }\n\n        assert_eq!(format!(\"{}\", num(0).unwrap()), \"08\");\n        assert_eq!(format!(\"{}\", num(8).unwrap()), \"16\");\n    }\n}",
      "file_name": "coreutils/src/uu\\split\\src\\number.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore nbbbb ncccc hexdigit getmaxstdio\nmod filenames;\nmod number;\nmod platform;\nmod strategy;\nuse crate::filenames::{FilenameIterator, Suffix, SuffixError};\nuse crate::strategy::{NumberType, Strategy, StrategyError};\nuse clap::{Arg, ArgAction, ArgMatches, Command, ValueHint, parser::ValueSource};\nuse std::env;\nuse std::ffi::OsString;\nuse std::fs::{File, metadata};\nuse std::io;\nuse std::io::{BufRead, BufReader, BufWriter, ErrorKind, Read, Seek, SeekFrom, Write, stdin};\nuse std::path::Path;\nuse thiserror::Error;\nuse uucore::display::Quotable;\nuse uucore::error::{FromIo, UIoError, UResult, USimpleError, UUsageError};\nuse uucore::parser::parse_size::parse_size_u64;\nuse uucore::uio_error;\nuse uucore::{format_usage, help_about, help_section, help_usage};\nstatic OPT_BYTES: &str = \"bytes\";\nstatic OPT_LINE_BYTES: &str = \"line-bytes\";\nstatic OPT_LINES: &str = \"lines\";\nstatic OPT_ADDITIONAL_SUFFIX: &str = \"additional-suffix\";\nstatic OPT_FILTER: &str = \"filter\";\nstatic OPT_NUMBER: &str = \"number\";\nstatic OPT_NUMERIC_SUFFIXES: &str = \"numeric-suffixes\";\nstatic OPT_NUMERIC_SUFFIXES_SHORT: &str = \"-d\";\nstatic OPT_HEX_SUFFIXES: &str = \"hex-suffixes\";\nstatic OPT_HEX_SUFFIXES_SHORT: &str = \"-x\";\nstatic OPT_SUFFIX_LENGTH: &str = \"suffix-length\";\nstatic OPT_VERBOSE: &str = \"verbose\";\nstatic OPT_SEPARATOR: &str = \"separator\";\nstatic OPT_ELIDE_EMPTY_FILES: &str = \"elide-empty-files\";\nstatic OPT_IO_BLKSIZE: &str = \"-io-blksize\";\nstatic ARG_INPUT: &str = \"input\";\nstatic ARG_PREFIX: &str = \"prefix\";\nconst ABOUT: &str = help_about!(\"split.md\");\nconst USAGE: &str = help_usage!(\"split.md\");\nconst AFTER_HELP: &str = help_section!(\"after help\", \"split.md\");\n#[uucore::main]\npub fn uumain(args: impl uucore::Args) -> UResult<()> {\n    let (args, obs_lines) = handle_obsolete(args);\n    let matches = uu_app().try_get_matches_from(args)?;\n\n    match Settings::from(&matches, obs_lines.as_deref()) {\n        Ok(settings) => split(&settings),\n        Err(e) if e.requires_usage() => Err(UUsageError::new(1, format!(\"{e}\"))),\n        Err(e) => Err(USimpleError::new(1, format!(\"{e}\"))),\n    }\n}\n/// Extract obsolete shorthand (if any) for specifying lines in following scenarios (and similar)\n/// `split -22 file` would mean `split -l 22 file`\n/// `split -2de file` would mean `split -l 2 -d -e file`\n/// `split -x300e file` would mean `split -x -l 300 -e file`\n/// `split -x300e -22 file` would mean `split -x -e -l 22 file` (last obsolete lines option wins)\n/// following GNU `split` behavior\nfn handle_obsolete(args: impl uucore::Args) -> (Vec<OsString>, Option<String>) {\n    let mut obs_lines = None;\n    let mut preceding_long_opt_req_value = false;\n    let mut preceding_short_opt_req_value = false;\n\n    let filtered_args = args\n        .filter_map(|os_slice| {\n            filter_args(\n                os_slice,\n                &mut obs_lines,\n                &mut preceding_long_opt_req_value,\n                &mut preceding_short_opt_req_value,\n            )\n        })\n        .collect();\n\n    (filtered_args, obs_lines)\n}\n/// Helper function to [`handle_obsolete`]\n/// Filters out obsolete lines option from args\nfn filter_args(\n    os_slice: OsString,\n    obs_lines: &mut Option<String>,\n    preceding_long_opt_req_value: &mut bool,\n    preceding_short_opt_req_value: &mut bool,\n) -> Option<OsString> {\n    let filter: Option<OsString>;\n    if let Some(slice) = os_slice.to_str() {\n        if should_extract_obs_lines(\n            slice,\n            preceding_long_opt_req_value,\n            preceding_short_opt_req_value,\n        ) {\n            // start of the short option string\n            // that can have obsolete lines option value in it\n            filter = handle_extract_obs_lines(slice, obs_lines);\n        } else {\n            // either not a short option\n            // or a short option that cannot have obsolete lines value in it\n            filter = Some(OsString::from(slice));\n        }\n        handle_preceding_options(\n            slice,\n            preceding_long_opt_req_value,\n            preceding_short_opt_req_value,\n        );\n    } else {\n        // Cannot cleanly convert os_slice to UTF-8\n        // Do not process and return as-is\n        // This will cause failure later on, but we should not handle it here\n        // and let clap panic on invalid UTF-8 argument\n        filter = Some(os_slice);\n    }\n    filter\n}\n/// Helper function to [`filter_args`]\n/// Checks if the slice is a true short option (and not hyphen prefixed value of an option)\n/// and if so, a short option that can contain obsolete lines value\nfn should_extract_obs_lines(\n    slice: &str,\n    preceding_long_opt_req_value: &bool,\n    preceding_short_opt_req_value: &bool,\n) -> bool {\n    slice.starts_with('-')\n        && !slice.starts_with(\"--\")\n        && !preceding_long_opt_req_value\n        && !preceding_short_opt_req_value\n        && !slice.starts_with(\"-a\")\n        && !slice.starts_with(\"-b\")\n        && !slice.starts_with(\"-C\")\n        && !slice.starts_with(\"-l\")\n        && !slice.starts_with(\"-n\")\n        && !slice.starts_with(\"-t\")\n}\n/// Helper function to [`filter_args`]\n/// Extracts obsolete lines numeric part from argument slice\n/// and filters it out\nfn handle_extract_obs_lines(slice: &str, obs_lines: &mut Option<String>) -> Option<OsString> {\n    let mut obs_lines_extracted: Vec<char> = vec![];\n    let mut obs_lines_end_reached = false;\n    let filtered_slice: Vec<char> = slice\n        .chars()\n        .filter(|c| {\n            // To correctly process scenario like '-x200a4'\n            // we need to stop extracting digits once alphabetic character is encountered\n            // after we already have something in obs_lines_extracted\n            if c.is_ascii_digit() && !obs_lines_end_reached {\n                obs_lines_extracted.push(*c);\n                false\n            } else {\n                if !obs_lines_extracted.is_empty() {\n                    obs_lines_end_reached = true;\n                }\n                true\n            }\n        })\n        .collect();\n\n    if obs_lines_extracted.is_empty() {\n        // no obsolete lines value found/extracted\n        Some(OsString::from(slice))\n    } else {\n        // obsolete lines value was extracted\n        let extracted: String = obs_lines_extracted.iter().collect();\n        *obs_lines = Some(extracted);\n        if filtered_slice.get(1).is_some() {\n            // there were some short options in front of or after obsolete lines value\n            // i.e. '-xd100' or '-100de' or similar, which after extraction of obsolete lines value\n            // would look like '-xd' or '-de' or similar\n            let filtered_slice: String = filtered_slice.iter().collect();\n            Some(OsString::from(filtered_slice))\n        } else {\n            None\n        }\n    }\n}\n/// Helper function to [`handle_extract_obs_lines`]\n/// Captures if current slice is a preceding option\n/// that requires value\nfn handle_preceding_options(\n    slice: &str,\n    preceding_long_opt_req_value: &mut bool,\n    preceding_short_opt_req_value: &mut bool,\n) {\n    // capture if current slice is a preceding long option that requires value and does not use '=' to assign that value\n    // following slice should be treaded as value for this option\n    // even if it starts with '-' (which would be treated as hyphen prefixed value)\n    if slice.starts_with(\"--\") {\n        *preceding_long_opt_req_value = &slice[2..] == OPT_BYTES\n            || &slice[2..] == OPT_LINE_BYTES\n            || &slice[2..] == OPT_LINES\n            || &slice[2..] == OPT_ADDITIONAL_SUFFIX\n            || &slice[2..] == OPT_FILTER\n            || &slice[2..] == OPT_NUMBER\n            || &slice[2..] == OPT_SUFFIX_LENGTH\n            || &slice[2..] == OPT_SEPARATOR;\n    }\n    // capture if current slice is a preceding short option that requires value and does not have value in the same slice (value separated by whitespace)\n    // following slice should be treaded as value for this option\n    // even if it starts with '-' (which would be treated as hyphen prefixed value)\n    *preceding_short_opt_req_value = slice == \"-b\"\n        || slice == \"-C\"\n        || slice == \"-l\"\n        || slice == \"-n\"\n        || slice == \"-a\"\n        || slice == \"-t\";\n    // slice is a value\n    // reset preceding option flags\n    if !slice.starts_with('-') {\n        *preceding_short_opt_req_value = false;\n        *preceding_long_opt_req_value = false;\n    }\n}",
      "file_name": "coreutils/src/uu\\split\\src\\split.rs"
    },
    {
      "chunk": "pub fn uu_app() -> Command {\n    Command::new(uucore::util_name())\n        .version(uucore::crate_version!())\n        .about(ABOUT)\n        .after_help(AFTER_HELP)\n        .override_usage(format_usage(USAGE))\n        .infer_long_args(true)\n        // strategy (mutually exclusive)\n        .arg(\n            Arg::new(OPT_BYTES)\n                .short('b')\n                .long(OPT_BYTES)\n                .allow_hyphen_values(true)\n                .value_name(\"SIZE\")\n                .help(\"put SIZE bytes per output file\"),\n        )\n        .arg(\n            Arg::new(OPT_LINE_BYTES)\n                .short('C')\n                .long(OPT_LINE_BYTES)\n                .allow_hyphen_values(true)\n                .value_name(\"SIZE\")\n                .help(\"put at most SIZE bytes of lines per output file\"),\n        )\n        .arg(\n            Arg::new(OPT_LINES)\n                .short('l')\n                .long(OPT_LINES)\n                .allow_hyphen_values(true)\n                .value_name(\"NUMBER\")\n                .default_value(\"1000\")\n                .help(\"put NUMBER lines/records per output file\"),\n        )\n        .arg(\n            Arg::new(OPT_NUMBER)\n                .short('n')\n                .long(OPT_NUMBER)\n                .allow_hyphen_values(true)\n                .value_name(\"CHUNKS\")\n                .help(\"generate CHUNKS output files; see explanation below\"),\n        )\n        // rest of the arguments\n        .arg(\n            Arg::new(OPT_ADDITIONAL_SUFFIX)\n                .long(OPT_ADDITIONAL_SUFFIX)\n                .allow_hyphen_values(true)\n                .value_name(\"SUFFIX\")\n                .default_value(\"\")\n                .help(\"additional SUFFIX to append to output file names\"),\n        )\n        .arg(\n            Arg::new(OPT_FILTER)\n                .long(OPT_FILTER)\n                .allow_hyphen_values(true)\n                .value_name(\"COMMAND\")\n                .value_hint(ValueHint::CommandName)\n                .help(\n                    \"write to shell COMMAND; file name is $FILE (Currently not implemented for Windows)\",\n                ),\n        )\n        .arg(\n            Arg::new(OPT_ELIDE_EMPTY_FILES)\n                .long(OPT_ELIDE_EMPTY_FILES)\n                .short('e')\n                .help(\"do not generate empty output files with '-n'\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(OPT_NUMERIC_SUFFIXES_SHORT)\n                .short('d')\n                .action(ArgAction::SetTrue)\n                .overrides_with_all([\n                    OPT_NUMERIC_SUFFIXES,\n                    OPT_NUMERIC_SUFFIXES_SHORT,\n                    OPT_HEX_SUFFIXES,\n                    OPT_HEX_SUFFIXES_SHORT\n                ])\n                .help(\"use numeric suffixes starting at 0, not alphabetic\"),\n        )\n        .arg(\n            Arg::new(OPT_NUMERIC_SUFFIXES)\n                .long(OPT_NUMERIC_SUFFIXES)\n                .require_equals(true)\n                .num_args(0..=1)\n                .overrides_with_all([\n                    OPT_NUMERIC_SUFFIXES,\n                    OPT_NUMERIC_SUFFIXES_SHORT,\n                    OPT_HEX_SUFFIXES,\n                    OPT_HEX_SUFFIXES_SHORT\n                ])\n                .value_name(\"FROM\")\n                .help(\"same as -d, but allow setting the start value\"),\n        )\n        .arg(\n            Arg::new(OPT_HEX_SUFFIXES_SHORT)\n                .short('x')\n                .action(ArgAction::SetTrue)\n                .overrides_with_all([\n                    OPT_NUMERIC_SUFFIXES,\n                    OPT_NUMERIC_SUFFIXES_SHORT,\n                    OPT_HEX_SUFFIXES,\n                    OPT_HEX_SUFFIXES_SHORT\n                ])\n                .help(\"use hex suffixes starting at 0, not alphabetic\"),\n        )\n        .arg(\n            Arg::new(OPT_HEX_SUFFIXES)\n                .long(OPT_HEX_SUFFIXES)\n                .require_equals(true)\n                .num_args(0..=1)\n                .overrides_with_all([\n                    OPT_NUMERIC_SUFFIXES,\n                    OPT_NUMERIC_SUFFIXES_SHORT,\n                    OPT_HEX_SUFFIXES,\n                    OPT_HEX_SUFFIXES_SHORT\n                ])\n                .value_name(\"FROM\")\n                .help(\"same as -x, but allow setting the start value\"),\n        )\n        .arg(\n            Arg::new(OPT_SUFFIX_LENGTH)\n                .short('a')\n                .long(OPT_SUFFIX_LENGTH)\n                .allow_hyphen_values(true)\n                .value_name(\"N\")\n                .help(\"generate suffixes of length N (default 2)\"),\n        )\n        .arg(\n            Arg::new(OPT_VERBOSE)\n                .long(OPT_VERBOSE)\n                .help(\"print a diagnostic just before each output file is opened\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(OPT_SEPARATOR)\n                .short('t')\n                .long(OPT_SEPARATOR)\n                .allow_hyphen_values(true)\n                .value_name(\"SEP\")\n                .action(ArgAction::Append)\n                .help(\"use SEP instead of newline as the record separator; '\\\\0' (zero) specifies the NUL character\"),\n        )\n        .arg(\n            Arg::new(OPT_IO_BLKSIZE)\n                .long(\"io-blksize\")\n                .alias(OPT_IO_BLKSIZE)\n                .hide(true),\n        )\n        .arg(\n            Arg::new(ARG_INPUT)\n                .default_value(\"-\")\n                .value_hint(ValueHint::FilePath),\n        )\n        .arg(\n            Arg::new(ARG_PREFIX)\n                .default_value(\"x\")\n        )\n}\n/// Parameters that control how a file gets split.\n///\n/// You can convert an [`ArgMatches`] instance into a [`Settings`]\n/// instance by calling [`Settings::from`].\nstruct Settings {\n    prefix: String,\n    suffix: Suffix,\n    input: String,\n    /// When supplied, a shell command to output to instead of xaa, xab \u2026\n    filter: Option<String>,\n    strategy: Strategy,\n    verbose: bool,\n    separator: u8,\n\n    /// Whether to *not* produce empty files when using `-n`.\n    ///\n    /// The `-n` command-line argument gives a specific number of\n    /// chunks into which the input files will be split. If the number\n    /// of chunks is greater than the number of bytes, and this is\n    /// `false`, then empty files will be created for the excess\n    /// chunks. If this is `false`, then empty files will not be\n    /// created.\n    elide_empty_files: bool,\n    io_blksize: Option<u64>,\n}\n#[derive(Debug, Error)]\n/// An error when parsing settings from command-line arguments.\nenum SettingsError {\n    /// Invalid chunking strategy.\n    #[error(\"{0}\")]\n    Strategy(StrategyError),\n\n    /// Invalid suffix length parameter.\n    #[error(\"{0}\")]\n    Suffix(SuffixError),\n\n    /// Multi-character (Invalid) separator\n    #[error(\"multi-character separator {}\", .0.quote())]\n    MultiCharacterSeparator(String),\n\n    /// Multiple different separator characters\n    #[error(\"multiple separator characters specified\")]\n    MultipleSeparatorCharacters,\n\n    /// Using `--filter` with `--number` option sub-strategies that print Kth chunk out of N chunks to stdout\n    /// K/N\n    /// l/K/N\n    /// r/K/N\n    #[error(\"--filter does not process a chunk extracted to stdout\")]\n    FilterWithKthChunkNumber,\n\n    /// Invalid IO block size\n    #[error(\"invalid IO block size: {}\", .0.quote())]\n    InvalidIOBlockSize(String),\n\n    /// The `--filter` option is not supported on Windows.\n    #[cfg(windows)]\n    #[error(\"{OPT_FILTER} is currently not supported in this platform\")]\n    NotSupported,\n}\nimpl SettingsError {\n    /// Whether the error demands a usage message.\n    fn requires_usage(&self) -> bool {\n        matches!(\n            self,\n            Self::Strategy(StrategyError::MultipleWays)\n                | Self::Suffix(SuffixError::ContainsSeparator(_))\n        )\n    }\n}",
      "file_name": "coreutils/src/uu\\split\\src\\split.rs"
    },
    {
      "chunk": "impl Settings {\n    /// Parse a strategy from the command-line arguments.\n    fn from(matches: &ArgMatches, obs_lines: Option<&str>) -> Result<Self, SettingsError> {\n        let strategy = Strategy::from(matches, obs_lines).map_err(SettingsError::Strategy)?;\n        let suffix = Suffix::from(matches, &strategy).map_err(SettingsError::Suffix)?;\n\n        // Make sure that separator is only one UTF8 character (if specified)\n        // defaults to '\\n' - newline character\n        // If the same separator (the same value) was used multiple times - `split` should NOT fail\n        // If the separator was used multiple times but with different values (not all values are the same) - `split` should fail\n        let separator = match matches.get_many::<String>(OPT_SEPARATOR) {\n            Some(mut sep_values) => {\n                let first = sep_values.next().unwrap(); // it is safe to just unwrap here since Clap should not return empty ValuesRef<'_,String> in the option from get_many() call\n                if !sep_values.all(|s| s == first) {\n                    return Err(SettingsError::MultipleSeparatorCharacters);\n                }\n                match first.as_str() {\n                    \"\\\\0\" => b'\\0',\n                    s if s.len() == 1 => s.as_bytes()[0],\n                    s => return Err(SettingsError::MultiCharacterSeparator(s.to_string())),\n                }\n            }\n            None => b'\\n',\n        };\n\n        let io_blksize: Option<u64> = if let Some(s) = matches.get_one::<String>(OPT_IO_BLKSIZE) {\n            match parse_size_u64(s) {\n                Ok(0) => return Err(SettingsError::InvalidIOBlockSize(s.to_string())),\n                Ok(n) if n <= uucore::fs::sane_blksize::MAX => Some(n),\n                _ => return Err(SettingsError::InvalidIOBlockSize(s.to_string())),\n            }\n        } else {\n            None\n        };\n\n        let result = Self {\n            prefix: matches.get_one::<String>(ARG_PREFIX).unwrap().clone(),\n            suffix,\n            input: matches.get_one::<String>(ARG_INPUT).unwrap().clone(),\n            filter: matches.get_one::<String>(OPT_FILTER).cloned(),\n            strategy,\n            verbose: matches.value_source(OPT_VERBOSE) == Some(ValueSource::CommandLine),\n            separator,\n            elide_empty_files: matches.get_flag(OPT_ELIDE_EMPTY_FILES),\n            io_blksize,\n        };\n\n        #[cfg(windows)]\n        if result.filter.is_some() {\n            // see https://github.com/rust-lang/rust/issues/29494\n            return Err(SettingsError::NotSupported);\n        }\n\n        // Return an error if `--filter` option is used with any of the\n        // Kth chunk sub-strategies of `--number` option\n        // As those are writing to stdout of `split` and cannot write to filter command child process\n        let kth_chunk = matches!(\n            result.strategy,\n            Strategy::Number(\n                NumberType::KthBytes(_, _)\n                    | NumberType::KthLines(_, _)\n                    | NumberType::KthRoundRobin(_, _)\n            )\n        );\n        if kth_chunk && result.filter.is_some() {\n            return Err(SettingsError::FilterWithKthChunkNumber);\n        }\n\n        Ok(result)\n    }\n\n    fn instantiate_current_writer(\n        &self,\n        filename: &str,\n        is_new: bool,\n    ) -> io::Result<BufWriter<Box<dyn Write>>> {\n        if platform::paths_refer_to_same_file(&self.input, filename) {\n            return Err(io::Error::other(format!(\n                \"'{filename}' would overwrite input; aborting\"\n            )));\n        }\n\n        platform::instantiate_current_writer(self.filter.as_deref(), filename, is_new)\n    }\n}\n/// When using `--filter` option, writing to child command process stdin\n/// could fail with BrokenPipe error\n/// It can be safely ignored\nfn ignorable_io_error(error: &io::Error, settings: &Settings) -> bool {\n    error.kind() == ErrorKind::BrokenPipe && settings.filter.is_some()\n}\n/// Custom wrapper for `write()` method\n/// Follows similar approach to GNU implementation\n/// If ignorable io error occurs, return number of bytes as if all bytes written\n/// Should not be used for Kth chunk number sub-strategies\n/// as those do not work with `--filter` option\nfn custom_write<T: Write>(bytes: &[u8], writer: &mut T, settings: &Settings) -> io::Result<usize> {\n    match writer.write(bytes) {\n        Ok(n) => Ok(n),\n        Err(e) if ignorable_io_error(&e, settings) => Ok(bytes.len()),\n        Err(e) => Err(e),\n    }\n}\n/// Custom wrapper for `write_all()` method\n/// Similar to [`custom_write`], but returns true or false\n/// depending on if `--filter` stdin is still open (no BrokenPipe error)\n/// Should not be used for Kth chunk number sub-strategies\n/// as those do not work with `--filter` option\nfn custom_write_all<T: Write>(\n    bytes: &[u8],\n    writer: &mut T,\n    settings: &Settings,\n) -> io::Result<bool> {\n    match writer.write_all(bytes) {\n        Ok(()) => Ok(true),\n        Err(e) if ignorable_io_error(&e, settings) => Ok(false),\n        Err(e) => Err(e),\n    }\n}\n/// Get the size of the input file in bytes\n/// Used only for subset of `--number=CHUNKS` strategy, as there is a need\n/// to determine input file size upfront in order to estimate the chunk size\n/// to be written into each of N files/chunks:\n/// * N       split into N files based on size of input\n/// * K/N     output Kth of N to stdout\n/// * l/N     split into N files without splitting lines/records\n/// * l/K/N   output Kth of N to stdout without splitting lines/records\n///\n/// For most files the size will be determined by either reading entire file content into a buffer\n/// or by `len()` function of [`std::fs::metadata`].\n///\n/// However, for some files which report filesystem metadata size that does not match\n/// their actual content size, we will need to attempt to find the end of file\n/// with direct `seek()` on [`std::fs::File`].\n///\n/// For STDIN stream - read into a buffer up to a limit\n/// If input stream does not EOF before that - return an error\n/// (i.e. \"infinite\" input as in `cat /dev/zero | split ...`, `yes | split ...` etc.).\n///\n/// Note: The `buf` might end up with either partial or entire input content.\nfn get_input_size<R>(\n    input: &String,\n    reader: &mut R,\n    buf: &mut Vec<u8>,\n    io_blksize: Option<u64>,\n) -> io::Result<u64>\nwhere\n    R: BufRead,\n{\n    // Set read limit to io_blksize if specified\n    let read_limit: u64 = if let Some(custom_blksize) = io_blksize {\n        custom_blksize\n    } else {\n        // otherwise try to get it from filesystem, or use default\n        uucore::fs::sane_blksize::sane_blksize_from_path(Path::new(input))\n    };\n\n    // Try to read into buffer up to a limit\n    let num_bytes = reader\n        .by_ref()\n        .take(read_limit)\n        .read_to_end(buf)\n        .map(|n| n as u64)?;\n\n    if num_bytes < read_limit {\n        // Finite file or STDIN stream that fits entirely\n        // into a buffer within the limit\n        // Note: files like /dev/null or similar,\n        // empty STDIN stream,\n        // and files with true file size 0\n        // will also fit here\n        Ok(num_bytes)\n    } else if input == \"-\" {\n        // STDIN stream that did not fit all content into a buffer\n        // Most likely continuous/infinite input stream\n        return Err(io::Error::other(format!(\n            \"{input}: cannot determine input size\"\n        )));\n    } else {\n        // Could be that file size is larger than set read limit\n        // Get the file size from filesystem metadata\n        let metadata = metadata(input)?;\n        let metadata_size = metadata.len();\n        if num_bytes <= metadata_size {\n            Ok(metadata_size)\n        } else {\n            // Could be a file from locations like /dev, /sys, /proc or similar\n            // which report filesystem metadata size that does not match\n            // their actual content size\n            // Attempt direct `seek()` for the end of a file\n            let mut tmp_fd = File::open(Path::new(input))?;\n            let end = tmp_fd.seek(SeekFrom::End(0))?;\n            if end > 0 {\n                Ok(end)\n            } else {\n                // Edge case of either \"infinite\" file (i.e. /dev/zero)\n                // or some other \"special\" non-standard file type\n                // Give up and return an error\n                // TODO It might be possible to do more here\n                // to address all possible file types and edge cases\n                return Err(io::Error::other(format!(\n                    \"{input}: cannot determine file size\"\n                )));\n            }\n        }\n    }\n}\n/// Write a certain number of bytes to one file, then move on to another one.\n///\n/// This struct maintains an underlying writer representing the\n/// current chunk of the output. If a call to [`write`] would cause\n/// the underlying writer to write more than the allowed number of\n/// bytes, a new writer is created and the excess bytes are written to\n/// that one instead. As many new underlying writers are created as\n/// needed to write all the bytes in the input buffer.\nstruct ByteChunkWriter<'a> {\n    /// Parameters for creating the underlying writer for each new chunk.\n    settings: &'a Settings,\n\n    /// The maximum number of bytes allowed for a single chunk of output.\n    chunk_size: u64,\n\n    /// Running total of number of chunks that have been completed.\n    num_chunks_written: u64,\n\n    /// Remaining capacity in number of bytes in the current chunk.\n    ///\n    /// This number starts at `chunk_size` and decreases as bytes are\n    /// written. Once it reaches zero, a writer for a new chunk is\n    /// initialized and this number gets reset to `chunk_size`.\n    num_bytes_remaining_in_current_chunk: u64,\n\n    /// The underlying writer for the current chunk.\n    ///\n    /// Once the number of bytes written to this writer exceeds\n    /// `chunk_size`, a new writer is initialized and assigned to this\n    /// field.\n    inner: BufWriter<Box<dyn Write>>,\n\n    /// Iterator that yields filenames for each chunk.\n    filename_iterator: FilenameIterator<'a>,\n}\nimpl<'a> ByteChunkWriter<'a> {\n    fn new(chunk_size: u64, settings: &'a Settings) -> UResult<Self> {\n        let mut filename_iterator = FilenameIterator::new(&settings.prefix, &settings.suffix)?;\n        let filename = filename_iterator\n            .next()\n            .ok_or_else(|| USimpleError::new(1, \"output file suffixes exhausted\"))?;\n        if settings.verbose {\n            println!(\"creating file {}\", filename.quote());\n        }\n        let inner = settings.instantiate_current_writer(&filename, true)?;\n        Ok(ByteChunkWriter {\n            settings,\n            chunk_size,\n            num_bytes_remaining_in_current_chunk: chunk_size,\n            num_chunks_written: 0,\n            inner,\n            filename_iterator,\n        })\n    }\n}",
      "file_name": "coreutils/src/uu\\split\\src\\split.rs"
    },
    {
      "chunk": "impl Write for ByteChunkWriter<'_> {\n    /// Implements `--bytes=SIZE`\n    fn write(&mut self, mut buf: &[u8]) -> io::Result<usize> {\n        // If the length of `buf` exceeds the number of bytes remaining\n        // in the current chunk, we will need to write to multiple\n        // different underlying writers. In that case, each iteration of\n        // this loop writes to the underlying writer that corresponds to\n        // the current chunk number.\n        let mut carryover_bytes_written: usize = 0;\n        loop {\n            if buf.is_empty() {\n                return Ok(carryover_bytes_written);\n            }\n\n            if self.num_bytes_remaining_in_current_chunk == 0 {\n                // Increment the chunk number, reset the number of bytes remaining, and instantiate the new underlying writer.\n                self.num_chunks_written += 1;\n                self.num_bytes_remaining_in_current_chunk = self.chunk_size;\n\n                // Allocate the new file, since at this point we know there are bytes to be written to it.\n                let filename = self\n                    .filename_iterator\n                    .next()\n                    .ok_or_else(|| io::Error::other(\"output file suffixes exhausted\"))?;\n                if self.settings.verbose {\n                    println!(\"creating file {}\", filename.quote());\n                }\n                self.inner = self.settings.instantiate_current_writer(&filename, true)?;\n            }\n\n            // If the capacity of this chunk is greater than the number of\n            // bytes in `buf`, then write all the bytes in `buf`. Otherwise,\n            // write enough bytes to fill the current chunk, then increment\n            // the chunk number and repeat.\n            let buf_len = buf.len();\n            if (buf_len as u64) < self.num_bytes_remaining_in_current_chunk {\n                let num_bytes_written = custom_write(buf, &mut self.inner, self.settings)?;\n                self.num_bytes_remaining_in_current_chunk -= num_bytes_written as u64;\n                return Ok(carryover_bytes_written + num_bytes_written);\n            } else {\n                // Write enough bytes to fill the current chunk.\n                //\n                // Conversion to usize is safe because we checked that\n                // self.num_bytes_remaining_in_current_chunk is lower than\n                // n, which is already usize.\n                let i = self.num_bytes_remaining_in_current_chunk as usize;\n                let num_bytes_written = custom_write(&buf[..i], &mut self.inner, self.settings)?;\n                self.num_bytes_remaining_in_current_chunk -= num_bytes_written as u64;\n\n                // It's possible that the underlying writer did not\n                // write all the bytes.\n                if num_bytes_written < i {\n                    return Ok(carryover_bytes_written + num_bytes_written);\n                } else {\n                    // Move the window to look at only the remaining bytes.\n                    buf = &buf[i..];\n\n                    // Remember for the next iteration that we wrote these bytes.\n                    carryover_bytes_written += num_bytes_written;\n                }\n            }\n        }\n    }\n    fn flush(&mut self) -> io::Result<()> {\n        self.inner.flush()\n    }\n}\n/// Write a certain number of lines to one file, then move on to another one.\n///\n/// This struct maintains an underlying writer representing the\n/// current chunk of the output. If a call to [`write`] would cause\n/// the underlying writer to write more than the allowed number of\n/// lines, a new writer is created and the excess lines are written to\n/// that one instead. As many new underlying writers are created as\n/// needed to write all the lines in the input buffer.\nstruct LineChunkWriter<'a> {\n    /// Parameters for creating the underlying writer for each new chunk.\n    settings: &'a Settings,\n\n    /// The maximum number of lines allowed for a single chunk of output.\n    chunk_size: u64,\n\n    /// Running total of number of chunks that have been completed.\n    num_chunks_written: u64,\n\n    /// Remaining capacity in number of lines in the current chunk.\n    ///\n    /// This number starts at `chunk_size` and decreases as lines are\n    /// written. Once it reaches zero, a writer for a new chunk is\n    /// initialized and this number gets reset to `chunk_size`.\n    num_lines_remaining_in_current_chunk: u64,\n\n    /// The underlying writer for the current chunk.\n    ///\n    /// Once the number of lines written to this writer exceeds\n    /// `chunk_size`, a new writer is initialized and assigned to this\n    /// field.\n    inner: BufWriter<Box<dyn Write>>,\n\n    /// Iterator that yields filenames for each chunk.\n    filename_iterator: FilenameIterator<'a>,\n}\nimpl<'a> LineChunkWriter<'a> {\n    fn new(chunk_size: u64, settings: &'a Settings) -> UResult<Self> {\n        let mut filename_iterator = FilenameIterator::new(&settings.prefix, &settings.suffix)?;\n        let inner = Self::start_new_chunk(settings, &mut filename_iterator)?;\n        Ok(LineChunkWriter {\n            settings,\n            chunk_size,\n            num_lines_remaining_in_current_chunk: chunk_size,\n            num_chunks_written: 0,\n            inner,\n            filename_iterator,\n        })\n    }\n\n    fn start_new_chunk(\n        settings: &Settings,\n        filename_iterator: &mut FilenameIterator,\n    ) -> io::Result<BufWriter<Box<dyn Write>>> {\n        let filename = filename_iterator\n            .next()\n            .ok_or_else(|| io::Error::other(\"output file suffixes exhausted\"))?;\n        if settings.verbose {\n            println!(\"creating file {}\", filename.quote());\n        }\n        settings.instantiate_current_writer(&filename, true)\n    }\n}\nimpl Write for LineChunkWriter<'_> {\n    /// Implements `--lines=NUMBER`\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        // If the number of lines in `buf` exceeds the number of lines\n        // remaining in the current chunk, we will need to write to\n        // multiple different underlying writers. In that case, each\n        // iteration of this loop writes to the underlying writer that\n        // corresponds to the current chunk number.\n        let mut prev = 0;\n        let mut total_bytes_written = 0;\n        let sep = self.settings.separator;\n        for i in memchr::memchr_iter(sep, buf) {\n            // If we have exceeded the number of lines to write in the\n            // current chunk, then start a new chunk and its\n            // corresponding writer.\n            if self.num_lines_remaining_in_current_chunk == 0 {\n                self.num_chunks_written += 1;\n                self.inner = Self::start_new_chunk(self.settings, &mut self.filename_iterator)?;\n                self.num_lines_remaining_in_current_chunk = self.chunk_size;\n            }\n\n            // Write the line, starting from *after* the previous\n            // separator character and ending *after* the current\n            // separator character.\n            let num_bytes_written = custom_write(&buf[prev..=i], &mut self.inner, self.settings)?;\n            total_bytes_written += num_bytes_written;\n            prev = i + 1;\n            self.num_lines_remaining_in_current_chunk -= 1;\n        }\n\n        // There might be bytes remaining in the buffer, and we write\n        // them to the current chunk. But first, we may need to rotate\n        // the current chunk in case it has already reached its line\n        // limit.\n        if prev < buf.len() {\n            if self.num_lines_remaining_in_current_chunk == 0 {\n                self.inner = Self::start_new_chunk(self.settings, &mut self.filename_iterator)?;\n                self.num_lines_remaining_in_current_chunk = self.chunk_size;\n            }\n            let num_bytes_written =\n                custom_write(&buf[prev..buf.len()], &mut self.inner, self.settings)?;\n            total_bytes_written += num_bytes_written;\n        }\n        Ok(total_bytes_written)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        self.inner.flush()\n    }\n}\n/// Output file parameters\nstruct OutFile {\n    filename: String,\n    maybe_writer: Option<BufWriter<Box<dyn Write>>>,\n    is_new: bool,\n}\n/// A set of output files\n/// Used in [`n_chunks_by_byte`], [`n_chunks_by_line`]\n/// and [`n_chunks_by_line_round_robin`] functions.\ntype OutFiles = Vec<OutFile>;\ntrait ManageOutFiles {\n    fn instantiate_writer(\n        &mut self,\n        idx: usize,\n        settings: &Settings,\n    ) -> UResult<&mut BufWriter<Box<dyn Write>>>;\n    /// Initialize a new set of output files\n    /// Each OutFile is generated with filename, while the writer for it could be\n    /// optional, to be instantiated later by the calling function as needed.\n    /// Optional writers could happen in the following situations:\n    /// * in [`n_chunks_by_line`] and [`n_chunks_by_line_round_robin`] if `elide_empty_files` parameter is set to `true`\n    /// * if the number of files is greater than system limit for open files\n    fn init(num_files: u64, settings: &Settings, is_writer_optional: bool) -> UResult<Self>\n    where\n        Self: Sized;\n    /// Get the writer for the output file by index.\n    /// If system limit of open files has been reached\n    /// it will try to close one of previously instantiated writers\n    /// to free up resources and re-try instantiating current writer,\n    /// except for `--filter` mode.\n    /// The writers that get closed to free up resources for the current writer\n    /// are flagged as `is_new=false`, so they can be re-opened for appending\n    /// instead of created anew if we need to keep writing into them later,\n    /// i.e. in case of round robin distribution as in [`n_chunks_by_line_round_robin`]\n    fn get_writer(\n        &mut self,\n        idx: usize,\n        settings: &Settings,\n    ) -> UResult<&mut BufWriter<Box<dyn Write>>>;\n}",
      "file_name": "coreutils/src/uu\\split\\src\\split.rs"
    },
    {
      "chunk": "impl ManageOutFiles for OutFiles {\n    fn init(num_files: u64, settings: &Settings, is_writer_optional: bool) -> UResult<Self> {\n        // This object is responsible for creating the filename for each chunk\n        let mut filename_iterator: FilenameIterator<'_> =\n            FilenameIterator::new(&settings.prefix, &settings.suffix)\n                .map_err(|e| io::Error::other(format!(\"{e}\")))?;\n        let mut out_files: Self = Self::new();\n        for _ in 0..num_files {\n            let filename = filename_iterator\n                .next()\n                .ok_or_else(|| USimpleError::new(1, \"output file suffixes exhausted\"))?;\n            let maybe_writer = if is_writer_optional {\n                None\n            } else {\n                let instantiated = settings.instantiate_current_writer(filename.as_str(), true);\n                // If there was an error instantiating the writer for a file,\n                // it could be due to hitting the system limit of open files,\n                // so record it as None and let [`get_writer`] function handle closing/re-opening\n                // of writers as needed within system limits.\n                // However, for `--filter` child process writers - propagate the error,\n                // as working around system limits of open files for child shell processes\n                // is currently not supported (same as in GNU)\n                match instantiated {\n                    Ok(writer) => Some(writer),\n                    Err(e) if settings.filter.is_some() => {\n                        return Err(e.into());\n                    }\n                    Err(_) => None,\n                }\n            };\n            out_files.push(OutFile {\n                filename,\n                maybe_writer,\n                is_new: true,\n            });\n        }\n        Ok(out_files)\n    }\n\n    fn instantiate_writer(\n        &mut self,\n        idx: usize,\n        settings: &Settings,\n    ) -> UResult<&mut BufWriter<Box<dyn Write>>> {\n        let mut count = 0;\n        // Use-case for doing multiple tries of closing fds:\n        // E.g. split running in parallel to other processes (e.g. another split) doing similar stuff,\n        // sharing the same limits. In this scenario, after closing one fd, the other process\n        // might \"steel\" the freed fd and open a file on its side. Then it would be beneficial\n        // if split would be able to close another fd before cancellation.\n        'loop1: loop {\n            let filename_to_open = self[idx].filename.as_str();\n            let file_to_open_is_new = self[idx].is_new;\n            let maybe_writer =\n                settings.instantiate_current_writer(filename_to_open, file_to_open_is_new);\n            if let Ok(writer) = maybe_writer {\n                self[idx].maybe_writer = Some(writer);\n                return Ok(self[idx].maybe_writer.as_mut().unwrap());\n            }\n\n            if settings.filter.is_some() {\n                // Propagate error if in `--filter` mode\n                return Err(maybe_writer.err().unwrap().into());\n            }\n\n            // Could have hit system limit for open files.\n            // Try to close one previously instantiated writer first\n            for (i, out_file) in self.iter_mut().enumerate() {\n                if i != idx && out_file.maybe_writer.is_some() {\n                    out_file.maybe_writer.as_mut().unwrap().flush()?;\n                    out_file.maybe_writer = None;\n                    out_file.is_new = false;\n                    count += 1;\n\n                    // And then try to instantiate the writer again\n                    continue 'loop1;\n                }\n            }\n\n            // If this fails - give up and propagate the error\n            uucore::show_error!(\n                \"at file descriptor limit, but no file descriptor left to close. Closed {count} writers before.\"\n            );\n            return Err(maybe_writer.err().unwrap().into());\n        }\n    }\n\n    fn get_writer(\n        &mut self,\n        idx: usize,\n        settings: &Settings,\n    ) -> UResult<&mut BufWriter<Box<dyn Write>>> {\n        if self[idx].maybe_writer.is_some() {\n            Ok(self[idx].maybe_writer.as_mut().unwrap())\n        } else {\n            // Writer was not instantiated upfront or was temporarily closed due to system resources constraints.\n            // Instantiate it and record for future use.\n            self.instantiate_writer(idx, settings)\n        }\n    }\n}\n/// Split a file or STDIN into a specific number of chunks by byte.\n///\n/// When file size cannot be evenly divided into the number of chunks of the same size,\n/// the first X chunks are 1 byte longer than the rest,\n/// where X is a modulus reminder of (file size % number of chunks)\n///\n/// In Kth chunk of N mode - writes to STDOUT the contents of the chunk identified by `kth_chunk`\n///\n/// In N chunks mode - this function always creates one output file for each chunk, even\n/// if there is an error reading or writing one of the chunks or if\n/// the input file is truncated. However, if the `--filter` option is\n/// being used, then files will only be created if `$FILE` variable was used\n/// in filter command,\n/// i.e. `split -n 10 --filter='head -c1 > $FILE' in`\n///\n/// # Errors\n///\n/// This function returns an error if there is a problem reading from\n/// `reader` or writing to one of the output files or stdout.\n///\n/// # See also\n///\n/// * [`n_chunks_by_line`], which splits its input into a specific number of chunks by line.\n///\n/// Implements `--number=CHUNKS`\n/// Where CHUNKS\n/// * N\n/// * K/N\nfn n_chunks_by_byte<R>(\n    settings: &Settings,\n    reader: &mut R,\n    num_chunks: u64,\n    kth_chunk: Option<u64>,\n) -> UResult<()>\nwhere\n    R: BufRead,\n{\n    // Get the size of the input in bytes\n    let initial_buf = &mut Vec::new();\n    let mut num_bytes = get_input_size(&settings.input, reader, initial_buf, settings.io_blksize)?;\n    let mut reader = initial_buf.chain(reader);\n\n    // If input file is empty and we would not have determined the Kth chunk\n    // in the Kth chunk of N chunk mode, then terminate immediately.\n    // This happens on `split -n 3/10 /dev/null`, for example.\n    if kth_chunk.is_some() && num_bytes == 0 {\n        return Ok(());\n    }\n\n    // If the requested number of chunks exceeds the number of bytes\n    // in the input:\n    // * in Kth chunk of N mode - just write empty byte string to stdout\n    //   NOTE: the `elide_empty_files` parameter is ignored here\n    //   as we do not generate any files\n    //   and instead writing to stdout\n    // * In N chunks mode - if the `elide_empty_files` parameter is enabled,\n    //   then behave as if the number of chunks was set to the number of\n    //   bytes in the file. This ensures that we don't write empty\n    //   files. Otherwise, just write the `num_chunks - num_bytes` empty files.\n    let num_chunks = if kth_chunk.is_none() && settings.elide_empty_files && num_chunks > num_bytes\n    {\n        num_bytes\n    } else {\n        num_chunks\n    };\n\n    // If we would have written zero chunks of output, then terminate\n    // immediately. This happens on `split -e -n 3 /dev/null`, for\n    // example.\n    if num_chunks == 0 {\n        return Ok(());\n    }\n\n    // In Kth chunk of N mode - we will write to stdout instead of to a file.\n    let mut stdout_writer = io::stdout().lock();\n    // In N chunks mode - we will write to `num_chunks` files\n    let mut out_files: OutFiles = OutFiles::new();\n\n    // Calculate chunk size base and modulo reminder\n    // to be used in calculating chunk_size later on\n    let chunk_size_base = num_bytes / num_chunks;\n    let chunk_size_reminder = num_bytes % num_chunks;\n\n    // If in N chunks mode\n    // Create one writer for each chunk.\n    // This will create each of the underlying files\n    // or stdin pipes to child shell/command processes if in `--filter` mode\n    if kth_chunk.is_none() {\n        out_files = OutFiles::init(num_chunks, settings, false)?;\n    }\n\n    for i in 1_u64..=num_chunks {\n        let chunk_size = chunk_size_base + (chunk_size_reminder > i - 1) as u64;\n        let buf = &mut Vec::new();\n        if num_bytes > 0 {\n            // Read `chunk_size` bytes from the reader into `buf`\n            // except the last.\n            //\n            // The last chunk gets all remaining bytes so that if the number\n            // of bytes in the input file was not evenly divisible by\n            // `num_chunks`, we don't leave any bytes behind.\n            let limit = {\n                if i == num_chunks {\n                    num_bytes\n                } else {\n                    chunk_size\n                }\n            };\n\n            let n_bytes_read = reader.by_ref().take(limit).read_to_end(buf);\n\n            match n_bytes_read {\n                Ok(n_bytes) => {\n                    num_bytes -= n_bytes as u64;\n                }\n                Err(error) => {\n                    return Err(USimpleError::new(\n                        1,\n                        format!(\"{}: cannot read from input : {error}\", settings.input),\n                    ));\n                }\n            }\n\n            match kth_chunk {\n                Some(chunk_number) => {\n                    if i == chunk_number {\n                        stdout_writer.write_all(buf)?;\n                        break;\n                    }\n                }\n                None => {\n                    let idx = (i - 1) as usize;\n                    let writer = out_files.get_writer(idx, settings)?;\n                    writer.write_all(buf)?;\n                }\n            }\n        } else {\n            break;\n        }\n    }\n    Ok(())\n}\n/// Split a file or STDIN into a specific number of chunks by line.\n///\n/// It is most likely that input cannot be evenly divided into the number of chunks\n/// of the same size in bytes or number of lines, since we cannot break lines.\n/// It is also likely that there could be empty files (having `elide_empty_files` is disabled)\n/// when a long line overlaps one or more chunks.\n///\n/// In Kth chunk of N mode - writes to STDOUT the contents of the chunk identified by `kth_chunk`\n/// Note: the `elide_empty_files` flag is ignored in this mode\n///\n/// In N chunks mode - this function always creates one output file for each chunk, even\n/// if there is an error reading or writing one of the chunks or if\n/// the input file is truncated. However, if the `--filter` option is\n/// being used, then files will only be created if `$FILE` variable was used\n/// in filter command,\n/// i.e. `split -n l/10 --filter='head -c1 > $FILE' in`\n///\n/// # Errors\n///\n/// This function returns an error if there is a problem reading from\n/// `reader` or writing to one of the output files.\n///\n/// # See also\n///\n/// * [`n_chunks_by_byte`], which splits its input into a specific number of chunks by byte.\n///\n/// Implements `--number=CHUNKS`\n/// Where CHUNKS\n/// * l/N\n/// * l/K/N",
      "file_name": "coreutils/src/uu\\split\\src\\split.rs"
    },
    {
      "chunk": "fn n_chunks_by_line<R>(\n    settings: &Settings,\n    reader: &mut R,\n    num_chunks: u64,\n    kth_chunk: Option<u64>,\n) -> UResult<()>\nwhere\n    R: BufRead,\n{\n    // Get the size of the input in bytes and compute the number\n    // of bytes per chunk.\n    let initial_buf = &mut Vec::new();\n    let num_bytes = get_input_size(&settings.input, reader, initial_buf, settings.io_blksize)?;\n    let reader = initial_buf.chain(reader);\n\n    // If input file is empty and we would not have determined the Kth chunk\n    // in the Kth chunk of N chunk mode, then terminate immediately.\n    // This happens on `split -n l/3/10 /dev/null`, for example.\n    // Similarly, if input file is empty and `elide_empty_files` parameter is enabled,\n    // then we would have written zero chunks of output,\n    // so terminate immediately as well.\n    // This happens on `split -e -n l/3 /dev/null`, for example.\n    if num_bytes == 0 && (kth_chunk.is_some() || settings.elide_empty_files) {\n        return Ok(());\n    }\n\n    // In Kth chunk of N mode - we will write to stdout instead of to a file.\n    let mut stdout_writer = io::stdout().lock();\n    // In N chunks mode - we will write to `num_chunks` files\n    let mut out_files: OutFiles = OutFiles::new();\n\n    // Calculate chunk size base and modulo reminder\n    // to be used in calculating `num_bytes_should_be_written` later on\n    let chunk_size_base = num_bytes / num_chunks;\n    let chunk_size_reminder = num_bytes % num_chunks;\n\n    // If in N chunks mode\n    // Generate filenames for each file and\n    // if `elide_empty_files` parameter is NOT enabled - instantiate the writer\n    // which will create each of the underlying files or stdin pipes\n    // to child shell/command processes if in `--filter` mode.\n    // Otherwise keep writer optional, to be instantiated later if there is data\n    // to write for the associated chunk.\n    if kth_chunk.is_none() {\n        out_files = OutFiles::init(num_chunks, settings, settings.elide_empty_files)?;\n    }\n\n    let mut chunk_number = 1;\n    let sep = settings.separator;\n    let mut num_bytes_should_be_written = chunk_size_base + (chunk_size_reminder > 0) as u64;\n    let mut num_bytes_written = 0;\n\n    for line_result in reader.split(sep) {\n        let mut line = line_result?;\n        // add separator back in at the end of the line,\n        // since `reader.split(sep)` removes it,\n        // except if the last line did not end with separator character\n        if (num_bytes_written + line.len() as u64) < num_bytes {\n            line.push(sep);\n        }\n        let bytes = line.as_slice();\n\n        match kth_chunk {\n            Some(kth) => {\n                if chunk_number == kth {\n                    stdout_writer.write_all(bytes)?;\n                }\n            }\n            None => {\n                // Should write into a file\n                let idx = (chunk_number - 1) as usize;\n                let writer = out_files.get_writer(idx, settings)?;\n                custom_write_all(bytes, writer, settings)?;\n            }\n        }\n\n        // Advance to the next chunk if the current one is filled.\n        // There could be a situation when a long line, which started in current chunk,\n        // would overlap the next chunk (or even several next chunks),\n        // and since we cannot break lines for this split strategy, we could end up with\n        // empty files in place(s) of skipped chunk(s)\n        let num_line_bytes = bytes.len() as u64;\n        num_bytes_written += num_line_bytes;\n        let mut skipped = -1;\n        while num_bytes_should_be_written <= num_bytes_written {\n            num_bytes_should_be_written +=\n                chunk_size_base + (chunk_size_reminder > chunk_number) as u64;\n            chunk_number += 1;\n            skipped += 1;\n        }\n\n        // If a chunk was skipped and `elide_empty_files` flag is set,\n        // roll chunk_number back to preserve sequential continuity\n        // of file names for files written to,\n        // except for Kth chunk of N mode\n        if settings.elide_empty_files && skipped > 0 && kth_chunk.is_none() {\n            chunk_number -= skipped as u64;\n        }\n\n        if let Some(kth) = kth_chunk {\n            if chunk_number > kth {\n                break;\n            }\n        }\n    }\n    Ok(())\n}\n/// Split a file or STDIN into a specific number of chunks by line, but\n/// assign lines via round-robin.\n/// Note: There is no need to know the size of the input upfront for this method,\n/// since the lines are assigned to chunks randomly and the size of each chunk\n/// does not need to be estimated. As a result, \"infinite\" inputs are supported\n/// for this method, i.e. `yes | split -n r/10` or `yes | split -n r/3/11`\n///\n/// In Kth chunk of N mode - writes to stdout the contents of the chunk identified by `kth_chunk`\n///\n/// In N chunks mode - this function always creates one output file for each chunk, even\n/// if there is an error reading or writing one of the chunks or if\n/// the input file is truncated. However, if the `--filter` option is\n/// being used, then files will only be created if `$FILE` variable was used\n/// in filter command,\n/// i.e. `split -n r/10 --filter='head -c1 > $FILE' in`\n///\n/// # Errors\n///\n/// This function returns an error if there is a problem reading from\n/// `reader` or writing to one of the output files.\n///\n/// # See also\n///\n/// * [`n_chunks_by_line`], which splits its input into a specific number of chunks by line.\n///\n/// Implements `--number=CHUNKS`\n/// Where CHUNKS\n/// * r/N\n/// * r/K/N\nfn n_chunks_by_line_round_robin<R>(\n    settings: &Settings,\n    reader: &mut R,\n    num_chunks: u64,\n    kth_chunk: Option<u64>,\n) -> UResult<()>\nwhere\n    R: BufRead,\n{\n    // In Kth chunk of N mode - we will write to stdout instead of to a file.\n    let mut stdout_writer = io::stdout().lock();\n    // In N chunks mode - we will write to `num_chunks` files\n    let mut out_files: OutFiles = OutFiles::new();\n\n    // If in N chunks mode\n    // Create one writer for each chunk.\n    // This will create each of the underlying files\n    // or stdin pipes to child shell/command processes if in `--filter` mode\n    if kth_chunk.is_none() {\n        out_files = OutFiles::init(num_chunks, settings, settings.elide_empty_files)?;\n    }\n\n    let num_chunks: usize = num_chunks.try_into().unwrap();\n    let sep = settings.separator;\n    let mut closed_writers = 0;\n\n    let mut i = 0;\n    loop {\n        let line = &mut Vec::new();\n        let num_bytes_read = reader.by_ref().read_until(sep, line)?;\n\n        // if there is nothing else to read - exit the loop\n        if num_bytes_read == 0 {\n            break;\n        };\n\n        let bytes = line.as_slice();\n        if let Some(chunk_number) = kth_chunk {\n            if (i % num_chunks) == (chunk_number - 1) as usize {\n                stdout_writer.write_all(bytes)?;\n            }\n        } else {\n            let writer = out_files.get_writer(i % num_chunks, settings)?;\n            let writer_stdin_open = custom_write_all(bytes, writer, settings)?;\n            if !writer_stdin_open {\n                closed_writers += 1;\n            }\n        }\n        i += 1;\n        if closed_writers == num_chunks {\n            // all writers are closed - stop reading\n            break;\n        }\n    }\n    Ok(())\n}\n/// Like `io::Lines`, but includes the line ending character.\n///\n/// This struct is generally created by calling `lines_with_sep` on a\n/// reader.\npub struct LinesWithSep<R> {\n    inner: R,\n    separator: u8,\n}\nimpl<R> Iterator for LinesWithSep<R>\nwhere\n    R: BufRead,\n{\n    type Item = io::Result<Vec<u8>>;\n\n    /// Read bytes from a buffer up to the requested number of lines.\n    fn next(&mut self) -> Option<Self::Item> {\n        let mut buf = vec![];\n        match self.inner.read_until(self.separator, &mut buf) {\n            Ok(0) => None,\n            Ok(_) => Some(Ok(buf)),\n            Err(e) => Some(Err(e)),\n        }\n    }\n}\n/// Like `std::str::lines` but includes the line ending character.\n///\n/// The `separator` defines the character to interpret as the line\n/// ending. For the usual notion of \"line\", set this to `b'\\n'`.\npub fn lines_with_sep<R>(reader: R, separator: u8) -> LinesWithSep<R>\nwhere\n    R: BufRead,\n{\n    LinesWithSep {\n        inner: reader,\n        separator,\n    }\n}\nfn line_bytes<R>(settings: &Settings, reader: &mut R, chunk_size: usize) -> UResult<()>\nwhere\n    R: BufRead,\n{\n    let mut filename_iterator = FilenameIterator::new(&settings.prefix, &settings.suffix)?;\n\n    // Initialize the writer just to satisfy the compiler. It is going\n    // to be overwritten for sure at the beginning of the loop below\n    // because we start with `remaining == 0`, indicating that a new\n    // chunk should start.\n    let mut writer: BufWriter<Box<dyn Write>> = BufWriter::new(Box::new(io::Cursor::new(vec![])));\n\n    let mut remaining = 0;\n    for line in lines_with_sep(reader, settings.separator) {\n        let line = line?;\n        let mut line = &line[..];\n        loop {\n            if remaining == 0 {\n                let filename = filename_iterator\n                    .next()\n                    .ok_or_else(|| USimpleError::new(1, \"output file suffixes exhausted\"))?;\n                if settings.verbose {\n                    println!(\"creating file {}\", filename.quote());\n                }\n                writer = settings.instantiate_current_writer(&filename, true)?;\n                remaining = chunk_size;\n            }\n\n            // Special case: if this is the last line and it doesn't end\n            // with a newline character, then count its length as though\n            // it did end with a newline. If that puts it over the edge\n            // of this chunk, continue to the next chunk.\n            if line.len() == remaining\n                && remaining < chunk_size\n                && line[line.len() - 1] != settings.separator\n            {\n                remaining = 0;\n                continue;\n            }\n\n            // If the entire line fits in this chunk, write it and\n            // continue to the next line.\n            if line.len() <= remaining {\n                custom_write_all(line, &mut writer, settings)?;\n                remaining -= line.len();\n                break;\n            }\n\n            // If the line is too large to fit in *any* chunk and we are\n            // at the start of a new chunk, write as much as we can of\n            // it and pass the remainder along to the next chunk.\n            if line.len() > chunk_size && remaining == chunk_size {\n                custom_write_all(&line[..chunk_size], &mut writer, settings)?;\n                line = &line[chunk_size..];\n                remaining = 0;\n                continue;\n            }\n\n            // If the line is too large to fit in *this* chunk, but\n            // might otherwise fit in the next chunk, then just continue\n            // to the next chunk and let it be handled there.\n            remaining = 0;\n        }\n    }\n    Ok(())\n}\n#[allow(clippy::cognitive_complexity)]",
      "file_name": "coreutils/src/uu\\split\\src\\split.rs"
    },
    {
      "chunk": "fn split(settings: &Settings) -> UResult<()> {\n    let r_box = if settings.input == \"-\" {\n        Box::new(stdin()) as Box<dyn Read>\n    } else {\n        let r = File::open(Path::new(&settings.input))\n            .map_err_context(|| format!(\"cannot open {} for reading\", settings.input.quote()))?;\n        Box::new(r) as Box<dyn Read>\n    };\n    let mut reader = if let Some(c) = settings.io_blksize {\n        BufReader::with_capacity(c.try_into().unwrap(), r_box)\n    } else {\n        BufReader::new(r_box)\n    };\n\n    match settings.strategy {\n        Strategy::Number(NumberType::Bytes(num_chunks)) => {\n            // split_into_n_chunks_by_byte(settings, &mut reader, num_chunks)\n            n_chunks_by_byte(settings, &mut reader, num_chunks, None)\n        }\n        Strategy::Number(NumberType::KthBytes(chunk_number, num_chunks)) => {\n            // kth_chunks_by_byte(settings, &mut reader, chunk_number, num_chunks)\n            n_chunks_by_byte(settings, &mut reader, num_chunks, Some(chunk_number))\n        }\n        Strategy::Number(NumberType::Lines(num_chunks)) => {\n            n_chunks_by_line(settings, &mut reader, num_chunks, None)\n        }\n        Strategy::Number(NumberType::KthLines(chunk_number, num_chunks)) => {\n            n_chunks_by_line(settings, &mut reader, num_chunks, Some(chunk_number))\n        }\n        Strategy::Number(NumberType::RoundRobin(num_chunks)) => {\n            n_chunks_by_line_round_robin(settings, &mut reader, num_chunks, None)\n        }\n        Strategy::Number(NumberType::KthRoundRobin(chunk_number, num_chunks)) => {\n            n_chunks_by_line_round_robin(settings, &mut reader, num_chunks, Some(chunk_number))\n        }\n        Strategy::Lines(chunk_size) => {\n            let mut writer = LineChunkWriter::new(chunk_size, settings)?;\n            match io::copy(&mut reader, &mut writer) {\n                Ok(_) => Ok(()),\n                Err(e) => match e.kind() {\n                    // TODO Since the writer object controls the creation of\n                    // new files, we need to rely on the `io::Result`\n                    // returned by its `write()` method to communicate any\n                    // errors to this calling scope. If a new file cannot be\n                    // created because we have exceeded the number of\n                    // allowable filenames, we use `ErrorKind::Other` to\n                    // indicate that. A special error message needs to be\n                    // printed in that case.\n                    ErrorKind::Other => Err(USimpleError::new(1, format!(\"{e}\"))),\n                    _ => Err(uio_error!(e, \"input/output error\")),\n                },\n            }\n        }\n        Strategy::Bytes(chunk_size) => {\n            let mut writer = ByteChunkWriter::new(chunk_size, settings)?;\n            match io::copy(&mut reader, &mut writer) {\n                Ok(_) => Ok(()),\n                Err(e) => match e.kind() {\n                    // TODO Since the writer object controls the creation of\n                    // new files, we need to rely on the `io::Result`\n                    // returned by its `write()` method to communicate any\n                    // errors to this calling scope. If a new file cannot be\n                    // created because we have exceeded the number of\n                    // allowable filenames, we use `ErrorKind::Other` to\n                    // indicate that. A special error message needs to be\n                    // printed in that case.\n                    ErrorKind::Other => Err(USimpleError::new(1, format!(\"{e}\"))),\n                    _ => Err(uio_error!(e, \"input/output error\")),\n                },\n            }\n        }\n        Strategy::LineBytes(chunk_size) => line_bytes(settings, &mut reader, chunk_size as usize),\n    }\n}",
      "file_name": "coreutils/src/uu\\split\\src\\split.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n//! Determine the strategy for breaking up the input (file or stdin) into chunks\n//! based on the command line options\nuse crate::{OPT_BYTES, OPT_LINE_BYTES, OPT_LINES, OPT_NUMBER};\nuse clap::{ArgMatches, parser::ValueSource};\nuse thiserror::Error;\nuse uucore::{\n    display::Quotable,\n    parser::parse_size::{ParseSizeError, parse_size_u64, parse_size_u64_max},\n};\n/// Sub-strategy of the [`Strategy::Number`]\n/// Splitting a file into a specific number of chunks.\n#[derive(Debug, PartialEq)]\npub enum NumberType {\n    /// Split into a specific number of chunks by byte.\n    Bytes(u64),\n\n    /// Split into a specific number of chunks by byte\n    /// but output only the *k*th chunk.\n    KthBytes(u64, u64),\n\n    /// Split into a specific number of chunks by line (approximately).\n    Lines(u64),\n\n    /// Split into a specific number of chunks by line\n    /// (approximately), but output only the *k*th chunk.\n    KthLines(u64, u64),\n\n    /// Assign lines via round-robin to the specified number of output chunks.\n    RoundRobin(u64),\n\n    /// Assign lines via round-robin to the specified number of output\n    /// chunks, but output only the *k*th chunk.\n    KthRoundRobin(u64, u64),\n}\nimpl NumberType {\n    /// The number of chunks for this number type.\n    pub fn num_chunks(&self) -> u64 {\n        match self {\n            Self::Bytes(n) => *n,\n            Self::KthBytes(_, n) => *n,\n            Self::Lines(n) => *n,\n            Self::KthLines(_, n) => *n,\n            Self::RoundRobin(n) => *n,\n            Self::KthRoundRobin(_, n) => *n,\n        }\n    }\n}\n/// An error due to an invalid parameter to the `-n` command-line option.\n#[derive(Debug, PartialEq, Error)]\npub enum NumberTypeError {\n    /// The number of chunks was invalid.\n    ///\n    /// This can happen if the value of `N` in any of the following\n    /// command-line options is not a positive integer:\n    ///\n    /// ```ignore\n    /// -n N\n    /// -n K/N\n    /// -n l/N\n    /// -n l/K/N\n    /// -n r/N\n    /// -n r/K/N\n    /// ```\n    #[error(\"invalid number of chunks: {}\", .0.quote())]\n    NumberOfChunks(String),\n\n    /// The chunk number was invalid.\n    ///\n    /// This can happen if the value of `K` in any of the following\n    /// command-line options is not a positive integer\n    /// or if `K` is 0\n    /// or if `K` is greater than `N`:\n    ///\n    /// ```ignore\n    /// -n K/N\n    /// -n l/K/N\n    /// -n r/K/N\n    /// ```\n    #[error(\"invalid chunk number: {}\", .0.quote())]\n    ChunkNumber(String),\n}\nimpl NumberType {\n    /// Parse a `NumberType` from a string.\n    ///\n    /// The following strings are valid arguments:\n    ///\n    /// ```ignore\n    /// \"N\"\n    /// \"K/N\"\n    /// \"l/N\"\n    /// \"l/K/N\"\n    /// \"r/N\"\n    /// \"r/K/N\"\n    /// ```\n    ///\n    /// The `N` represents the number of chunks and the `K` represents\n    /// a chunk number.\n    ///\n    /// # Errors\n    ///\n    /// If the string is not one of the valid number types,\n    /// if `K` is not a non-negative integer,\n    /// or if `K` is 0,\n    /// or if `N` is not a positive integer,\n    /// or if `K` is greater than `N`\n    /// then this function returns [`NumberTypeError`].\n    fn from(s: &str) -> Result<Self, NumberTypeError> {\n        fn is_invalid_chunk(chunk_number: u64, num_chunks: u64) -> bool {\n            chunk_number > num_chunks || chunk_number == 0\n        }\n        let mut parts = s.splitn(4, '/');\n        match (parts.next(), parts.next(), parts.next(), parts.next()) {\n            (Some(n_str), None, None, None) => {\n                let num_chunks = parse_size_u64(n_str)\n                    .map_err(|_| NumberTypeError::NumberOfChunks(n_str.to_string()))?;\n                if num_chunks > 0 {\n                    Ok(Self::Bytes(num_chunks))\n                } else {\n                    Err(NumberTypeError::NumberOfChunks(s.to_string()))\n                }\n            }\n            (Some(k_str), Some(n_str), None, None)\n                if !k_str.starts_with('l') && !k_str.starts_with('r') =>\n            {\n                let num_chunks = parse_size_u64(n_str)\n                    .map_err(|_| NumberTypeError::NumberOfChunks(n_str.to_string()))?;\n                let chunk_number = parse_size_u64(k_str)\n                    .map_err(|_| NumberTypeError::ChunkNumber(k_str.to_string()))?;\n                if is_invalid_chunk(chunk_number, num_chunks) {\n                    return Err(NumberTypeError::ChunkNumber(k_str.to_string()));\n                }\n                Ok(Self::KthBytes(chunk_number, num_chunks))\n            }\n            (Some(\"l\"), Some(n_str), None, None) => {\n                let num_chunks = parse_size_u64(n_str)\n                    .map_err(|_| NumberTypeError::NumberOfChunks(n_str.to_string()))?;\n                Ok(Self::Lines(num_chunks))\n            }\n            (Some(\"l\"), Some(k_str), Some(n_str), None) => {\n                let num_chunks = parse_size_u64(n_str)\n                    .map_err(|_| NumberTypeError::NumberOfChunks(n_str.to_string()))?;\n                let chunk_number = parse_size_u64(k_str)\n                    .map_err(|_| NumberTypeError::ChunkNumber(k_str.to_string()))?;\n                if is_invalid_chunk(chunk_number, num_chunks) {\n                    return Err(NumberTypeError::ChunkNumber(k_str.to_string()));\n                }\n                Ok(Self::KthLines(chunk_number, num_chunks))\n            }\n            (Some(\"r\"), Some(n_str), None, None) => {\n                let num_chunks = parse_size_u64(n_str)\n                    .map_err(|_| NumberTypeError::NumberOfChunks(n_str.to_string()))?;\n                Ok(Self::RoundRobin(num_chunks))\n            }\n            (Some(\"r\"), Some(k_str), Some(n_str), None) => {\n                let num_chunks = parse_size_u64(n_str)\n                    .map_err(|_| NumberTypeError::NumberOfChunks(n_str.to_string()))?;\n                let chunk_number = parse_size_u64(k_str)\n                    .map_err(|_| NumberTypeError::ChunkNumber(k_str.to_string()))?;\n                if is_invalid_chunk(chunk_number, num_chunks) {\n                    return Err(NumberTypeError::ChunkNumber(k_str.to_string()));\n                }\n                Ok(Self::KthRoundRobin(chunk_number, num_chunks))\n            }\n            _ => Err(NumberTypeError::NumberOfChunks(s.to_string())),\n        }\n    }\n}\n/// The strategy for breaking up the input file into chunks.\npub enum Strategy {\n    /// Each chunk has the specified number of lines.\n    Lines(u64),\n\n    /// Each chunk has the specified number of bytes.\n    Bytes(u64),\n\n    /// Each chunk has as many lines as possible without exceeding the\n    /// specified number of bytes.\n    LineBytes(u64),\n\n    /// Split the file into this many chunks.\n    ///\n    /// There are several sub-strategies available, as defined by\n    /// [`NumberType`].\n    Number(NumberType),\n}\n/// An error when parsing a chunking strategy from command-line arguments.\n#[derive(Debug, Error)]\npub enum StrategyError {\n    /// Invalid number of lines.\n    #[error(\"invalid number of lines: {0}\")]\n    Lines(ParseSizeError),\n\n    /// Invalid number of bytes.\n    #[error(\"invalid number of bytes: {0}\")]\n    Bytes(ParseSizeError),\n\n    /// Invalid number type.\n    #[error(\"{0}\")]\n    NumberType(NumberTypeError),\n\n    /// Multiple chunking strategies were specified (but only one should be).\n    #[error(\"cannot split in more than one way\")]\n    MultipleWays,\n}\nimpl Strategy {\n    /// Parse a strategy from the command-line arguments.\n    pub fn from(matches: &ArgMatches, obs_lines: Option<&str>) -> Result<Self, StrategyError> {\n        fn get_and_parse(\n            matches: &ArgMatches,\n            option: &str,\n            strategy: fn(u64) -> Strategy,\n            error: fn(ParseSizeError) -> StrategyError,\n        ) -> Result<Strategy, StrategyError> {\n            let s = matches.get_one::<String>(option).unwrap();\n            let n = parse_size_u64_max(s).map_err(error)?;\n            if n > 0 {\n                Ok(strategy(n))\n            } else {\n                Err(error(ParseSizeError::ParseFailure(s.to_string())))\n            }\n        }\n        // Check that the user is not specifying more than one strategy.\n        //\n        // Note: right now, this exact behavior cannot be handled by\n        // overrides_with_all() due to obsolete lines value option\n        match (\n            obs_lines,\n            matches.value_source(OPT_LINES) == Some(ValueSource::CommandLine),\n            matches.value_source(OPT_BYTES) == Some(ValueSource::CommandLine),\n            matches.value_source(OPT_LINE_BYTES) == Some(ValueSource::CommandLine),\n            matches.value_source(OPT_NUMBER) == Some(ValueSource::CommandLine),\n        ) {\n            (Some(v), false, false, false, false) => {\n                let v = parse_size_u64_max(v).map_err(|_| {\n                    StrategyError::Lines(ParseSizeError::ParseFailure(v.to_string()))\n                })?;\n                if v > 0 {\n                    Ok(Self::Lines(v))\n                } else {\n                    Err(StrategyError::Lines(ParseSizeError::ParseFailure(\n                        v.to_string(),\n                    )))\n                }\n            }\n            (None, false, false, false, false) => Ok(Self::Lines(1000)),\n            (None, true, false, false, false) => {\n                get_and_parse(matches, OPT_LINES, Self::Lines, StrategyError::Lines)\n            }\n            (None, false, true, false, false) => {\n                get_and_parse(matches, OPT_BYTES, Self::Bytes, StrategyError::Bytes)\n            }\n            (None, false, false, true, false) => get_and_parse(\n                matches,\n                OPT_LINE_BYTES,\n                Self::LineBytes,\n                StrategyError::Bytes,\n            ),\n            (None, false, false, false, true) => {\n                let s = matches.get_one::<String>(OPT_NUMBER).unwrap();\n                let number_type = NumberType::from(s).map_err(StrategyError::NumberType)?;\n                Ok(Self::Number(number_type))\n            }\n            _ => Err(StrategyError::MultipleWays),\n        }\n    }\n}\n#[cfg(test)]",
      "file_name": "coreutils/src/uu\\split\\src\\strategy.rs"
    },
    {
      "chunk": "mod tests {\n\n    use crate::{strategy::NumberType, strategy::NumberTypeError};\n\n    #[test]\n    fn test_number_type_from() {\n        assert_eq!(NumberType::from(\"123\").unwrap(), NumberType::Bytes(123));\n        assert_eq!(NumberType::from(\"l/123\").unwrap(), NumberType::Lines(123));\n        assert_eq!(\n            NumberType::from(\"l/123/456\").unwrap(),\n            NumberType::KthLines(123, 456)\n        );\n        assert_eq!(\n            NumberType::from(\"r/123\").unwrap(),\n            NumberType::RoundRobin(123)\n        );\n        assert_eq!(\n            NumberType::from(\"r/123/456\").unwrap(),\n            NumberType::KthRoundRobin(123, 456)\n        );\n    }\n\n    #[test]\n    #[allow(clippy::cognitive_complexity)]\n    fn test_number_type_from_error() {\n        assert_eq!(\n            NumberType::from(\"xyz\").unwrap_err(),\n            NumberTypeError::NumberOfChunks(\"xyz\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"l/xyz\").unwrap_err(),\n            NumberTypeError::NumberOfChunks(\"xyz\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"l/123/xyz\").unwrap_err(),\n            NumberTypeError::NumberOfChunks(\"xyz\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"l/abc/456\").unwrap_err(),\n            NumberTypeError::ChunkNumber(\"abc\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"l/456/123\").unwrap_err(),\n            NumberTypeError::ChunkNumber(\"456\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"r/456/123\").unwrap_err(),\n            NumberTypeError::ChunkNumber(\"456\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"456/123\").unwrap_err(),\n            NumberTypeError::ChunkNumber(\"456\".to_string())\n        );\n        // In GNU split, the number of chunks get precedence:\n        //\n        //     $ split -n l/abc/xyz\n        //     split: invalid number of chunks: \u2018xyz\u2019\n        //\n        assert_eq!(\n            NumberType::from(\"l/abc/xyz\").unwrap_err(),\n            NumberTypeError::NumberOfChunks(\"xyz\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"r/xyz\").unwrap_err(),\n            NumberTypeError::NumberOfChunks(\"xyz\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"r/123/xyz\").unwrap_err(),\n            NumberTypeError::NumberOfChunks(\"xyz\".to_string())\n        );\n        assert_eq!(\n            NumberType::from(\"r/abc/456\").unwrap_err(),\n            NumberTypeError::ChunkNumber(\"abc\".to_string())\n        );\n        // In GNU split, the number of chunks get precedence:\n        //\n        //     $ split -n r/abc/xyz\n        //     split: invalid number of chunks: \u2018xyz\u2019\n        //\n        assert_eq!(\n            NumberType::from(\"r/abc/xyz\").unwrap_err(),\n            NumberTypeError::NumberOfChunks(\"xyz\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_number_type_num_chunks() {\n        assert_eq!(NumberType::from(\"123\").unwrap().num_chunks(), 123);\n        assert_eq!(NumberType::from(\"123/456\").unwrap().num_chunks(), 456);\n        assert_eq!(NumberType::from(\"l/123\").unwrap().num_chunks(), 123);\n        assert_eq!(NumberType::from(\"l/123/456\").unwrap().num_chunks(), 456);\n        assert_eq!(NumberType::from(\"r/123\").unwrap().num_chunks(), 123);\n        assert_eq!(NumberType::from(\"r/123/456\").unwrap().num_chunks(), 456);\n    }\n}",
      "file_name": "coreutils/src/uu\\split\\src\\strategy.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n#[cfg(unix)]\npub use self::unix::instantiate_current_writer;\n#[cfg(unix)]\npub use self::unix::paths_refer_to_same_file;\n#[cfg(windows)]\npub use self::windows::instantiate_current_writer;\n#[cfg(windows)]\npub use self::windows::paths_refer_to_same_file;\n#[cfg(unix)]\nmod unix;\n#[cfg(windows)]\nmod windows;",
      "file_name": "coreutils/src/uu\\split\\src\\platform\\mod.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nuse std::env;\nuse std::io::Write;\nuse std::io::{BufWriter, Error, Result};\nuse std::path::Path;\nuse std::process::{Child, Command, Stdio};\nuse uucore::error::USimpleError;\nuse uucore::fs;\nuse uucore::fs::FileInformation;\nuse uucore::show;\n/// A writer that writes to a shell_process' stdin\n///\n/// We use a shell process (not directly calling a sub-process) so we can forward the name of the\n/// corresponding output file (xaa, xab, xac\u2026 ). This is the way it was implemented in GNU split.\nstruct FilterWriter {\n    /// Running shell process\n    shell_process: Child,\n}\nimpl Write for FilterWriter {\n    fn write(&mut self, buf: &[u8]) -> Result<usize> {\n        self.shell_process\n            .stdin\n            .as_mut()\n            .expect(\"failed to get shell stdin\")\n            .write(buf)\n    }\n    fn flush(&mut self) -> Result<()> {\n        self.shell_process\n            .stdin\n            .as_mut()\n            .expect(\"failed to get shell stdin\")\n            .flush()\n    }\n}\n/// Have an environment variable set at a value during this lifetime\nstruct WithEnvVarSet {\n    /// Env var key\n    _previous_var_key: String,\n    /// Previous value set to this key\n    _previous_var_value: std::result::Result<String, env::VarError>,\n}\nimpl WithEnvVarSet {\n    /// Save previous value assigned to key, set key=value\n    fn new(key: &str, value: &str) -> Self {\n        let previous_env_value = env::var(key);\n        unsafe {\n            env::set_var(key, value);\n        }\n        Self {\n            _previous_var_key: String::from(key),\n            _previous_var_value: previous_env_value,\n        }\n    }\n}\nimpl Drop for WithEnvVarSet {\n    /// Restore previous value now that this is being dropped by context\n    fn drop(&mut self) {\n        if let Ok(ref prev_value) = self._previous_var_value {\n            unsafe {\n                env::set_var(&self._previous_var_key, prev_value);\n            }\n        } else {\n            unsafe {\n                env::remove_var(&self._previous_var_key);\n            }\n        }\n    }\n}\nimpl FilterWriter {\n    /// Create a new filter running a command with $FILE pointing at the output name\n    ///\n    /// #Arguments\n    ///\n    /// * `command` - The shell command to execute\n    /// * `filepath` - Path of the output file (forwarded to command as $FILE)\n    fn new(command: &str, filepath: &str) -> Result<Self> {\n        // set $FILE, save previous value (if there was one)\n        let _with_env_var_set = WithEnvVarSet::new(\"FILE\", filepath);\n\n        let shell_process =\n            Command::new(env::var(\"SHELL\").unwrap_or_else(|_| \"/bin/sh\".to_owned()))\n                .arg(\"-c\")\n                .arg(command)\n                .stdin(Stdio::piped())\n                .spawn()?;\n\n        Ok(Self { shell_process })\n    }\n}\nimpl Drop for FilterWriter {\n    /// flush stdin, close it and wait on `shell_process` before dropping self\n    fn drop(&mut self) {\n        {\n            // close stdin by dropping it\n            let _stdin = self.shell_process.stdin.as_mut();\n        }\n        let exit_status = self\n            .shell_process\n            .wait()\n            .expect(\"Couldn't wait for child process\");\n        if let Some(return_code) = exit_status.code() {\n            if return_code != 0 {\n                show!(USimpleError::new(\n                    1,\n                    format!(\"Shell process returned {return_code}\")\n                ));\n            }\n        } else {\n            show!(USimpleError::new(1, \"Shell process terminated by signal\"));\n        }\n    }\n}\n/// Instantiate either a file writer or a \"write to shell process's stdin\" writer\npub fn instantiate_current_writer(\n    filter: Option<&str>,\n    filename: &str,\n    is_new: bool,\n) -> Result<BufWriter<Box<dyn Write>>> {\n    match filter {\n        None => {\n            let file = if is_new {\n                // create new file\n                std::fs::OpenOptions::new()\n                    .write(true)\n                    .create(true)\n                    .truncate(true)\n                    .open(Path::new(&filename))\n                    .map_err(|_| Error::other(format!(\"unable to open '{filename}'; aborting\")))?\n            } else {\n                // re-open file that we previously created to append to it\n                std::fs::OpenOptions::new()\n                    .append(true)\n                    .open(Path::new(&filename))\n                    .map_err(|_| {\n                        Error::other(format!(\"unable to re-open '{filename}'; aborting\"))\n                    })?\n            };\n            Ok(BufWriter::new(Box::new(file) as Box<dyn Write>))\n        }\n        Some(filter_command) => Ok(BufWriter::new(Box::new(\n            // spawn a shell command and write to it\n            FilterWriter::new(filter_command, filename)?,\n        ) as Box<dyn Write>)),\n    }\n}\npub fn paths_refer_to_same_file(p1: &str, p2: &str) -> bool {\n    // We have to take symlinks and relative paths into account.\n    let p1 = if p1 == \"-\" {\n        FileInformation::from_file(&std::io::stdin())\n    } else {\n        FileInformation::from_path(Path::new(&p1), true)\n    };\n    fs::infos_refer_to_same_file(p1, FileInformation::from_path(Path::new(p2), true))\n}",
      "file_name": "coreutils/src/uu\\split\\src\\platform\\unix.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nuse std::io::Write;\nuse std::io::{BufWriter, Error, Result};\nuse std::path::Path;\nuse uucore::fs;\n/// Get a file writer\n///\n/// Unlike the unix version of this function, this _always_ returns\n/// a file writer\npub fn instantiate_current_writer(\n    _filter: Option<&str>,\n    filename: &str,\n    is_new: bool,\n) -> Result<BufWriter<Box<dyn Write>>> {\n    let file = if is_new {\n        // create new file\n        std::fs::OpenOptions::new()\n            .write(true)\n            .create(true)\n            .truncate(true)\n            .open(Path::new(&filename))\n            .map_err(|_| Error::other(format!(\"unable to open '{filename}'; aborting\")))?\n    } else {\n        // re-open file that we previously created to append to it\n        std::fs::OpenOptions::new()\n            .append(true)\n            .open(Path::new(&filename))\n            .map_err(|_| Error::other(format!(\"unable to re-open '{filename}'; aborting\")))?\n    };\n    Ok(BufWriter::new(Box::new(file) as Box<dyn Write>))\n}\npub fn paths_refer_to_same_file(p1: &str, p2: &str) -> bool {\n    // Windows doesn't support many of the unix ways of paths being equals\n    fs::paths_refer_to_same_file(Path::new(p1), Path::new(p2), true)\n}",
      "file_name": "coreutils/src/uu\\split\\src\\platform\\windows.rs"
    }
  ],
  "tail": [
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (ToDO) kqueue Signum\nuse crate::paths::Input;\nuse crate::{Quotable, parse, platform};\nuse clap::{Arg, ArgAction, ArgMatches, Command, value_parser};\nuse same_file::Handle;\nuse std::ffi::OsString;\nuse std::io::IsTerminal;\nuse std::time::Duration;\nuse uucore::error::{UResult, USimpleError, UUsageError};\nuse uucore::parser::parse_size::{ParseSizeError, parse_size_u64};\nuse uucore::parser::parse_time;\nuse uucore::parser::shortcut_value_parser::ShortcutValueParser;\nuse uucore::{format_usage, help_about, help_usage, show_warning};\nconst ABOUT: &str = help_about!(\"tail.md\");\nconst USAGE: &str = help_usage!(\"tail.md\");\npub mod options {\n    pub mod verbosity {\n        pub const QUIET: &str = \"quiet\";\n        pub const VERBOSE: &str = \"verbose\";\n    }\n    pub const BYTES: &str = \"bytes\";\n    pub const FOLLOW: &str = \"follow\";\n    pub const LINES: &str = \"lines\";\n    pub const PID: &str = \"pid\";\n    pub const SLEEP_INT: &str = \"sleep-interval\";\n    pub const ZERO_TERM: &str = \"zero-terminated\";\n    pub const DISABLE_INOTIFY_TERM: &str = \"-disable-inotify\"; // NOTE: three hyphens is correct\n    pub const USE_POLLING: &str = \"use-polling\";\n    pub const RETRY: &str = \"retry\";\n    pub const FOLLOW_RETRY: &str = \"F\";\n    pub const MAX_UNCHANGED_STATS: &str = \"max-unchanged-stats\";\n    pub const ARG_FILES: &str = \"files\";\n    pub const PRESUME_INPUT_PIPE: &str = \"-presume-input-pipe\"; // NOTE: three hyphens is correct\n}\n#[derive(Clone, Copy, Debug, PartialEq, Eq)]\npub enum Signum {\n    Negative(u64),\n    Positive(u64),\n    PlusZero,\n    MinusZero,\n}\n#[derive(Debug, PartialEq, Eq)]\npub enum FilterMode {\n    Bytes(Signum),\n\n    /// Mode for lines delimited by delimiter as u8\n    Lines(Signum, u8),\n}\nimpl FilterMode {\n    fn from_obsolete_args(args: &parse::ObsoleteArgs) -> Self {\n        let signum = if args.plus {\n            Signum::Positive(args.num)\n        } else {\n            Signum::Negative(args.num)\n        };\n        if args.lines {\n            Self::Lines(signum, b'\\n')\n        } else {\n            Self::Bytes(signum)\n        }\n    }\n\n    fn from(matches: &ArgMatches) -> UResult<Self> {\n        let zero_term = matches.get_flag(options::ZERO_TERM);\n        let mode = if let Some(arg) = matches.get_one::<String>(options::BYTES) {\n            match parse_num(arg) {\n                Ok(signum) => Self::Bytes(signum),\n                Err(e) => {\n                    return Err(USimpleError::new(\n                        1,\n                        format!(\"invalid number of bytes: '{e}'\"),\n                    ));\n                }\n            }\n        } else if let Some(arg) = matches.get_one::<String>(options::LINES) {\n            match parse_num(arg) {\n                Ok(signum) => {\n                    let delimiter = if zero_term { 0 } else { b'\\n' };\n                    Self::Lines(signum, delimiter)\n                }\n                Err(e) => {\n                    return Err(USimpleError::new(\n                        1,\n                        format!(\"invalid number of lines: {e}\"),\n                    ));\n                }\n            }\n        } else if zero_term {\n            Self::default_zero()\n        } else {\n            Self::default()\n        };\n\n        Ok(mode)\n    }\n\n    fn default_zero() -> Self {\n        Self::Lines(Signum::Negative(10), 0)\n    }\n}\nimpl Default for FilterMode {\n    fn default() -> Self {\n        Self::Lines(Signum::Negative(10), b'\\n')\n    }\n}\n#[derive(Debug, PartialEq, Eq, Clone, Copy)]\npub enum FollowMode {\n    Descriptor,\n    Name,\n}\n#[derive(Debug)]\npub enum VerificationResult {\n    Ok,\n    CannotFollowStdinByName,\n    NoOutput,\n}\n#[derive(Debug)]\npub struct Settings {\n    pub follow: Option<FollowMode>,\n    pub max_unchanged_stats: u32,\n    pub mode: FilterMode,\n    pub pid: platform::Pid,\n    pub retry: bool,\n    pub sleep_sec: Duration,\n    pub use_polling: bool,\n    pub verbose: bool,\n    pub presume_input_pipe: bool,\n    /// `FILE(s)` positional arguments\n    pub inputs: Vec<Input>,\n}\nimpl Default for Settings {\n    fn default() -> Self {\n        Self {\n            max_unchanged_stats: 5,\n            sleep_sec: Duration::from_secs_f32(1.0),\n            follow: Option::default(),\n            mode: FilterMode::default(),\n            pid: Default::default(),\n            retry: Default::default(),\n            use_polling: Default::default(),\n            verbose: Default::default(),\n            presume_input_pipe: Default::default(),\n            inputs: Vec::default(),\n        }\n    }\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\args.rs"
    },
    {
      "chunk": "impl Settings {\n    pub fn from_obsolete_args(args: &parse::ObsoleteArgs, name: Option<&OsString>) -> Self {\n        let mut settings = Self::default();\n        if args.follow {\n            settings.follow = if name.is_some() {\n                Some(FollowMode::Name)\n            } else {\n                Some(FollowMode::Descriptor)\n            };\n        }\n        settings.mode = FilterMode::from_obsolete_args(args);\n        let input = if let Some(name) = name {\n            Input::from(name)\n        } else {\n            Input::default()\n        };\n        settings.inputs.push(input);\n        settings\n    }\n\n    pub fn from(matches: &ArgMatches) -> UResult<Self> {\n        // We're parsing --follow, -F and --retry under the following conditions:\n        // * -F sets --retry and --follow=name\n        // * plain --follow or short -f is the same like specifying --follow=descriptor\n        // * All these options and flags can occur multiple times as command line arguments\n        let follow_retry = matches.get_flag(options::FOLLOW_RETRY);\n        // We don't need to check for occurrences of --retry if -F was specified which already sets\n        // retry\n        let retry = follow_retry || matches.get_flag(options::RETRY);\n        let follow = match (\n            follow_retry,\n            matches\n                .get_one::<String>(options::FOLLOW)\n                .map(|s| s.as_str()),\n        ) {\n            // -F and --follow if -F is specified after --follow. We don't need to care about the\n            // value of --follow.\n            (true, Some(_))\n                // It's ok to use `index_of` instead of `indices_of` since -F and  --follow\n                // overwrite themselves (not only the value but also the index).\n                if matches.index_of(options::FOLLOW_RETRY) > matches.index_of(options::FOLLOW) =>\n            {\n                Some(FollowMode::Name)\n            }\n            // * -F and --follow=name if --follow=name is specified after -F\n            // * No occurrences of -F but --follow=name\n            // * -F and no occurrences of --follow\n            (_, Some(\"name\")) | (true, None) => Some(FollowMode::Name),\n            // * -F and --follow=descriptor (or plain --follow, -f) if --follow=descriptor is\n            // specified after -F\n            // * No occurrences of -F but --follow=descriptor, --follow, -f\n            (_, Some(_)) => Some(FollowMode::Descriptor),\n            // The default for no occurrences of -F or --follow\n            (false, None) => None,\n        };\n\n        let mut settings: Self = Self {\n            follow,\n            retry,\n            use_polling: matches.get_flag(options::USE_POLLING),\n            mode: FilterMode::from(matches)?,\n            verbose: matches.get_flag(options::verbosity::VERBOSE),\n            presume_input_pipe: matches.get_flag(options::PRESUME_INPUT_PIPE),\n            ..Default::default()\n        };\n\n        if let Some(source) = matches.get_one::<String>(options::SLEEP_INT) {\n            settings.sleep_sec = parse_time::from_str(source, false).map_err(|_| {\n                UUsageError::new(1, format!(\"invalid number of seconds: '{source}'\"))\n            })?;\n        }\n\n        if let Some(s) = matches.get_one::<String>(options::MAX_UNCHANGED_STATS) {\n            settings.max_unchanged_stats = match s.parse::<u32>() {\n                Ok(s) => s,\n                Err(_) => {\n                    return Err(UUsageError::new(\n                        1,\n                        format!(\n                            \"invalid maximum number of unchanged stats between opens: {}\",\n                            s.quote()\n                        ),\n                    ));\n                }\n            }\n        }\n\n        if let Some(pid_str) = matches.get_one::<String>(options::PID) {\n            match pid_str.parse() {\n                Ok(pid) => {\n                    // NOTE: on unix platform::Pid is i32, on windows platform::Pid is u32\n                    #[cfg(unix)]\n                    if pid < 0 {\n                        // NOTE: tail only accepts an unsigned pid\n                        return Err(USimpleError::new(\n                            1,\n                            format!(\"invalid PID: {}\", pid_str.quote()),\n                        ));\n                    }\n\n                    settings.pid = pid;\n                }\n                Err(e) => {\n                    return Err(USimpleError::new(\n                        1,\n                        format!(\"invalid PID: {}: {e}\", pid_str.quote()),\n                    ));\n                }\n            }\n        }\n\n        settings.inputs = matches\n            .get_many::<OsString>(options::ARG_FILES)\n            .map(|v| v.map(Input::from).collect())\n            .unwrap_or_else(|| vec![Input::default()]);\n\n        settings.verbose = (matches.get_flag(options::verbosity::VERBOSE)\n            || settings.inputs.len() > 1)\n            && !matches.get_flag(options::verbosity::QUIET);\n\n        Ok(settings)\n    }\n\n    pub fn has_only_stdin(&self) -> bool {\n        self.inputs.iter().all(|input| input.is_stdin())\n    }\n\n    pub fn has_stdin(&self) -> bool {\n        self.inputs.iter().any(|input| input.is_stdin())\n    }\n\n    pub fn num_inputs(&self) -> usize {\n        self.inputs.len()\n    }\n\n    /// Check [`Settings`] for problematic configurations of tail originating from user provided\n    /// command line arguments and print appropriate warnings.\n    pub fn check_warnings(&self) {\n        if self.retry {\n            if self.follow.is_none() {\n                show_warning!(\"--retry ignored; --retry is useful only when following\");\n            } else if self.follow == Some(FollowMode::Descriptor) {\n                show_warning!(\"--retry only effective for the initial open\");\n            }\n        }\n\n        if self.pid != 0 {\n            if self.follow.is_none() {\n                show_warning!(\"PID ignored; --pid=PID is useful only when following\");\n            } else if !platform::supports_pid_checks(self.pid) {\n                show_warning!(\"--pid=PID is not supported on this system\");\n            }\n        }\n\n        // This warning originates from gnu's tail implementation of the equivalent warning. If the\n        // user wants to follow stdin, but tail is blocking indefinitely anyways, because of stdin\n        // as `tty` (but no otherwise blocking stdin), then we print a warning that `--follow`\n        // cannot be applied under these circumstances and is therefore ineffective.\n        if self.follow.is_some() && self.has_stdin() {\n            let blocking_stdin = self.pid == 0\n                && self.follow == Some(FollowMode::Descriptor)\n                && self.num_inputs() == 1\n                && Handle::stdin().is_ok_and(|handle| {\n                    handle\n                        .as_file()\n                        .metadata()\n                        .is_ok_and(|meta| !meta.is_file())\n                });\n\n            if !blocking_stdin && std::io::stdin().is_terminal() {\n                show_warning!(\"following standard input indefinitely is ineffective\");\n            }\n        }\n    }\n\n    /// Verify [`Settings`] and try to find unsolvable misconfigurations of tail originating from\n    /// user provided command line arguments. In contrast to [`Settings::check_warnings`] these\n    /// misconfigurations usually lead to the immediate exit or abortion of the running `tail`\n    /// process.\n    pub fn verify(&self) -> VerificationResult {\n        // Mimic GNU's tail for `tail -F`\n        if self.inputs.iter().any(|i| i.is_stdin()) && self.follow == Some(FollowMode::Name) {\n            return VerificationResult::CannotFollowStdinByName;\n        }\n\n        // Mimic GNU's tail for -[nc]0 without -f and exit immediately\n        if self.follow.is_none()\n            && matches!(\n                self.mode,\n                FilterMode::Lines(Signum::MinusZero, _) | FilterMode::Bytes(Signum::MinusZero)\n            )\n        {\n            return VerificationResult::NoOutput;\n        }\n\n        VerificationResult::Ok\n    }\n}\npub fn parse_obsolete(arg: &OsString, input: Option<&OsString>) -> UResult<Option<Settings>> {\n    match parse::parse_obsolete(arg) {\n        Some(Ok(args)) => Ok(Some(Settings::from_obsolete_args(&args, input))),\n        None => Ok(None),\n        Some(Err(e)) => {\n            let arg_str = arg.to_string_lossy();\n            Err(USimpleError::new(\n                1,\n                match e {\n                    parse::ParseError::OutOfRange => format!(\n                        \"invalid number: {}: Numerical result out of range\",\n                        arg_str.quote()\n                    ),\n                    parse::ParseError::Overflow => format!(\"invalid number: {}\", arg_str.quote()),\n                    // this ensures compatibility to GNU's error message (as tested in misc/tail)\n                    parse::ParseError::Context => format!(\n                        \"option used in invalid context -- {}\",\n                        arg_str.chars().nth(1).unwrap_or_default()\n                    ),\n                    parse::ParseError::InvalidEncoding => {\n                        format!(\"bad argument encoding: '{arg_str}'\")\n                    }\n                },\n            ))\n        }\n    }\n}\nfn parse_num(src: &str) -> Result<Signum, ParseSizeError> {\n    let mut size_string = src.trim();\n    let mut starting_with = false;\n\n    if let Some(c) = size_string.chars().next() {\n        if c == '+' || c == '-' {\n            // tail: '-' is not documented (8.32 man pages)\n            size_string = &size_string[1..];\n            if c == '+' {\n                starting_with = true;\n            }\n        }\n    }\n\n    match parse_size_u64(size_string) {\n        Ok(n) => match (n, starting_with) {\n            (0, true) => Ok(Signum::PlusZero),\n            (0, false) => Ok(Signum::MinusZero),\n            (n, true) => Ok(Signum::Positive(n)),\n            (n, false) => Ok(Signum::Negative(n)),\n        },\n        Err(_) => Err(ParseSizeError::ParseFailure(size_string.to_string())),\n    }\n}\npub fn parse_args(args: impl uucore::Args) -> UResult<Settings> {\n    let args_vec: Vec<OsString> = args.collect();\n    let clap_args = uu_app().try_get_matches_from(args_vec.clone());\n    let clap_result = match clap_args {\n        Ok(matches) => Ok(Settings::from(&matches)?),\n        Err(err) => Err(err.into()),\n    };\n\n    // clap isn't able to handle obsolete syntax.\n    // therefore, we want to check further for obsolete arguments.\n    // argv[0] is always present, argv[1] might be obsolete arguments\n    // argv[2] might contain an input file, argv[3] isn't allowed in obsolete mode\n    if args_vec.len() != 2 && args_vec.len() != 3 {\n        return clap_result;\n    }\n\n    // At this point, there are a few possible cases:\n    //\n    //    1. clap has succeeded and the arguments would be invalid for the obsolete syntax.\n    //    2. The case of `tail -c 5` is ambiguous. clap parses this as `tail -c5`,\n    //       but it could also be interpreted as valid obsolete syntax (tail -c on file '5').\n    //       GNU chooses to interpret this as `tail -c5`, like clap.\n    //    3. `tail -f foo` is also ambiguous, but has the same effect in both cases. We can safely\n    //        use the clap result here.\n    //    4. clap succeeded for obsolete arguments starting with '+', but misinterprets them as\n    //       input files (e.g. 'tail +f').\n    //    5. clap failed because of unknown flags, but possibly valid obsolete arguments\n    //        (e.g. tail -l; tail -10c).\n    //\n    // In cases 4 & 5, we want to try parsing the obsolete arguments, which corresponds to\n    // checking whether clap succeeded or the first argument starts with '+'.\n    let possible_obsolete_args = &args_vec[1];\n    if clap_result.is_ok() && !possible_obsolete_args.to_string_lossy().starts_with('+') {\n        return clap_result;\n    }\n    match parse_obsolete(possible_obsolete_args, args_vec.get(2))? {\n        Some(settings) => Ok(settings),\n        None => clap_result,\n    }\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\args.rs"
    },
    {
      "chunk": "pub fn uu_app() -> Command {\n    #[cfg(target_os = \"linux\")]\n    const POLLING_HELP: &str = \"Disable 'inotify' support and use polling instead\";\n    #[cfg(all(unix, not(target_os = \"linux\")))]\n    const POLLING_HELP: &str = \"Disable 'kqueue' support and use polling instead\";\n    #[cfg(target_os = \"windows\")]\n    const POLLING_HELP: &str = \"Disable 'ReadDirectoryChanges' support and use polling instead\";\n\n    Command::new(uucore::util_name())\n        .version(uucore::crate_version!())\n        .about(ABOUT)\n        .override_usage(format_usage(USAGE))\n        .infer_long_args(true)\n        .arg(\n            Arg::new(options::BYTES)\n                .short('c')\n                .long(options::BYTES)\n                .allow_hyphen_values(true)\n                .overrides_with_all([options::BYTES, options::LINES])\n                .help(\"Number of bytes to print\"),\n        )\n        .arg(\n            Arg::new(options::FOLLOW)\n                .short('f')\n                .long(options::FOLLOW)\n                .default_missing_value(\"descriptor\")\n                .num_args(0..=1)\n                .require_equals(true)\n                .value_parser(ShortcutValueParser::new([\"descriptor\", \"name\"]))\n                .overrides_with(options::FOLLOW)\n                .help(\"Print the file as it grows\"),\n        )\n        .arg(\n            Arg::new(options::LINES)\n                .short('n')\n                .long(options::LINES)\n                .allow_hyphen_values(true)\n                .overrides_with_all([options::BYTES, options::LINES])\n                .help(\"Number of lines to print\"),\n        )\n        .arg(\n            Arg::new(options::PID)\n                .long(options::PID)\n                .value_name(\"PID\")\n                .help(\"With -f, terminate after process ID, PID dies\")\n                .overrides_with(options::PID),\n        )\n        .arg(\n            Arg::new(options::verbosity::QUIET)\n                .short('q')\n                .long(options::verbosity::QUIET)\n                .visible_alias(\"silent\")\n                .overrides_with_all([options::verbosity::QUIET, options::verbosity::VERBOSE])\n                .help(\"Never output headers giving file names\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SLEEP_INT)\n                .short('s')\n                .value_name(\"N\")\n                .long(options::SLEEP_INT)\n                .help(\"Number of seconds to sleep between polling the file when running with -f\"),\n        )\n        .arg(\n            Arg::new(options::MAX_UNCHANGED_STATS)\n                .value_name(\"N\")\n                .long(options::MAX_UNCHANGED_STATS)\n                .help(\n                    \"Reopen a FILE which has not changed size after N (default 5) iterations \\\n                        to see if it has been unlinked or renamed (this is the usual case of rotated \\\n                        log files); This option is meaningful only when polling \\\n                        (i.e., with --use-polling) and when --follow=name\",\n                ),\n        )\n        .arg(\n            Arg::new(options::verbosity::VERBOSE)\n                .short('v')\n                .long(options::verbosity::VERBOSE)\n                .overrides_with_all([options::verbosity::QUIET, options::verbosity::VERBOSE])\n                .help(\"Always output headers giving file names\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::ZERO_TERM)\n                .short('z')\n                .long(options::ZERO_TERM)\n                .help(\"Line delimiter is NUL, not newline\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::USE_POLLING)\n                .alias(options::DISABLE_INOTIFY_TERM) // NOTE: Used by GNU's test suite\n                .alias(\"dis\") // NOTE: Used by GNU's test suite\n                .long(options::USE_POLLING)\n                .help(POLLING_HELP)\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::RETRY)\n                .long(options::RETRY)\n                .help(\"Keep trying to open a file if it is inaccessible\")\n                .overrides_with(options::RETRY)\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::FOLLOW_RETRY)\n                .short('F')\n                .help(\"Same as --follow=name --retry\")\n                .overrides_with(options::FOLLOW_RETRY)\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::PRESUME_INPUT_PIPE)\n                .long(\"presume-input-pipe\")\n                .alias(options::PRESUME_INPUT_PIPE)\n                .hide(true)\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::ARG_FILES)\n                .action(ArgAction::Append)\n                .num_args(1..)\n                .value_parser(value_parser!(OsString))\n                .value_hint(clap::ValueHint::FilePath),\n        )\n}\n#[cfg(test)]\nmod tests {\n    use rstest::rstest;\n\n    use crate::parse::ObsoleteArgs;\n\n    use super::*;\n\n    #[test]\n    fn test_parse_num_when_sign_is_given() {\n        let result = parse_num(\"+0\");\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), Signum::PlusZero);\n\n        let result = parse_num(\"+1\");\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), Signum::Positive(1));\n\n        let result = parse_num(\"-0\");\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), Signum::MinusZero);\n\n        let result = parse_num(\"-1\");\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), Signum::Negative(1));\n    }\n\n    #[test]\n    fn test_parse_num_when_no_sign_is_given() {\n        let result = parse_num(\"0\");\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), Signum::MinusZero);\n\n        let result = parse_num(\"1\");\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), Signum::Negative(1));\n    }\n\n    #[test]\n    fn test_parse_obsolete_settings_f() {\n        let args = ObsoleteArgs {\n            follow: true,\n            ..Default::default()\n        };\n        let result = Settings::from_obsolete_args(&args, None);\n        assert_eq!(result.follow, Some(FollowMode::Descriptor));\n\n        let result = Settings::from_obsolete_args(&args, Some(&\"file\".into()));\n        assert_eq!(result.follow, Some(FollowMode::Name));\n    }\n\n    #[rstest]\n    #[case::default(vec![], None, false)]\n    #[case::retry(vec![\"--retry\"], None, true)]\n    #[case::multiple_retry(vec![\"--retry\", \"--retry\"], None, true)]\n    #[case::follow_long(vec![\"--follow\"], Some(FollowMode::Descriptor), false)]\n    #[case::follow_short(vec![\"-f\"], Some(FollowMode::Descriptor), false)]\n    #[case::follow_long_with_retry(vec![\"--follow\", \"--retry\"], Some(FollowMode::Descriptor), true)]\n    #[case::follow_short_with_retry(vec![\"-f\", \"--retry\"], Some(FollowMode::Descriptor), true)]\n    #[case::follow_overwrites_previous_selection_1(vec![\"--follow=name\", \"--follow=descriptor\"], Some(FollowMode::Descriptor), false)]\n    #[case::follow_overwrites_previous_selection_2(vec![\"--follow=descriptor\", \"--follow=name\"], Some(FollowMode::Name), false)]\n    #[case::big_f(vec![\"-F\"], Some(FollowMode::Name), true)]\n    #[case::multiple_big_f(vec![\"-F\", \"-F\"], Some(FollowMode::Name), true)]\n    #[case::big_f_with_retry_then_does_not_change(vec![\"-F\", \"--retry\"], Some(FollowMode::Name), true)]\n    #[case::big_f_with_follow_descriptor_then_change(vec![\"-F\", \"--follow=descriptor\"], Some(FollowMode::Descriptor), true)]\n    #[case::multiple_big_f_with_follow_descriptor_then_no_change(vec![\"-F\", \"--follow=descriptor\", \"-F\"], Some(FollowMode::Name), true)]\n    #[case::big_f_with_follow_short_then_change(vec![\"-F\", \"-f\"], Some(FollowMode::Descriptor), true)]\n    #[case::follow_descriptor_with_big_f_then_change(vec![\"--follow=descriptor\", \"-F\"], Some(FollowMode::Name), true)]\n    #[case::follow_short_with_big_f_then_change(vec![\"-f\", \"-F\"], Some(FollowMode::Name), true)]\n    #[case::big_f_with_follow_name_then_not_change(vec![\"-F\", \"--follow=name\"], Some(FollowMode::Name), true)]\n    #[case::follow_name_with_big_f_then_not_change(vec![\"--follow=name\", \"-F\"], Some(FollowMode::Name), true)]\n    #[case::big_f_with_multiple_long_follow(vec![\"--follow=name\", \"-F\", \"--follow=descriptor\"], Some(FollowMode::Descriptor), true)]\n    #[case::big_f_with_multiple_long_follow_name(vec![\"--follow=name\", \"-F\", \"--follow=name\"], Some(FollowMode::Name), true)]\n    #[case::big_f_with_multiple_short_follow(vec![\"-f\", \"-F\", \"-f\"], Some(FollowMode::Descriptor), true)]\n    #[case::multiple_big_f_with_multiple_short_follow(vec![\"-f\", \"-F\", \"-f\", \"-F\"], Some(FollowMode::Name), true)]\n    fn test_parse_settings_follow_mode_and_retry(\n        #[case] args: Vec<&str>,\n        #[case] expected_follow_mode: Option<FollowMode>,\n        #[case] expected_retry: bool,\n    ) {\n        let settings =\n            Settings::from(&uu_app().no_binary_name(true).get_matches_from(args)).unwrap();\n        assert_eq!(settings.follow, expected_follow_mode);\n        assert_eq!(settings.retry, expected_retry);\n    }\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\args.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n//! Iterating over a file by chunks, either starting at the end of the file with [`ReverseChunks`]\n//! or at the end of piped stdin with [`LinesChunk`] or [`BytesChunk`].\n//!\n//! Use [`ReverseChunks::new`] to create a new iterator over chunks of bytes from the file.\n// spell-checker:ignore (ToDO) filehandle BUFSIZ\nuse std::collections::VecDeque;\nuse std::fs::File;\nuse std::io::{BufRead, Read, Seek, SeekFrom, Write};\nuse uucore::error::UResult;\n/// When reading files in reverse in `bounded_tail`, this is the size of each\n/// block read at a time.\npub const BLOCK_SIZE: u64 = 1 << 16;\n/// The size of the backing buffer of a LinesChunk or BytesChunk in bytes. The value of BUFFER_SIZE\n/// originates from the BUFSIZ constant in stdio.h and the libc crate to make stream IO efficient.\n/// In the latter the value is constantly set to 8192 on all platforms, where the value in stdio.h\n/// is determined on each platform differently. Since libc chose 8192 as a reasonable default the\n/// value here is set to this value, too.\npub const BUFFER_SIZE: usize = 8192;\n/// An iterator over a file in non-overlapping chunks from the end of the file.\n///\n/// Each chunk is a [`Vec`]<[`u8`]> of size [`BLOCK_SIZE`] (except\n/// possibly the last chunk, which might be smaller). Each call to\n/// [`ReverseChunks::next`] will seek backwards through the given file.\npub struct ReverseChunks<'a> {\n    /// The file to iterate over, by blocks, from the end to the beginning.\n    file: &'a File,\n\n    /// The total number of bytes in the file.\n    size: u64,\n\n    /// The total number of blocks to read.\n    max_blocks_to_read: usize,\n\n    /// The index of the next block to read.\n    block_idx: usize,\n}\nimpl<'a> ReverseChunks<'a> {\n    pub fn new(file: &'a mut File) -> Self {\n        let current = if cfg!(unix) {\n            file.stream_position().unwrap()\n        } else {\n            0\n        };\n        let size = file.seek(SeekFrom::End(0)).unwrap() - current;\n        let max_blocks_to_read = (size as f64 / BLOCK_SIZE as f64).ceil() as usize;\n        let block_idx = 0;\n        ReverseChunks {\n            file,\n            size,\n            max_blocks_to_read,\n            block_idx,\n        }\n    }\n}\nimpl Iterator for ReverseChunks<'_> {\n    type Item = Vec<u8>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        // If there are no more chunks to read, terminate the iterator.\n        if self.block_idx >= self.max_blocks_to_read {\n            return None;\n        }\n\n        // The chunk size is `BLOCK_SIZE` for all but the last chunk\n        // (that is, the chunk closest to the beginning of the file),\n        // which contains the remainder of the bytes.\n        let block_size = if self.block_idx == self.max_blocks_to_read - 1 {\n            self.size % BLOCK_SIZE\n        } else {\n            BLOCK_SIZE\n        };\n\n        // Seek backwards by the next chunk, read the full chunk into\n        // `buf`, and then seek back to the start of the chunk again.\n        let mut buf = vec![0; BLOCK_SIZE as usize];\n        let pos = self\n            .file\n            .seek(SeekFrom::Current(-(block_size as i64)))\n            .unwrap();\n        self.file\n            .read_exact(&mut buf[0..(block_size as usize)])\n            .unwrap();\n        let pos2 = self\n            .file\n            .seek(SeekFrom::Current(-(block_size as i64)))\n            .unwrap();\n        assert_eq!(pos, pos2);\n\n        self.block_idx += 1;\n\n        Some(buf[0..(block_size as usize)].to_vec())\n    }\n}\n/// The type of the backing buffer of [`BytesChunk`] and [`LinesChunk`] which can hold\n/// [`BUFFER_SIZE`] elements at max.\ntype ChunkBuffer = [u8; BUFFER_SIZE];\n/// A [`BytesChunk`] storing a fixed size number of bytes in a buffer.\n#[derive(Clone, PartialEq, Eq, Debug)]\npub struct BytesChunk {\n    /// The [`ChunkBuffer`], an array storing the bytes, for example filled by\n    /// [`BytesChunk::fill`]\n    buffer: ChunkBuffer,\n\n    /// Stores the number of bytes, this buffer holds. This is not equal to buffer.len(), since the\n    /// [`BytesChunk`] may store less bytes than the internal buffer can hold. In addition\n    /// [`BytesChunk`] may be reused, what makes it necessary to track the number of stored bytes.\n    /// The choice of usize is sufficient here, since the number of bytes max value is\n    /// [`BUFFER_SIZE`], which is a usize.\n    bytes: usize,\n}\nimpl BytesChunk {\n    #[allow(clippy::new_without_default)]\n    pub fn new() -> Self {\n        Self {\n            buffer: [0; BUFFER_SIZE],\n            bytes: 0,\n        }\n    }\n\n    /// Create a new chunk from an existing chunk. The new chunk's buffer will be copied from the\n    /// old chunk's buffer, copying the slice `[offset..old_chunk.bytes]` into the new chunk's\n    /// buffer but starting at 0 instead of offset. If the offset is larger or equal to\n    /// `chunk.lines` then a new empty `BytesChunk` is returned.\n    ///\n    /// # Arguments\n    ///\n    /// * `chunk`: The chunk to create a new `BytesChunk` chunk from\n    /// * `offset`: Start to copy the old chunk's buffer from this position. May not be larger\n    ///   than `chunk.bytes`.\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = BytesChunk::new();\n    /// chunk.buffer[1] = 1;\n    /// chunk.bytes = 2;\n    /// let new_chunk = BytesChunk::from_chunk(&chunk, 0);\n    /// assert_eq!(2, new_chunk.get_buffer().len());\n    /// assert_eq!(&[0, 1], new_chunk.get_buffer());\n    ///\n    /// let new_chunk = BytesChunk::from_chunk(&chunk, 1);\n    /// assert_eq!(1, new_chunk.get_buffer().len());\n    /// assert_eq!(&[1], new_chunk.get_buffer());\n    /// ```\n    fn from_chunk(chunk: &Self, offset: usize) -> Self {\n        if offset >= chunk.bytes {\n            return Self::new();\n        }\n\n        let mut buffer: ChunkBuffer = [0; BUFFER_SIZE];\n        let slice = chunk.get_buffer_with(offset);\n        buffer[..slice.len()].copy_from_slice(slice);\n        Self {\n            buffer,\n            bytes: chunk.bytes - offset,\n        }\n    }\n\n    /// Receive the internal buffer safely, so it returns a slice only containing as many bytes as\n    /// large the `self.bytes` value is.\n    ///\n    /// returns: a slice containing the bytes of the internal buffer from `[0..self.bytes]`\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = BytesChunk::new();\n    /// chunk.bytes = 1;\n    /// assert_eq!(&[0], chunk.get_buffer());\n    /// ```\n    pub fn get_buffer(&self) -> &[u8] {\n        &self.buffer[..self.bytes]\n    }\n\n    /// Like [`BytesChunk::get_buffer`], but returning a slice from `[offset.self.bytes]`.\n    ///\n    /// returns: a slice containing the bytes of the internal buffer from `[offset..self.bytes]`\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = BytesChunk::new();\n    /// chunk.bytes = 2;\n    /// assert_eq!(&[0], chunk.get_buffer_with(1));\n    /// ```\n    pub fn get_buffer_with(&self, offset: usize) -> &[u8] {\n        &self.buffer[offset..self.bytes]\n    }\n\n    pub fn has_data(&self) -> bool {\n        self.bytes > 0\n    }\n\n    /// Fills `self.buffer` with maximal [`BUFFER_SIZE`] number of bytes, draining the reader by\n    /// that number of bytes. If EOF is reached (so 0 bytes are read), then returns\n    /// [`UResult<None>`] or else the result with [`Some(bytes)`] where bytes is the number of bytes\n    /// read from the source.\n    pub fn fill(&mut self, filehandle: &mut impl BufRead) -> UResult<Option<usize>> {\n        let num_bytes = filehandle.read(&mut self.buffer)?;\n        self.bytes = num_bytes;\n        if num_bytes == 0 {\n            return Ok(None);\n        }\n\n        Ok(Some(self.bytes))\n    }\n}\n/// An abstraction layer on top of [`BytesChunk`] mainly to simplify filling only the needed amount\n/// of chunks. See also [`Self::fill`].\npub struct BytesChunkBuffer {\n    /// The number of bytes to print\n    num_print: u64,\n    /// The current number of bytes summed over all stored chunks in [`Self::chunks`]. Use u64 here\n    /// to support files > 4GB on 32-bit systems. Note, this differs from `BytesChunk::bytes` which\n    /// is a usize. The choice of u64 is based on `tail::FilterMode::Bytes`.\n    bytes: u64,\n    /// The buffer to store [`BytesChunk`] in\n    chunks: VecDeque<Box<BytesChunk>>,\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\chunks.rs"
    },
    {
      "chunk": "impl BytesChunkBuffer {\n    /// Creates a new [`BytesChunkBuffer`].\n    ///\n    /// # Arguments\n    ///\n    /// * `num_print`: The number of bytes to print\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = BytesChunk::new();\n    /// chunk.buffer[1] = 1;\n    /// chunk.bytes = 2;\n    /// let new_chunk = BytesChunk::from_chunk(&chunk, 0);\n    /// assert_eq!(2, new_chunk.get_buffer().len());\n    /// assert_eq!(&[0, 1], new_chunk.get_buffer());\n    ///\n    /// let new_chunk = BytesChunk::from_chunk(&chunk, 1);\n    /// assert_eq!(1, new_chunk.get_buffer().len());\n    /// assert_eq!(&[1], new_chunk.get_buffer());\n    /// ```\n    pub fn new(num_print: u64) -> Self {\n        Self {\n            bytes: 0,\n            num_print,\n            chunks: VecDeque::new(),\n        }\n    }\n\n    /// Fills this buffer with chunks and consumes the reader completely. This method ensures that\n    /// there are exactly as many chunks as needed to match `self.num_print` bytes, so there are\n    /// in sum exactly `self.num_print` bytes stored in all chunks. The method returns an iterator\n    /// over these chunks. If there are no chunks, for example because the piped stdin contained no\n    /// bytes, or `num_print = 0` then `iterator.next` returns None.\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// use crate::chunks::BytesChunkBuffer;\n    /// use std::io::{BufReader, Cursor};\n    ///\n    /// let mut reader = BufReader::new(Cursor::new(\"\"));\n    /// let num_print = 0;\n    /// let mut chunks = BytesChunkBuffer::new(num_print);\n    /// chunks.fill(&mut reader).unwrap();\n    ///\n    /// let mut reader = BufReader::new(Cursor::new(\"a\"));\n    /// let num_print = 1;\n    /// let mut chunks = BytesChunkBuffer::new(num_print);\n    /// chunks.fill(&mut reader).unwrap();\n    /// ```\n    pub fn fill(&mut self, reader: &mut impl BufRead) -> UResult<()> {\n        let mut chunk = Box::new(BytesChunk::new());\n\n        // fill chunks with all bytes from reader and reuse already instantiated chunks if possible\n        while chunk.fill(reader)?.is_some() {\n            self.bytes += chunk.bytes as u64;\n            self.chunks.push_back(chunk);\n\n            let first = &self.chunks[0];\n            if self.bytes - first.bytes as u64 > self.num_print {\n                chunk = self.chunks.pop_front().unwrap();\n                self.bytes -= chunk.bytes as u64;\n            } else {\n                chunk = Box::new(BytesChunk::new());\n            }\n        }\n\n        // quit early if there are no chunks for example in case the pipe was empty\n        if self.chunks.is_empty() {\n            return Ok(());\n        }\n\n        let chunk = self.chunks.pop_front().unwrap();\n\n        // calculate the offset in the first chunk and put the calculated chunk as first element in\n        // the self.chunks collection. The calculated offset must be in the range 0 to BUFFER_SIZE\n        // and is therefore safely convertible to a usize without losses.\n        let offset = self.bytes.saturating_sub(self.num_print) as usize;\n        self.chunks\n            .push_front(Box::new(BytesChunk::from_chunk(&chunk, offset)));\n\n        Ok(())\n    }\n\n    pub fn print(&self, writer: &mut impl Write) -> UResult<()> {\n        for chunk in &self.chunks {\n            writer.write_all(chunk.get_buffer())?;\n        }\n        Ok(())\n    }\n\n    pub fn has_data(&self) -> bool {\n        !self.chunks.is_empty()\n    }\n}\n/// Works similar to a [`BytesChunk`] but also stores the number of lines encountered in the current\n/// buffer. The size of the buffer is limited to a fixed size number of bytes.\n#[derive(Debug)]\npub struct LinesChunk {\n    /// Work on top of a [`BytesChunk`]\n    chunk: BytesChunk,\n    /// The number of lines delimited by `delimiter`. The choice of usize is sufficient here,\n    /// because lines max value is the number of bytes contained in this chunk's buffer, and the\n    /// number of bytes max value is [`BUFFER_SIZE`], which is a usize.\n    lines: usize,\n    /// The delimiter to use, to count the lines\n    delimiter: u8,\n}\nimpl LinesChunk {\n    pub fn new(delimiter: u8) -> Self {\n        Self {\n            chunk: BytesChunk::new(),\n            lines: 0,\n            delimiter,\n        }\n    }\n\n    /// Count the number of lines delimited with [`Self::delimiter`] contained in the buffer.\n    /// Currently [`memchr`] is used because performance is better than using an iterator or for\n    /// loop.\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = LinesChunk::new(b'\\n');\n    /// chunk.buffer[0..12].copy_from_slice(\"hello\\nworld\\n\".as_bytes());\n    /// chunk.bytes = 12;\n    /// assert_eq!(2, chunk.count_lines());\n    ///\n    /// chunk.buffer[0..14].copy_from_slice(\"hello\\r\\nworld\\r\\n\".as_bytes());\n    /// chunk.bytes = 14;\n    /// assert_eq!(2, chunk.count_lines());\n    /// ```\n    fn count_lines(&self) -> usize {\n        memchr::memchr_iter(self.delimiter, self.get_buffer()).count()\n    }\n\n    /// Creates a new [`LinesChunk`] from an existing one with an offset in lines. The new chunk\n    /// contains exactly `chunk.lines - offset` lines. The offset in bytes is calculated and applied\n    /// to the new chunk, so the new chunk contains only the bytes encountered after the offset in\n    /// number of lines and the `delimiter`. If the offset is larger than `chunk.lines` then a new\n    /// empty `LinesChunk` is returned.\n    ///\n    /// # Arguments\n    ///\n    /// * `chunk`: The chunk to create the new chunk from\n    /// * `offset`: The offset in number of lines (not bytes)\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = LinesChunk::new(b'\\n');\n    /// // manually filling the buffer and setting the correct values for bytes and lines\n    /// chunk.buffer[0..12].copy_from_slice(\"hello\\nworld\\n\".as_bytes());\n    /// chunk.bytes = 12;\n    /// chunk.lines = 2;\n    ///\n    /// let offset = 1; // offset in number of lines\n    /// let new_chunk = LinesChunk::from(&chunk, offset);\n    /// assert_eq!(\"world\\n\".as_bytes(), new_chunk.get_buffer());\n    /// assert_eq!(6, new_chunk.bytes);\n    /// assert_eq!(1, new_chunk.lines);\n    /// ```\n    fn from_chunk(chunk: &Self, offset: usize) -> Self {\n        if offset > chunk.lines {\n            return Self::new(chunk.delimiter);\n        }\n\n        let bytes_offset = chunk.calculate_bytes_offset_from(offset);\n        let new_chunk = BytesChunk::from_chunk(&chunk.chunk, bytes_offset);\n\n        Self {\n            chunk: new_chunk,\n            lines: chunk.lines - offset,\n            delimiter: chunk.delimiter,\n        }\n    }\n\n    /// Returns true if this buffer has stored any bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = LinesChunk::new(b'\\n');\n    /// assert!(!chunk.has_data());\n    ///\n    /// chunk.buffer[0] = 1;\n    /// assert!(!chunk.has_data());\n    ///\n    /// chunk.bytes = 1;\n    /// assert!(chunk.has_data());\n    /// ```\n    pub fn has_data(&self) -> bool {\n        self.chunk.has_data()\n    }\n\n    /// Returns this buffer safely. See [`BytesChunk::get_buffer`]\n    ///\n    /// returns: &[u8] with length `self.bytes`\n    pub fn get_buffer(&self) -> &[u8] {\n        self.chunk.get_buffer()\n    }\n\n    /// Returns this buffer safely with an offset applied. See [`BytesChunk::get_buffer_with`].\n    ///\n    /// returns: &[u8] with length `self.bytes - offset`\n    pub fn get_buffer_with(&self, offset: usize) -> &[u8] {\n        self.chunk.get_buffer_with(offset)\n    }\n\n    /// Return the number of lines the buffer contains. `self.lines` needs to be set before the call\n    /// to this function returns the correct value. If the calculation of lines is needed then\n    /// use `self.count_lines`.\n    pub fn get_lines(&self) -> usize {\n        self.lines\n    }\n\n    /// Fills `self.buffer` with maximal [`BUFFER_SIZE`] number of bytes, draining the reader by\n    /// that number of bytes. This function works like the [`BytesChunk::fill`] function besides\n    /// that this function also counts and stores the number of lines encountered while reading from\n    /// the `filehandle`.\n    pub fn fill(&mut self, filehandle: &mut impl BufRead) -> UResult<Option<usize>> {\n        match self.chunk.fill(filehandle)? {\n            None => {\n                self.lines = 0;\n                Ok(None)\n            }\n            Some(bytes) => {\n                self.lines = self.count_lines();\n                Ok(Some(bytes))\n            }\n        }\n    }\n\n    /// Calculates the offset in bytes within this buffer from the offset in number of lines. The\n    /// resulting offset is 0-based and points to the byte after the delimiter.\n    ///\n    /// # Arguments\n    ///\n    /// * `offset`: the offset in number of lines. If offset is 0 then 0 is returned, if larger than\n    ///   the contained lines then self.bytes is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```rust,ignore\n    /// let mut chunk = LinesChunk::new(b'\\n');\n    /// chunk.buffer[0..12].copy_from_slice(\"hello\\nworld\\n\".as_bytes());\n    /// chunk.bytes = 12;\n    /// chunk.lines = 2; // note that if not setting lines the result might not be what is expected\n    /// let bytes_offset = chunk.calculate_bytes_offset_from(1);\n    /// assert_eq!(6, bytes_offset);\n    /// assert_eq!(\n    ///     \"world\\n\",\n    ///     String::from_utf8_lossy(chunk.get_buffer_with(bytes_offset)));\n    /// ```\n    fn calculate_bytes_offset_from(&self, offset: usize) -> usize {\n        let mut lines_offset = offset;\n        let mut bytes_offset = 0;\n        for byte in self.get_buffer() {\n            if lines_offset == 0 {\n                break;\n            }\n            if byte == &self.delimiter {\n                lines_offset -= 1;\n            }\n            bytes_offset += 1;\n        }\n        bytes_offset\n    }\n\n    /// Print the bytes contained in this buffer calculated with the given offset in number of\n    /// lines.\n    ///\n    /// # Arguments\n    ///\n    /// * `writer`: must implement [`Write`]\n    /// * `offset`: An offset in number of lines.\n    pub fn print_lines(&self, writer: &mut impl Write, offset: usize) -> UResult<()> {\n        self.print_bytes(writer, self.calculate_bytes_offset_from(offset))\n    }\n\n    /// Print the bytes contained in this buffer beginning from the given offset in number of bytes.\n    ///\n    /// # Arguments\n    ///\n    /// * `writer`: must implement [`Write`]\n    /// * `offset`: An offset in number of bytes.\n    pub fn print_bytes(&self, writer: &mut impl Write, offset: usize) -> UResult<()> {\n        writer.write_all(self.get_buffer_with(offset))?;\n        Ok(())\n    }\n}\n/// An abstraction layer on top of [`LinesChunk`] mainly to simplify filling only the needed amount\n/// of chunks. See also [`Self::fill`]. Works similar like [`BytesChunkBuffer`], but works on top\n/// of lines delimited by `self.delimiter` instead of bytes.",
      "file_name": "coreutils/src/uu\\tail\\src\\chunks.rs"
    },
    {
      "chunk": "pub struct LinesChunkBuffer {\n    /// The delimiter to recognize a line. Any [`u8`] is allowed.\n    delimiter: u8,\n    /// The amount of lines occurring in all currently stored [`LinesChunk`]s. Use u64 here to\n    /// support files > 4GB on 32-bit systems. Note, this differs from [`LinesChunk::lines`] which\n    /// is a usize. The choice of u64 is based on `tail::FilterMode::Lines`.\n    lines: u64,\n    /// The amount of lines to print.\n    num_print: u64,\n    /// Stores the [`LinesChunk`]\n    chunks: VecDeque<Box<LinesChunk>>,\n}\nimpl LinesChunkBuffer {\n    /// Create a new [`LinesChunkBuffer`]\n    pub fn new(delimiter: u8, num_print: u64) -> Self {\n        Self {\n            delimiter,\n            num_print,\n            lines: 0,\n            chunks: VecDeque::new(),\n        }\n    }\n\n    /// Fills this buffer with chunks and consumes the reader completely. This method ensures that\n    /// there are exactly as many chunks as needed to match `self.num_print` lines, so there are\n    /// in sum exactly `self.num_print` lines stored in all chunks. The method returns an iterator\n    /// over these chunks. If there are no chunks, for example because the piped stdin contained no\n    /// lines, or `num_print = 0` then `iterator.next` will return None.\n    pub fn fill(&mut self, reader: &mut impl BufRead) -> UResult<()> {\n        let mut chunk = Box::new(LinesChunk::new(self.delimiter));\n\n        while chunk.fill(reader)?.is_some() {\n            self.lines += chunk.lines as u64;\n            self.chunks.push_back(chunk);\n\n            let first = &self.chunks[0];\n            if self.lines - first.lines as u64 > self.num_print {\n                chunk = self.chunks.pop_front().unwrap();\n\n                self.lines -= chunk.lines as u64;\n            } else {\n                chunk = Box::new(LinesChunk::new(self.delimiter));\n            }\n        }\n\n        if self.chunks.is_empty() {\n            // chunks is empty when a file is empty so quitting early here\n            return Ok(());\n        } else {\n            let length = &self.chunks.len();\n            let last = &mut self.chunks[length - 1];\n            if !last.get_buffer().ends_with(&[self.delimiter]) {\n                last.lines += 1;\n                self.lines += 1;\n            }\n        }\n\n        // skip unnecessary chunks and save the first chunk which may hold some lines we have to\n        // print\n        let chunk = loop {\n            // it's safe to call unwrap here because there is at least one chunk and sorting out\n            // more chunks than exist shouldn't be possible.\n            let chunk = self.chunks.pop_front().unwrap();\n\n            // skip is true as long there are enough lines left in the other stored chunks.\n            let skip = self.lines - chunk.lines as u64 > self.num_print;\n            if skip {\n                self.lines -= chunk.lines as u64;\n            } else {\n                break chunk;\n            }\n        };\n\n        // Calculate the number of lines to skip in the current chunk. The calculated value must be\n        // in the range 0 to BUFFER_SIZE and is therefore safely convertible to a usize without\n        // losses.\n        let skip_lines = self.lines.saturating_sub(self.num_print) as usize;\n        let chunk = LinesChunk::from_chunk(&chunk, skip_lines);\n        self.chunks.push_front(Box::new(chunk));\n\n        Ok(())\n    }\n\n    pub fn print(&self, mut writer: impl Write) -> UResult<()> {\n        for chunk in &self.chunks {\n            chunk.print_bytes(&mut writer, 0)?;\n        }\n        Ok(())\n    }\n}\n#[cfg(test)]\nmod tests {\n    use crate::chunks::{BUFFER_SIZE, BytesChunk};\n\n    #[test]\n    fn test_bytes_chunk_from_when_offset_is_zero() {\n        let mut chunk = BytesChunk::new();\n        chunk.bytes = BUFFER_SIZE;\n        chunk.buffer[1] = 1;\n        let other = BytesChunk::from_chunk(&chunk, 0);\n        assert_eq!(other, chunk);\n\n        chunk.bytes = 2;\n        let other = BytesChunk::from_chunk(&chunk, 0);\n        assert_eq!(other, chunk);\n\n        chunk.bytes = 1;\n        let other = BytesChunk::from_chunk(&chunk, 0);\n        assert_eq!(other.buffer, [0; BUFFER_SIZE]);\n        assert_eq!(other.bytes, chunk.bytes);\n\n        chunk.bytes = BUFFER_SIZE;\n        let other = BytesChunk::from_chunk(&chunk, 2);\n        assert_eq!(other.buffer, [0; BUFFER_SIZE]);\n        assert_eq!(other.bytes, BUFFER_SIZE - 2);\n    }\n\n    #[test]\n    fn test_bytes_chunk_from_when_offset_is_not_zero() {\n        let mut chunk = BytesChunk::new();\n        chunk.bytes = BUFFER_SIZE;\n        chunk.buffer[1] = 1;\n\n        let other = BytesChunk::from_chunk(&chunk, 1);\n        let mut expected_buffer = [0; BUFFER_SIZE];\n        expected_buffer[0] = 1;\n        assert_eq!(other.buffer, expected_buffer);\n        assert_eq!(other.bytes, BUFFER_SIZE - 1);\n\n        let other = BytesChunk::from_chunk(&chunk, 2);\n        assert_eq!(other.buffer, [0; BUFFER_SIZE]);\n        assert_eq!(other.bytes, BUFFER_SIZE - 2);\n    }\n\n    #[test]\n    fn test_bytes_chunk_from_when_offset_is_larger_than_chunk_size_1() {\n        let mut chunk = BytesChunk::new();\n        chunk.bytes = BUFFER_SIZE;\n        let new_chunk = BytesChunk::from_chunk(&chunk, BUFFER_SIZE + 1);\n        assert_eq!(0, new_chunk.bytes);\n    }\n\n    #[test]\n    fn test_bytes_chunk_from_when_offset_is_larger_than_chunk_size_2() {\n        let mut chunk = BytesChunk::new();\n        chunk.bytes = 0;\n        let new_chunk = BytesChunk::from_chunk(&chunk, 1);\n        assert_eq!(0, new_chunk.bytes);\n    }\n\n    #[test]\n    fn test_bytes_chunk_from_when_offset_is_larger_than_chunk_size_3() {\n        let mut chunk = BytesChunk::new();\n        chunk.bytes = 1;\n        let new_chunk = BytesChunk::from_chunk(&chunk, 2);\n        assert_eq!(0, new_chunk.bytes);\n    }\n\n    #[test]\n    fn test_bytes_chunk_from_when_offset_is_equal_to_chunk_size() {\n        let mut chunk = BytesChunk::new();\n        chunk.buffer[0] = 1;\n        chunk.bytes = 1;\n        let new_chunk = BytesChunk::from_chunk(&chunk, 1);\n        assert_eq!(0, new_chunk.bytes);\n    }\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\chunks.rs"
    },
    {
      "chunk": "uucore::bin!(uu_tail);",
      "file_name": "coreutils/src/uu\\tail\\src\\main.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nuse std::ffi::OsString;\n#[derive(PartialEq, Eq, Debug, Copy, Clone)]\npub struct ObsoleteArgs {\n    pub num: u64,\n    pub plus: bool,\n    pub lines: bool,\n    pub follow: bool,\n}\nimpl Default for ObsoleteArgs {\n    fn default() -> Self {\n        Self {\n            num: 10,\n            plus: false,\n            lines: true,\n            follow: false,\n        }\n    }\n}\n#[derive(PartialEq, Eq, Debug)]\npub enum ParseError {\n    OutOfRange,\n    Overflow,\n    Context,\n    InvalidEncoding,\n}\n/// Parses obsolete syntax\n/// tail -\\[NUM\\]\\[bcl\\]\\[f\\] and tail +\\[NUM\\]\\[bcl\\]\\[f\\]\npub fn parse_obsolete(src: &OsString) -> Option<Result<ObsoleteArgs, ParseError>> {\n    let Some(mut rest) = src.to_str() else {\n        return Some(Err(ParseError::InvalidEncoding));\n    }\n;\nlet sign = if let Some(r) = rest.strip_prefix('-') {\n        rest = r;\n        '-'\n    } else if let Some(r) = rest.strip_prefix('+') {\n        rest = r;\n        '+'\n    } else {\n        return None;\n    };\nlet end_num = rest\n        .find(|c: char| !c.is_ascii_digit())\n        .unwrap_or(rest.len());\nlet has_num = !rest[..end_num].is_empty();\nlet num: u64 = if has_num {\n        if let Ok(num) = rest[..end_num].parse() {\n            num\n        } else {\n            return Some(Err(ParseError::OutOfRange));\n        }\n    } else {\n        10\n    };\nrest = &rest[end_num..];\nlet mode = if let Some(r) = rest.strip_prefix('l') {\n        rest = r;\n        'l'\n    } else if let Some(r) = rest.strip_prefix('c') {\n        rest = r;\n        'c'\n    } else if let Some(r) = rest.strip_prefix('b') {\n        rest = r;\n        'b'\n    } else {\n        'l'\n    };\nlet follow = rest.contains('f');\nif !rest.chars().all(|f| f == 'f') {\n        // GNU allows an arbitrary amount of following fs, but nothing else\n        if sign == '-' && has_num {\n            return Some(Err(ParseError::Context));\n        }\n        return None;\n    }\nlet multiplier = if mode == 'b' { 512 } else { 1 };\nlet Some(num) = num.checked_mul(multiplier)\nelse {\n        return Some(Err(ParseError::Overflow));\n}\n;\nSome(Ok(ObsoleteArgs {\n        num,\n        plus: sign == '+',\n        lines: mode == 'l',\n        follow,\n    }))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    #[test]\n    fn test_parse_numbers_obsolete() {\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"+2c\")),\n            Some(Ok(ObsoleteArgs {\n                num: 2,\n                plus: true,\n                lines: false,\n                follow: false,\n            }))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-5\")),\n            Some(Ok(ObsoleteArgs {\n                num: 5,\n                plus: false,\n                lines: true,\n                follow: false,\n            }))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"+100f\")),\n            Some(Ok(ObsoleteArgs {\n                num: 100,\n                plus: true,\n                lines: true,\n                follow: true,\n            }))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-2b\")),\n            Some(Ok(ObsoleteArgs {\n                num: 1024,\n                plus: false,\n                lines: false,\n                follow: false,\n            }))\n        );\n    }\n    #[test]\n    fn test_parse_errors_obsolete() {\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-5n\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-5c5\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-1vzc\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-5m\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-1k\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-1mmk\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-105kzm\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-1vz\")),\n            Some(Err(ParseError::Context))\n        );\n        assert_eq!(\n            parse_obsolete(&OsString::from(\"-1vzqvq\")), // spell-checker:disable-line\n            Some(Err(ParseError::Context))\n        );\n    }\n    #[test]\n    fn test_parse_obsolete_no_match() {\n        assert_eq!(parse_obsolete(&OsString::from(\"-k\")), None);\n        assert_eq!(parse_obsolete(&OsString::from(\"asd\")), None);\n        assert_eq!(parse_obsolete(&OsString::from(\"-cc\")), None);\n    }\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\parse.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore tailable seekable stdlib (stdlib)\nuse crate::text;\nuse std::ffi::OsStr;\nuse std::fs::{File, Metadata};\nuse std::io::{Seek, SeekFrom};\n#[cfg(unix)]\nuse std::os::unix::fs::{FileTypeExt, MetadataExt};\nuse std::path::{Path, PathBuf};\nuse uucore::error::UResult;\n#[derive(Debug, Clone)]\npub enum InputKind {\n    File(PathBuf),\n    Stdin,\n}\n#[cfg(unix)]\nimpl From<&OsStr> for InputKind {\n    fn from(value: &OsStr) -> Self {\n        if value == OsStr::new(\"-\") {\n            Self::Stdin\n        } else {\n            Self::File(PathBuf::from(value))\n        }\n    }\n}\n#[cfg(not(unix))]\nimpl From<&OsStr> for InputKind {\n    fn from(value: &OsStr) -> Self {\n        if value == OsStr::new(text::DASH) {\n            Self::Stdin\n        } else {\n            Self::File(PathBuf::from(value))\n        }\n    }\n}\n#[derive(Debug, Clone)]\npub struct Input {\n    kind: InputKind,\n    pub display_name: String,\n}\nimpl Input {\n    pub fn from<T: AsRef<OsStr>>(string: T) -> Self {\n        let string = string.as_ref();\n\n        let kind = string.into();\n        let display_name = match kind {\n            InputKind::File(_) => string.to_string_lossy().to_string(),\n            InputKind::Stdin => text::STDIN_HEADER.to_string(),\n        };\n\n        Self { kind, display_name }\n    }\n\n    pub fn kind(&self) -> &InputKind {\n        &self.kind\n    }\n\n    pub fn is_stdin(&self) -> bool {\n        match self.kind {\n            InputKind::File(_) => false,\n            InputKind::Stdin => true,\n        }\n    }\n\n    pub fn resolve(&self) -> Option<PathBuf> {\n        match &self.kind {\n            InputKind::File(path) if path != &PathBuf::from(text::DEV_STDIN) => {\n                path.canonicalize().ok()\n            }\n            InputKind::File(_) | InputKind::Stdin => {\n                // on macOS, /dev/fd isn't backed by /proc and canonicalize()\n                // on dev/fd/0 (or /dev/stdin) will fail (NotFound),\n                // so we treat stdin as a pipe here\n                // https://github.com/rust-lang/rust/issues/95239\n                #[cfg(target_os = \"macos\")]\n                {\n                    None\n                }\n                #[cfg(not(target_os = \"macos\"))]\n                {\n                    PathBuf::from(text::FD0).canonicalize().ok()\n                }\n            }\n        }\n    }\n\n    pub fn is_tailable(&self) -> bool {\n        match &self.kind {\n            InputKind::File(path) => path_is_tailable(path),\n            InputKind::Stdin => self.resolve().is_some_and(|path| path_is_tailable(&path)),\n        }\n    }\n}\nimpl Default for Input {\n    fn default() -> Self {\n        Self {\n            kind: InputKind::Stdin,\n            display_name: String::from(text::STDIN_HEADER),\n        }\n    }\n}\n#[derive(Debug, Default, Clone, Copy)]\npub struct HeaderPrinter {\n    verbose: bool,\n    first_header: bool,\n}\nimpl HeaderPrinter {\n    pub fn new(verbose: bool, first_header: bool) -> Self {\n        Self {\n            verbose,\n            first_header,\n        }\n    }\n\n    pub fn print_input(&mut self, input: &Input) {\n        self.print(input.display_name.as_str());\n    }\n\n    pub fn print(&mut self, string: &str) {\n        if self.verbose {\n            println!(\n                \"{}==> {string} <==\",\n                if self.first_header { \"\" } else { \"\\n\" },\n            );\n            self.first_header = false;\n        }\n    }\n}\npub trait FileExtTail {\n    #[allow(clippy::wrong_self_convention)]\n    fn is_seekable(&mut self, current_offset: u64) -> bool;\n}\nimpl FileExtTail for File {\n    /// Test if File is seekable.\n    /// Set the current position offset to `current_offset`.\n    fn is_seekable(&mut self, current_offset: u64) -> bool {\n        self.stream_position().is_ok()\n            && self.seek(SeekFrom::End(0)).is_ok()\n            && self.seek(SeekFrom::Start(current_offset)).is_ok()\n    }\n}\npub trait MetadataExtTail {\n    fn is_tailable(&self) -> bool;\n    fn got_truncated(&self, other: &Metadata) -> UResult<bool>;\n    fn get_block_size(&self) -> u64;\n    fn file_id_eq(&self, other: &Metadata) -> bool;\n}\nimpl MetadataExtTail for Metadata {\n    fn is_tailable(&self) -> bool {\n        let ft = self.file_type();\n        #[cfg(unix)]\n        {\n            ft.is_file() || ft.is_char_device() || ft.is_fifo()\n        }\n        #[cfg(not(unix))]\n        {\n            ft.is_file()\n        }\n    }\n\n    /// Return true if the file was modified and is now shorter\n    fn got_truncated(&self, other: &Metadata) -> UResult<bool> {\n        Ok(other.len() < self.len() && other.modified()? != self.modified()?)\n    }\n\n    fn get_block_size(&self) -> u64 {\n        #[cfg(unix)]\n        {\n            self.blocks()\n        }\n        #[cfg(not(unix))]\n        {\n            self.len()\n        }\n    }\n\n    fn file_id_eq(&self, _other: &Metadata) -> bool {\n        #[cfg(unix)]\n        {\n            self.ino().eq(&_other.ino())\n        }\n        #[cfg(windows)]\n        {\n            // TODO: `file_index` requires unstable library feature `windows_by_handle`\n            // use std::os::windows::prelude::*;\n            // if let Some(self_id) = self.file_index() {\n            //     if let Some(other_id) = other.file_index() {\n            //     // TODO: not sure this is the equivalent of comparing inode numbers\n            //\n            //         return self_id.eq(&other_id);\n            //     }\n            // }\n            false\n        }\n    }\n}\npub trait PathExtTail {\n    fn is_stdin(&self) -> bool;\n    fn is_orphan(&self) -> bool;\n    fn is_tailable(&self) -> bool;\n}\nimpl PathExtTail for Path {\n    fn is_stdin(&self) -> bool {\n        self.eq(Self::new(text::DASH))\n            || self.eq(Self::new(text::DEV_STDIN))\n            || self.eq(Self::new(text::STDIN_HEADER))\n    }\n\n    /// Return true if `path` does not have an existing parent directory\n    fn is_orphan(&self) -> bool {\n        !matches!(self.parent(), Some(parent) if parent.is_dir())\n    }\n\n    /// Return true if `path` is is a file type that can be tailed\n    fn is_tailable(&self) -> bool {\n        path_is_tailable(self)\n    }\n}\npub fn path_is_tailable(path: &Path) -> bool {\n    path.is_file() || path.exists() && path.metadata().is_ok_and(|meta| meta.is_tailable())\n}\n#[inline]\npub fn stdin_is_bad_fd() -> bool {\n    // FIXME : Rust's stdlib is reopening fds as /dev/null\n    // see also: https://github.com/uutils/coreutils/issues/2873\n    // (gnu/tests/tail-2/follow-stdin.sh fails because of this)\n    //#[cfg(unix)]\n    {\n        //platform::stdin_is_bad_fd()\n    }\n    //#[cfg(not(unix))]\n    false\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\paths.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (ToDO) seekable seek'd tail'ing ringbuffer ringbuf unwatch\n// spell-checker:ignore (ToDO) Uncategorized filehandle Signum memrchr\n// spell-checker:ignore (libs) kqueue\n// spell-checker:ignore (acronyms)\n// spell-checker:ignore (env/flags)\n// spell-checker:ignore (jargon) tailable untailable stdlib\n// spell-checker:ignore (names)\n// spell-checker:ignore (shell/tools)\n// spell-checker:ignore (misc)\npub mod args;\npub mod chunks;\nmod follow;\nmod parse;\nmod paths;\nmod platform;\npub mod text;\npub use args::uu_app;\nuse args::{FilterMode, Settings, Signum, parse_args};\nuse chunks::ReverseChunks;\nuse follow::Observer;\nuse memchr::{memchr_iter, memrchr_iter};\nuse paths::{FileExtTail, HeaderPrinter, Input, InputKind, MetadataExtTail};\nuse same_file::Handle;\nuse std::cmp::Ordering;\nuse std::fs::File;\nuse std::io::{self, BufReader, BufWriter, ErrorKind, Read, Seek, SeekFrom, Write, stdin, stdout};\nuse std::path::{Path, PathBuf};\nuse uucore::display::Quotable;\nuse uucore::error::{FromIo, UResult, USimpleError, get_exit_code, set_exit_code};\nuse uucore::{show, show_error};\n#[uucore::main]\npub fn uumain(args: impl uucore::Args) -> UResult<()> {\n    let settings = parse_args(args)?;\n\n    settings.check_warnings();\n\n    match settings.verify() {\n        args::VerificationResult::CannotFollowStdinByName => {\n            return Err(USimpleError::new(\n                1,\n                format!(\"cannot follow {} by name\", text::DASH.quote()),\n            ));\n        }\n        // Exit early if we do not output anything. Note, that this may break a pipe\n        // when tail is on the receiving side.\n        args::VerificationResult::NoOutput => return Ok(()),\n        args::VerificationResult::Ok => {}\n    }\n\n    uu_tail(&settings)\n}\nfn uu_tail(settings: &Settings) -> UResult<()> {\n    let mut printer = HeaderPrinter::new(settings.verbose, true);\n    let mut observer = Observer::from(settings);\n\n    observer.start(settings)?;\n    // Do an initial tail print of each path's content.\n    // Add `path` and `reader` to `files` map if `--follow` is selected.\n    for input in &settings.inputs.clone() {\n        match input.kind() {\n            InputKind::Stdin => {\n                tail_stdin(settings, &mut printer, input, &mut observer)?;\n            }\n            InputKind::File(path) if cfg!(unix) && path == &PathBuf::from(text::DEV_STDIN) => {\n                tail_stdin(settings, &mut printer, input, &mut observer)?;\n            }\n            InputKind::File(path) => {\n                tail_file(settings, &mut printer, input, path, &mut observer, 0)?;\n            }\n        }\n    }\n\n    if settings.follow.is_some() {\n        /*\n        POSIX specification regarding tail -f\n        If the input file is a regular file or if the file operand specifies a FIFO, do not\n        terminate after the last line of the input file has been copied, but read and copy\n        further bytes from the input file when they become available. If no file operand is\n        specified and standard input is a pipe or FIFO, the -f option shall be ignored. If\n        the input file is not a FIFO, pipe, or regular file, it is unspecified whether or\n        not the -f option shall be ignored.\n        */\n        if !settings.has_only_stdin() || settings.pid != 0 {\n            follow::follow(observer, settings)?;\n        }\n    }\n\n    if get_exit_code() > 0 && paths::stdin_is_bad_fd() {\n        show_error!(\"-: {}\", text::BAD_FD);\n    }\n\n    Ok(())\n}\nfn tail_file(\n    settings: &Settings,\n    header_printer: &mut HeaderPrinter,\n    input: &Input,\n    path: &Path,\n    observer: &mut Observer,\n    offset: u64,\n) -> UResult<()> {\n    if !path.exists() {\n        set_exit_code(1);\n        show_error!(\n            \"cannot open '{}' for reading: {}\",\n            input.display_name,\n            text::NO_SUCH_FILE\n        );\n        observer.add_bad_path(path, input.display_name.as_str(), false)?;\n    } else if path.is_dir() {\n        set_exit_code(1);\n\n        header_printer.print_input(input);\n        let err_msg = \"Is a directory\".to_string();\n\n        show_error!(\"error reading '{}': {err_msg}\", input.display_name);\n        if settings.follow.is_some() {\n            let msg = if settings.retry {\n                \"\"\n            } else {\n                \"; giving up on this name\"\n            };\n            show_error!(\n                \"{}: cannot follow end of this type of file{msg}\",\n                input.display_name,\n            );\n        }\n        if !observer.follow_name_retry() {\n            // skip directory if not retry\n            return Ok(());\n        }\n        observer.add_bad_path(path, input.display_name.as_str(), false)?;\n    } else if input.is_tailable() {\n        let metadata = path.metadata().ok();\n        match File::open(path) {\n            Ok(mut file) => {\n                header_printer.print_input(input);\n                let mut reader;\n                if !settings.presume_input_pipe\n                    && file.is_seekable(if input.is_stdin() { offset } else { 0 })\n                    && metadata.as_ref().unwrap().get_block_size() > 0\n                {\n                    bounded_tail(&mut file, settings);\n                    reader = BufReader::new(file);\n                } else {\n                    reader = BufReader::new(file);\n                    unbounded_tail(&mut reader, settings)?;\n                }\n                observer.add_path(\n                    path,\n                    input.display_name.as_str(),\n                    Some(Box::new(reader)),\n                    true,\n                )?;\n            }\n            Err(e) if e.kind() == ErrorKind::PermissionDenied => {\n                observer.add_bad_path(path, input.display_name.as_str(), false)?;\n                show!(e.map_err_context(|| {\n                    format!(\"cannot open '{}' for reading\", input.display_name)\n                }));\n            }\n            Err(e) => {\n                observer.add_bad_path(path, input.display_name.as_str(), false)?;\n                return Err(e.map_err_context(|| {\n                    format!(\"cannot open '{}' for reading\", input.display_name)\n                }));\n            }\n        }\n    } else {\n        observer.add_bad_path(path, input.display_name.as_str(), false)?;\n    }\n\n    Ok(())\n}\nfn tail_stdin(\n    settings: &Settings,\n    header_printer: &mut HeaderPrinter,\n    input: &Input,\n    observer: &mut Observer,\n) -> UResult<()> {\n    // on macOS, resolve() will always return None for stdin,\n    // we need to detect if stdin is a directory ourselves.\n    // fstat-ing certain descriptors under /dev/fd fails with\n    // bad file descriptor or might not catch directory cases\n    // e.g. see the differences between running ls -l /dev/stdin /dev/fd/0\n    // on macOS and Linux.\n    #[cfg(target_os = \"macos\")]\n    {\n        if let Ok(mut stdin_handle) = Handle::stdin() {\n            if let Ok(meta) = stdin_handle.as_file_mut().metadata() {\n                if meta.file_type().is_dir() {\n                    set_exit_code(1);\n                    show_error!(\n                        \"cannot open '{}' for reading: {}\",\n                        input.display_name,\n                        text::NO_SUCH_FILE\n                    );\n                    return Ok(());\n                }\n            }\n        }\n    }\n\n    match input.resolve() {\n        // fifo\n        Some(path) => {\n            let mut stdin_offset = 0;\n            if cfg!(unix) {\n                // Save the current seek position/offset of a stdin redirected file.\n                // This is needed to pass \"gnu/tests/tail-2/start-middle.sh\"\n                if let Ok(mut stdin_handle) = Handle::stdin() {\n                    if let Ok(offset) = stdin_handle.as_file_mut().stream_position() {\n                        stdin_offset = offset;\n                    }\n                }\n            }\n            tail_file(\n                settings,\n                header_printer,\n                input,\n                &path,\n                observer,\n                stdin_offset,\n            )?;\n        }\n        // pipe\n        None => {\n            header_printer.print_input(input);\n            if paths::stdin_is_bad_fd() {\n                set_exit_code(1);\n                show_error!(\n                    \"cannot fstat {}: {}\",\n                    text::STDIN_HEADER.quote(),\n                    text::BAD_FD\n                );\n                if settings.follow.is_some() {\n                    show_error!(\n                        \"error reading {}: {}\",\n                        text::STDIN_HEADER.quote(),\n                        text::BAD_FD\n                    );\n                }\n            } else {\n                let mut reader = BufReader::new(stdin());\n                unbounded_tail(&mut reader, settings)?;\n                observer.add_stdin(input.display_name.as_str(), Some(Box::new(reader)), true)?;\n            }\n        }\n    };\n\n    Ok(())\n}\n/// Find the index after the given number of instances of a given byte.\n///\n/// This function reads through a given reader until `num_delimiters`\n/// instances of `delimiter` have been seen, returning the index of\n/// the byte immediately following that delimiter. If there are fewer\n/// than `num_delimiters` instances of `delimiter`, this returns the\n/// total number of bytes read from the `reader` until EOF.\n///\n/// # Errors\n///\n/// This function returns an error if there is an error during reading\n/// from `reader`.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust,ignore\n/// use std::io::Cursor;\n///\n/// let mut reader = Cursor::new(\"a\\nb\\nc\\nd\\ne\\n\");\n/// let i = forwards_thru_file(&mut reader, 2, b'\\n').unwrap();\n/// assert_eq!(i, 4);\n/// ```\n///\n/// If `num_delimiters` is zero, then this function always returns\n/// zero:\n///\n/// ```rust,ignore\n/// use std::io::Cursor;\n///\n/// let mut reader = Cursor::new(\"a\\n\");\n/// let i = forwards_thru_file(&mut reader, 0, b'\\n').unwrap();\n/// assert_eq!(i, 0);\n/// ```\n///\n/// If there are fewer than `num_delimiters` instances of `delimiter`\n/// in the reader, then this function returns the total number of\n/// bytes read:\n///\n/// ```rust,ignore\n/// use std::io::Cursor;\n///\n/// let mut reader = Cursor::new(\"a\\n\");",
      "file_name": "coreutils/src/uu\\tail\\src\\tail.rs"
    },
    {
      "chunk": "/// let i = forwards_thru_file(&mut reader, 2, b'\\n').unwrap();\n/// assert_eq!(i, 2);\n/// ```\nfn forwards_thru_file(\n    reader: &mut impl Read,\n    num_delimiters: u64,\n    delimiter: u8,\n) -> io::Result<usize> {\n    // If num_delimiters == 0, always return 0.\n    if num_delimiters == 0 {\n        return Ok(0);\n    }\n    // Use a 32K buffer.\n    let mut buf = [0; 32 * 1024];\n    let mut total = 0;\n    let mut count = 0;\n    // Iterate through the input, using `count` to record the number of times `delimiter`\n    // is seen. Once we find `num_delimiters` instances, return the offset of the byte\n    // immediately following that delimiter.\n    loop {\n        match reader.read(&mut buf) {\n            // Ok(0) => EoF before we found `num_delimiters` instance of `delimiter`.\n            // Return the total number of bytes read in that case.\n            Ok(0) => return Ok(total),\n            Ok(n) => {\n                // Use memchr_iter since it greatly improves search performance.\n                for offset in memchr_iter(delimiter, &buf[..n]) {\n                    count += 1;\n                    if count == num_delimiters {\n                        // Return offset of the byte after the `delimiter` instance.\n                        return Ok(total + offset + 1);\n                    }\n                }\n                total += n;\n            }\n            Err(e) if e.kind() == ErrorKind::Interrupted => continue,\n            Err(e) => return Err(e),\n        }\n    }\n}\n/// Iterate over bytes in the file, in reverse, until we find the\n/// `num_delimiters` instance of `delimiter`. The `file` is left seek'd to the\n/// position just after that delimiter.\nfn backwards_thru_file(file: &mut File, num_delimiters: u64, delimiter: u8) {\n    // This variable counts the number of delimiters found in the file\n    // so far (reading from the end of the file toward the beginning).\n    let mut counter = 0;\n    let mut first_slice = true;\n    for slice in ReverseChunks::new(file) {\n        // Iterate over each byte in the slice in reverse order.\n        let mut iter = memrchr_iter(delimiter, &slice);\n\n        // Ignore a trailing newline in the last block, if there is one.\n        if first_slice {\n            if let Some(c) = slice.last() {\n                if *c == delimiter {\n                    iter.next();\n                }\n            }\n            first_slice = false;\n        }\n\n        // For each byte, increment the count of the number of\n        // delimiters found. If we have found more than the specified\n        // number of delimiters, terminate the search and seek to the\n        // appropriate location in the file.\n        for i in iter {\n            counter += 1;\n            if counter >= num_delimiters {\n                // We should never over-count - assert that.\n                assert_eq!(counter, num_delimiters);\n                // After each iteration of the outer loop, the\n                // cursor in the file is at the *beginning* of the\n                // block, so seeking forward by `i + 1` bytes puts\n                // us right after the found delimiter.\n                file.seek(SeekFrom::Current((i + 1) as i64)).unwrap();\n                return;\n            }\n        }\n    }\n}\n/// When tail'ing a file, we do not need to read the whole file from start to\n/// finish just to find the last n lines or bytes. Instead, we can seek to the\n/// end of the file, and then read the file \"backwards\" in blocks of size\n/// `BLOCK_SIZE` until we find the location of the first line/byte. This ends up\n/// being a nice performance win for very large files.\nfn bounded_tail(file: &mut File, settings: &Settings) {\n    debug_assert!(!settings.presume_input_pipe);\n\n    // Find the position in the file to start printing from.\n    match &settings.mode {\n        FilterMode::Lines(Signum::Negative(count), delimiter) => {\n            backwards_thru_file(file, *count, *delimiter);\n        }\n        FilterMode::Lines(Signum::Positive(count), delimiter) if count > &1 => {\n            let i = forwards_thru_file(file, *count - 1, *delimiter).unwrap();\n            file.seek(SeekFrom::Start(i as u64)).unwrap();\n        }\n        FilterMode::Lines(Signum::MinusZero, _) => {\n            return;\n        }\n        FilterMode::Bytes(Signum::Negative(count)) => {\n            let len = file.seek(SeekFrom::End(0)).unwrap();\n            file.seek(SeekFrom::End(-((*count).min(len) as i64)))\n                .unwrap();\n        }\n        FilterMode::Bytes(Signum::Positive(count)) if count > &1 => {\n            // GNU `tail` seems to index bytes and lines starting at 1, not\n            // at 0. It seems to treat `+0` and `+1` as the same thing.\n            file.seek(SeekFrom::Start(*count - 1)).unwrap();\n        }\n        FilterMode::Bytes(Signum::MinusZero) => {\n            return;\n        }\n        _ => {}\n    }\n\n    // Print the target section of the file.\n    let stdout = stdout();\n    let mut stdout = stdout.lock();\n    io::copy(file, &mut stdout).unwrap();\n}\nfn unbounded_tail<T: Read>(reader: &mut BufReader<T>, settings: &Settings) -> UResult<()> {\n    let mut writer = BufWriter::new(stdout().lock());\n    match &settings.mode {\n        FilterMode::Lines(Signum::Negative(count), sep) => {\n            let mut chunks = chunks::LinesChunkBuffer::new(*sep, *count);\n            chunks.fill(reader)?;\n            chunks.print(&mut writer)?;\n        }\n        FilterMode::Lines(Signum::PlusZero | Signum::Positive(1), _) => {\n            io::copy(reader, &mut writer)?;\n        }\n        FilterMode::Lines(Signum::Positive(count), sep) => {\n            let mut num_skip = *count - 1;\n            let mut chunk = chunks::LinesChunk::new(*sep);\n            while chunk.fill(reader)?.is_some() {\n                let lines = chunk.get_lines() as u64;\n                if lines < num_skip {\n                    num_skip -= lines;\n                } else {\n                    break;\n                }\n            }\n            if chunk.has_data() {\n                chunk.print_lines(&mut writer, num_skip as usize)?;\n                io::copy(reader, &mut writer)?;\n            }\n        }\n        FilterMode::Bytes(Signum::Negative(count)) => {\n            let mut chunks = chunks::BytesChunkBuffer::new(*count);\n            chunks.fill(reader)?;\n            chunks.print(&mut writer)?;\n        }\n        FilterMode::Bytes(Signum::PlusZero | Signum::Positive(1)) => {\n            io::copy(reader, &mut writer)?;\n        }\n        FilterMode::Bytes(Signum::Positive(count)) => {\n            let mut num_skip = *count - 1;\n            let mut chunk = chunks::BytesChunk::new();\n            loop {\n                if let Some(bytes) = chunk.fill(reader)? {\n                    let bytes: u64 = bytes as u64;\n                    match bytes.cmp(&num_skip) {\n                        Ordering::Less => num_skip -= bytes,\n                        Ordering::Equal => {\n                            break;\n                        }\n                        Ordering::Greater => {\n                            writer.write_all(chunk.get_buffer_with(num_skip as usize))?;\n                            break;\n                        }\n                    }\n                } else {\n                    return Ok(());\n                }\n            }\n\n            io::copy(reader, &mut writer)?;\n        }\n        _ => {}\n    }\n    writer.flush()?;\n    Ok(())\n}\n#[cfg(test)]\nmod tests {\n\n    use crate::forwards_thru_file;\n    use std::io::Cursor;\n\n    #[test]\n    fn test_forwards_thru_file_zero() {\n        let mut reader = Cursor::new(\"a\\n\");\n        let i = forwards_thru_file(&mut reader, 0, b'\\n').unwrap();\n        assert_eq!(i, 0);\n    }\n\n    #[test]\n    fn test_forwards_thru_file_basic() {\n        //                   01 23 45 67 89\n        let mut reader = Cursor::new(\"a\\nb\\nc\\nd\\ne\\n\");\n        let i = forwards_thru_file(&mut reader, 2, b'\\n').unwrap();\n        assert_eq!(i, 4);\n    }\n\n    #[test]\n    fn test_forwards_thru_file_past_end() {\n        let mut reader = Cursor::new(\"x\\n\");\n        let i = forwards_thru_file(&mut reader, 2, b'\\n').unwrap();\n        assert_eq!(i, 2);\n    }\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\tail.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (ToDO) kqueue\npub const DASH: &str = \"-\";\npub const DEV_STDIN: &str = \"/dev/stdin\";\npub const STDIN_HEADER: &str = \"standard input\";\npub const NO_FILES_REMAINING: &str = \"no files remaining\";\npub const NO_SUCH_FILE: &str = \"No such file or directory\";\npub const BECOME_INACCESSIBLE: &str = \"has become inaccessible\";\npub const BAD_FD: &str = \"Bad file descriptor\";\n#[cfg(target_os = \"linux\")]\npub const BACKEND: &str = \"inotify\";\n#[cfg(all(unix, not(target_os = \"linux\")))]\npub const BACKEND: &str = \"kqueue\";\n#[cfg(target_os = \"windows\")]\npub const BACKEND: &str = \"ReadDirectoryChanges\";\npub const FD0: &str = \"/dev/fd/0\";\npub const IS_A_DIRECTORY: &str = \"Is a directory\";\npub const DEV_TTY: &str = \"/dev/tty\";\npub const DEV_PTMX: &str = \"/dev/ptmx\";",
      "file_name": "coreutils/src/uu\\tail\\src\\text.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore tailable seekable stdlib (stdlib)\nuse crate::args::Settings;\nuse crate::chunks::BytesChunkBuffer;\nuse crate::paths::{HeaderPrinter, PathExtTail};\nuse crate::text;\nuse std::collections::HashMap;\nuse std::collections::hash_map::Keys;\nuse std::fs::{File, Metadata};\nuse std::io::{BufRead, BufReader, BufWriter, Write, stdout};\nuse std::path::{Path, PathBuf};\nuse uucore::error::UResult;\n/// Data structure to keep a handle on files to follow.\n/// `last` always holds the path/key of the last file that was printed from.\n/// The keys of the HashMap can point to an existing file path (normal case),\n/// or stdin (\"-\"), or to a non existing path (--retry).\n/// For existing files, all keys in the HashMap are absolute Paths.\npub struct FileHandling {\n    map: HashMap<PathBuf, PathData>,\n    last: Option<PathBuf>,\n    header_printer: HeaderPrinter,\n}\nimpl FileHandling {\n    pub fn from(settings: &Settings) -> Self {\n        Self {\n            map: HashMap::with_capacity(settings.inputs.len()),\n            last: None,\n            header_printer: HeaderPrinter::new(settings.verbose, false),\n        }\n    }\n\n    /// Wrapper for HashMap::insert using Path::canonicalize\n    pub fn insert(&mut self, k: &Path, v: PathData, update_last: bool) {\n        let k = Self::canonicalize_path(k);\n        if update_last {\n            self.last = Some(k.clone());\n        }\n        let _ = self.map.insert(k, v);\n    }\n\n    /// Wrapper for HashMap::remove using Path::canonicalize\n    pub fn remove(&mut self, k: &Path) -> PathData {\n        self.map.remove(&Self::canonicalize_path(k)).unwrap()\n    }\n\n    /// Wrapper for HashMap::get using Path::canonicalize\n    pub fn get(&self, k: &Path) -> &PathData {\n        self.map.get(&Self::canonicalize_path(k)).unwrap()\n    }\n\n    /// Wrapper for HashMap::get_mut using Path::canonicalize\n    pub fn get_mut(&mut self, k: &Path) -> &mut PathData {\n        self.map.get_mut(&Self::canonicalize_path(k)).unwrap()\n    }\n\n    /// Canonicalize `path` if it is not already an absolute path\n    fn canonicalize_path(path: &Path) -> PathBuf {\n        if path.is_relative() && !path.is_stdin() {\n            if let Ok(p) = path.canonicalize() {\n                return p;\n            }\n        }\n        path.to_owned()\n    }\n\n    pub fn get_mut_metadata(&mut self, path: &Path) -> Option<&Metadata> {\n        self.get_mut(path).metadata.as_ref()\n    }\n\n    pub fn keys(&self) -> Keys<PathBuf, PathData> {\n        self.map.keys()\n    }\n\n    pub fn contains_key(&self, k: &Path) -> bool {\n        self.map.contains_key(k)\n    }\n\n    pub fn get_last(&self) -> Option<&PathBuf> {\n        self.last.as_ref()\n    }\n\n    /// Return true if there is only stdin remaining\n    pub fn only_stdin_remaining(&self) -> bool {\n        self.map.len() == 1 && (self.map.contains_key(Path::new(text::DASH)))\n    }\n\n    /// Return true if there is at least one \"tailable\" path (or stdin) remaining\n    pub fn files_remaining(&self) -> bool {\n        for path in self.map.keys() {\n            if path.is_tailable() || path.is_stdin() {\n                return true;\n            }\n        }\n        false\n    }\n\n    /// Returns true if there are no files remaining\n    pub fn no_files_remaining(&self, settings: &Settings) -> bool {\n        self.map.is_empty() || !self.files_remaining() && !settings.retry\n    }\n\n    /// Set `reader` to None to indicate that `path` is not an existing file anymore.\n    pub fn reset_reader(&mut self, path: &Path) {\n        self.get_mut(path).reader = None;\n    }\n\n    /// Reopen the file at the monitored `path`\n    pub fn update_reader(&mut self, path: &Path) -> UResult<()> {\n        /*\n        BUG: If it's not necessary to reopen a file, GNU's tail calls seek to offset 0.\n        However we can't call seek here because `BufRead` does not implement `Seek`.\n        As a workaround we always reopen the file even though this might not always\n        be necessary.\n        */\n        self.get_mut(path)\n            .reader\n            .replace(Box::new(BufReader::new(File::open(path)?)));\n        Ok(())\n    }\n\n    /// Reload metadata from `path`, or `metadata`\n    pub fn update_metadata(&mut self, path: &Path, metadata: Option<Metadata>) {\n        self.get_mut(path).metadata = if metadata.is_some() {\n            metadata\n        } else {\n            path.metadata().ok()\n        };\n    }\n\n    /// Read new data from `path` and print it to stdout\n    pub fn tail_file(&mut self, path: &Path, verbose: bool) -> UResult<bool> {\n        let mut chunks = BytesChunkBuffer::new(u64::MAX);\n        if let Some(reader) = self.get_mut(path).reader.as_mut() {\n            chunks.fill(reader)?;\n        }\n        if chunks.has_data() {\n            if self.needs_header(path, verbose) {\n                let display_name = self.get(path).display_name.clone();\n                self.header_printer.print(display_name.as_str());\n            }\n\n            let mut writer = BufWriter::new(stdout().lock());\n            chunks.print(&mut writer)?;\n            writer.flush()?;\n\n            self.last.replace(path.to_owned());\n            self.update_metadata(path, None);\n            Ok(true)\n        } else {\n            Ok(false)\n        }\n    }\n\n    /// Decide if printing `path` needs a header based on when it was last printed\n    pub fn needs_header(&self, path: &Path, verbose: bool) -> bool {\n        if verbose {\n            if let Some(ref last) = self.last {\n                !last.eq(&path)\n            } else {\n                true\n            }\n        } else {\n            false\n        }\n    }\n}\n/// Data structure to keep a handle on the BufReader, Metadata\n/// and the display_name (header_name) of files that are being followed.\npub struct PathData {\n    pub reader: Option<Box<dyn BufRead>>,\n    pub metadata: Option<Metadata>,\n    pub display_name: String,\n}\nimpl PathData {\n    pub fn new(\n        reader: Option<Box<dyn BufRead>>,\n        metadata: Option<Metadata>,\n        display_name: &str,\n    ) -> Self {\n        Self {\n            reader,\n            metadata,\n            display_name: display_name.to_owned(),\n        }\n    }\n    pub fn from_other_with_path(data: Self, path: &Path) -> Self {\n        // Remove old reader\n        let old_reader = data.reader;\n        let reader = if old_reader.is_some() {\n            // Use old reader with the same file descriptor if there is one\n            old_reader\n        } else if let Ok(file) = File::open(path) {\n            // Open new file tail from start\n            Some(Box::new(BufReader::new(file)) as Box<dyn BufRead>)\n        } else {\n            // Probably file was renamed/moved or removed again\n            None\n        };\n\n        Self::new(reader, path.metadata().ok(), data.display_name.as_str())\n    }\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\follow\\files.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nmod files;\nmod watch;\npub use watch::{Observer, follow};",
      "file_name": "coreutils/src/uu\\tail\\src\\follow\\mod.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (ToDO) tailable untailable stdlib kqueue Uncategorized unwatch\nuse crate::args::{FollowMode, Settings};\nuse crate::follow::files::{FileHandling, PathData};\nuse crate::paths::{Input, InputKind, MetadataExtTail, PathExtTail};\nuse crate::{platform, text};\nuse notify::{RecommendedWatcher, RecursiveMode, Watcher, WatcherKind};\nuse std::io::BufRead;\nuse std::path::{Path, PathBuf};\nuse std::sync::mpsc::{self, Receiver, channel};\nuse uucore::display::Quotable;\nuse uucore::error::{UResult, USimpleError, set_exit_code};\nuse uucore::show_error;\npub struct WatcherRx {\n    watcher: Box<dyn Watcher>,\n    receiver: Receiver<Result<notify::Event, notify::Error>>,\n}\nimpl WatcherRx {\n    fn new(\n        watcher: Box<dyn Watcher>,\n        receiver: Receiver<Result<notify::Event, notify::Error>>,\n    ) -> Self {\n        Self { watcher, receiver }\n    }\n\n    /// Wrapper for `notify::Watcher::watch` to also add the parent directory of `path` if necessary.\n    fn watch_with_parent(&mut self, path: &Path) -> UResult<()> {\n        let mut path = path.to_owned();\n        #[cfg(target_os = \"linux\")]\n        if path.is_file() {\n            /*\n            NOTE: Using the parent directory instead of the file is a workaround.\n            This workaround follows the recommendation of the notify crate authors:\n            > On some platforms, if the `path` is renamed or removed while being watched, behavior may\n            > be unexpected. See discussions in [#165] and [#166]. If less surprising behavior is wanted\n            > one may non-recursively watch the _parent_ directory as well and manage related events.\n            NOTE: Adding both: file and parent results in duplicate/wrong events.\n            Tested for notify::InotifyWatcher and for notify::PollWatcher.\n            */\n            if let Some(parent) = path.parent() {\n                // clippy::assigning_clones added with Rust 1.78\n                // Rust version = 1.76 on OpenBSD stable/7.5\n                #[cfg_attr(not(target_os = \"openbsd\"), allow(clippy::assigning_clones))]\n                if parent.is_dir() {\n                    path = parent.to_owned();\n                } else {\n                    path = PathBuf::from(\".\");\n                }\n            } else {\n                return Err(USimpleError::new(\n                    1,\n                    format!(\"cannot watch parent directory of {}\", path.display()),\n                ));\n            };\n        }\n        if path.is_relative() {\n            path = path.canonicalize()?;\n        }\n\n        // for syscalls: 2x \"inotify_add_watch\" (\"filename\" and \".\") and 1x \"inotify_rm_watch\"\n        self.watch(&path, RecursiveMode::NonRecursive)?;\n        Ok(())\n    }\n\n    fn watch(&mut self, path: &Path, mode: RecursiveMode) -> UResult<()> {\n        self.watcher\n            .watch(path, mode)\n            .map_err(|err| USimpleError::new(1, err.to_string()))\n    }\n\n    fn unwatch(&mut self, path: &Path) -> UResult<()> {\n        self.watcher\n            .unwatch(path)\n            .map_err(|err| USimpleError::new(1, err.to_string()))\n    }\n}\npub struct Observer {\n    /// Whether --retry was given on the command line\n    pub retry: bool,\n\n    /// The [`FollowMode`]\n    pub follow: Option<FollowMode>,\n\n    /// Indicates whether to use the fallback `polling` method instead of the\n    /// platform specific event driven method. Since `use_polling` is subject to\n    /// change during runtime it is moved out of [`Settings`].\n    pub use_polling: bool,\n\n    pub watcher_rx: Option<WatcherRx>,\n    pub orphans: Vec<PathBuf>,\n    pub files: FileHandling,\n\n    pub pid: platform::Pid,\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\follow\\watch.rs"
    },
    {
      "chunk": "impl Observer {\n    pub fn new(\n        retry: bool,\n        follow: Option<FollowMode>,\n        use_polling: bool,\n        files: FileHandling,\n        pid: platform::Pid,\n    ) -> Self {\n        let pid = if platform::supports_pid_checks(pid) {\n            pid\n        } else {\n            0\n        };\n\n        Self {\n            retry,\n            follow,\n            use_polling,\n            watcher_rx: None,\n            orphans: Vec::new(),\n            files,\n            pid,\n        }\n    }\n\n    pub fn from(settings: &Settings) -> Self {\n        Self::new(\n            settings.retry,\n            settings.follow,\n            settings.use_polling,\n            FileHandling::from(settings),\n            settings.pid,\n        )\n    }\n\n    pub fn add_path(\n        &mut self,\n        path: &Path,\n        display_name: &str,\n        reader: Option<Box<dyn BufRead>>,\n        update_last: bool,\n    ) -> UResult<()> {\n        if self.follow.is_some() {\n            let path = if path.is_relative() {\n                std::env::current_dir()?.join(path)\n            } else {\n                path.to_owned()\n            };\n            let metadata = path.metadata().ok();\n            self.files.insert(\n                &path,\n                PathData::new(reader, metadata, display_name),\n                update_last,\n            );\n        }\n\n        Ok(())\n    }\n\n    pub fn add_stdin(\n        &mut self,\n        display_name: &str,\n        reader: Option<Box<dyn BufRead>>,\n        update_last: bool,\n    ) -> UResult<()> {\n        if self.follow == Some(FollowMode::Descriptor) {\n            return self.add_path(\n                &PathBuf::from(text::DEV_STDIN),\n                display_name,\n                reader,\n                update_last,\n            );\n        }\n\n        Ok(())\n    }\n\n    pub fn add_bad_path(\n        &mut self,\n        path: &Path,\n        display_name: &str,\n        update_last: bool,\n    ) -> UResult<()> {\n        if self.retry && self.follow.is_some() {\n            return self.add_path(path, display_name, None, update_last);\n        }\n\n        Ok(())\n    }\n\n    pub fn start(&mut self, settings: &Settings) -> UResult<()> {\n        if settings.follow.is_none() {\n            return Ok(());\n        }\n\n        let (tx, rx) = channel();\n\n        /*\n        Watcher is implemented per platform using the best implementation available on that\n        platform. In addition to such event driven implementations, a polling implementation\n        is also provided that should work on any platform.\n        Linux / Android: inotify\n        macOS: FSEvents / kqueue\n        Windows: ReadDirectoryChangesWatcher\n        FreeBSD / NetBSD / OpenBSD / DragonflyBSD: kqueue\n        Fallback: polling every n seconds\n\n        NOTE:\n        We force the use of kqueue with: features=[\"macos_kqueue\"].\n        On macOS only `kqueue` is suitable for our use case because `FSEvents`\n        waits for file close util it delivers a modify event. See:\n        https://github.com/notify-rs/notify/issues/240\n        */\n\n        let watcher: Box<dyn Watcher>;\n        let watcher_config = notify::Config::default()\n            .with_poll_interval(settings.sleep_sec)\n            /*\n            NOTE: By enabling compare_contents, performance will be significantly impacted\n            as all files will need to be read and hashed at each `poll_interval`.\n            However, this is necessary to pass: \"gnu/tests/tail-2/F-vs-rename.sh\"\n            */\n            .with_compare_contents(true);\n        if self.use_polling || RecommendedWatcher::kind() == WatcherKind::PollWatcher {\n            self.use_polling = true; // We have to use polling because there's no supported backend\n            watcher = Box::new(notify::PollWatcher::new(tx, watcher_config).unwrap());\n        } else {\n            let tx_clone = tx.clone();\n            match RecommendedWatcher::new(tx, notify::Config::default()) {\n                Ok(w) => watcher = Box::new(w),\n                Err(e) if e.to_string().starts_with(\"Too many open files\") => {\n                    /*\n                    NOTE: This ErrorKind is `Uncategorized`, but it is not recommended\n                    to match an error against `Uncategorized`\n                    NOTE: Could be tested with decreasing `max_user_instances`, e.g.:\n                    `sudo sysctl fs.inotify.max_user_instances=64`\n                    */\n                    show_error!(\n                        \"{} cannot be used, reverting to polling: Too many open files\",\n                        text::BACKEND\n                    );\n                    set_exit_code(1);\n                    self.use_polling = true;\n                    watcher = Box::new(notify::PollWatcher::new(tx_clone, watcher_config).unwrap());\n                }\n                Err(e) => return Err(USimpleError::new(1, e.to_string())),\n            };\n        }\n\n        self.watcher_rx = Some(WatcherRx::new(watcher, rx));\n        self.init_files(&settings.inputs)?;\n\n        Ok(())\n    }\n\n    pub fn follow_descriptor(&self) -> bool {\n        self.follow == Some(FollowMode::Descriptor)\n    }\n\n    pub fn follow_name(&self) -> bool {\n        self.follow == Some(FollowMode::Name)\n    }\n\n    pub fn follow_descriptor_retry(&self) -> bool {\n        self.follow_descriptor() && self.retry\n    }\n\n    pub fn follow_name_retry(&self) -> bool {\n        self.follow_name() && self.retry\n    }\n\n    fn init_files(&mut self, inputs: &Vec<Input>) -> UResult<()> {\n        if let Some(watcher_rx) = &mut self.watcher_rx {\n            for input in inputs {\n                match input.kind() {\n                    InputKind::Stdin => continue,\n                    InputKind::File(path) => {\n                        #[cfg(all(unix, not(target_os = \"linux\")))]\n                        if !path.is_file() {\n                            continue;\n                        }\n                        let mut path = path.clone();\n                        if path.is_relative() {\n                            path = std::env::current_dir()?.join(path);\n                        }\n\n                        if path.is_tailable() {\n                            // Add existing regular files to `Watcher` (InotifyWatcher).\n                            watcher_rx.watch_with_parent(&path)?;\n                        } else if !path.is_orphan() {\n                            // If `path` is not a tailable file, add its parent to `Watcher`.\n                            watcher_rx\n                                .watch(path.parent().unwrap(), RecursiveMode::NonRecursive)?;\n                        } else {\n                            // If there is no parent, add `path` to `orphans`.\n                            self.orphans.push(path);\n                        }\n                    }\n                }\n            }\n        }\n        Ok(())\n    }\n\n    #[allow(clippy::cognitive_complexity)]\n    fn handle_event(\n        &mut self,\n        event: &notify::Event,\n        settings: &Settings,\n    ) -> UResult<Vec<PathBuf>> {\n        use notify::event::*;\n\n        let event_path = event.paths.first().unwrap();\n        let mut paths: Vec<PathBuf> = vec![];\n        let display_name = self.files.get(event_path).display_name.clone();\n\n        match event.kind {\n            EventKind::Modify(ModifyKind::Metadata(MetadataKind::Any |\nMetadataKind::WriteTime) | ModifyKind::Data(DataChange::Any) |\nModifyKind::Name(RenameMode::To)) |\nEventKind::Create(CreateKind::File | CreateKind::Folder | CreateKind::Any) => {\n                    if let Ok(new_md) = event_path.metadata() {\n\n                        let is_tailable = new_md.is_tailable();\n                        let pd = self.files.get(event_path);\n                        if let Some(old_md) = &pd.metadata {\n                            if is_tailable {\n                                // We resume tracking from the start of the file,\n                                // assuming it has been truncated to 0. This mimics GNU's `tail`\n                                // behavior and is the usual truncation operation for log self.files.\n                                if !old_md.is_tailable() {\n                                    show_error!( \"{} has become accessible\", display_name.quote());\n                                    self.files.update_reader(event_path)?;\n                                } else if pd.reader.is_none() {\n                                    show_error!( \"{} has appeared;  following new file\", display_name.quote());\n                                    self.files.update_reader(event_path)?;\n                                } else if event.kind == EventKind::Modify(ModifyKind::Name(RenameMode::To))\n                                || (self.use_polling\n                                && !old_md.file_id_eq(&new_md)) {\n                                    show_error!( \"{} has been replaced;  following new file\", display_name.quote());\n                                    self.files.update_reader(event_path)?;\n                                } else if old_md.got_truncated(&new_md)? {\n                                    show_error!(\"{display_name}: file truncated\");\n                                    self.files.update_reader(event_path)?;\n                                }\n                                paths.push(event_path.clone());\n                            } else if !is_tailable && old_md.is_tailable() {\n                                if pd.reader.is_some() {\n                                    self.files.reset_reader(event_path);\n                                } else {\n                                    show_error!(\n                                        \"{} has been replaced with an untailable file\",\n                                        display_name.quote()\n                                    );\n                                }\n                            }\n                        } else if is_tailable {\n                                show_error!( \"{} has appeared;  following new file\", display_name.quote());\n                                self.files.update_reader(event_path)?;\n                                paths.push(event_path.clone());\n                            } else if settings.retry {\n                                if self.follow_descriptor() {\n                                    show_error!(\n                                        \"{} has been replaced with an untailable file; giving up on this name\",\n                                        display_name.quote()\n                                    );\n                                    let _ = self.watcher_rx.as_mut().unwrap().watcher.unwatch(event_path);\n                                    self.files.remove(event_path);\n                                    if self.files.no_files_remaining(settings) {\n                                        return Err(USimpleError::new(1, text::NO_FILES_REMAINING));\n                                    }\n                                } else {\n                                    show_error!(\n                                        \"{} has been replaced with an untailable file\",\n                                        display_name.quote()\n                                    );\n                                }\n                            }\n                        self.files.update_metadata(event_path, Some(new_md));\n                    }\n                }\n            EventKind::Remove(RemoveKind::File | RemoveKind::Any)\n\n                // | EventKind::Modify(ModifyKind::Name(RenameMode::Any))\n                | EventKind::Modify(ModifyKind::Name(RenameMode::From)) => {\n                    if self.follow_name() {\n                        if settings.retry {\n                            if let Some(old_md) = self.files.get_mut_metadata(event_path) {\n                                if old_md.is_tailable() && self.files.get(event_path).reader.is_some() {\n                                    show_error!(\n                                        \"{} {}: {}\",\n                                        display_name.quote(),\n                                        text::BECOME_INACCESSIBLE,\n                                        text::NO_SUCH_FILE\n                                    );\n                                }\n                            }\n                            if event_path.is_orphan() && !self.orphans.contains(event_path) {\n                                show_error!(\"directory containing watched file was removed\");\n                                show_error!(",
      "file_name": "coreutils/src/uu\\tail\\src\\follow\\watch.rs"
    },
    {
      "chunk": "                                    \"{} cannot be used, reverting to polling\",\n                                    text::BACKEND\n                                );\n                                self.orphans.push(event_path.clone());\n                                let _ = self.watcher_rx.as_mut().unwrap().unwatch(event_path);\n                            }\n                        } else {\n                            show_error!(\"{display_name}: {}\", text::NO_SUCH_FILE);\n                            if !self.files.files_remaining() && self.use_polling {\n                                // NOTE: GNU's tail exits here for `---disable-inotify`\n                                return Err(USimpleError::new(1, text::NO_FILES_REMAINING));\n                            }\n                        }\n                        self.files.reset_reader(event_path);\n                    } else if self.follow_descriptor_retry() {\n                        // --retry only effective for the initial open\n                        let _ = self.watcher_rx.as_mut().unwrap().unwatch(event_path);\n                        self.files.remove(event_path);\n                    } else if self.use_polling && event.kind == EventKind::Remove(RemoveKind::Any) {\n                        /*\n                        BUG: The watched file was removed. Since we're using Polling, this\n                        could be a rename. We can't tell because `notify::PollWatcher` doesn't\n                        recognize renames properly.\n                        Ideally we want to call seek to offset 0 on the file handle.\n                        But because we only have access to `PathData::reader` as `BufRead`,\n                        we cannot seek to 0 with `BufReader::seek_relative`.\n                        Also because we don't have the new name, we cannot work around this\n                        by simply reopening the file.\n                        */\n                    }\n                }\n            EventKind::Modify(ModifyKind::Name(RenameMode::Both)) => {\n                /*\n                NOTE: For `tail -f a`, keep tracking additions to b after `mv a b`\n                (gnu/tests/tail-2/descriptor-vs-rename.sh)\n                NOTE: The File/BufReader doesn't need to be updated.\n                However, we need to update our `files.map`.\n                This can only be done for inotify, because this EventKind does not\n                trigger for the PollWatcher.\n                BUG: As a result, there's a bug if polling is used:\n                $ tail -f file_a ---disable-inotify\n                $ mv file_a file_b\n                $ echo A >> file_b\n                $ echo A >> file_a\n                The last append to file_a is printed, however this shouldn't be because\n                after the \"mv\" tail should only follow \"file_b\".\n                TODO: [2022-05; jhscheer] add test for this bug\n                */\n\n                if self.follow_descriptor() {\n                    let new_path = event.paths.last().unwrap();\n                    paths.push(new_path.clone());\n\n                    let new_data = PathData::from_other_with_path(self.files.remove(event_path), new_path);\n                    self.files.insert(\n                        new_path,\n                        new_data,\n                        self.files.get_last().unwrap() == event_path\n                    );\n\n                    // Unwatch old path and watch new path\n                    let _ = self.watcher_rx.as_mut().unwrap().unwatch(event_path);\n                    self.watcher_rx.as_mut().unwrap().watch_with_parent(new_path)?;\n                }\n            }\n            _ => {}\n        }\n        Ok(paths)\n    }\n}\n#[allow(clippy::cognitive_complexity)]\npub fn follow(mut observer: Observer, settings: &Settings) -> UResult<()> {\n    if observer.files.no_files_remaining(settings) && !observer.files.only_stdin_remaining() {\n        return Err(USimpleError::new(1, text::NO_FILES_REMAINING.to_string()));\n    }\n\n    let mut process = platform::ProcessChecker::new(observer.pid);\n\n    let mut timeout_counter = 0;\n\n    // main follow loop\n    loop {\n        let mut _read_some = false;\n\n        // If `--pid=p`, tail checks whether process p\n        // is alive at least every `--sleep-interval=N` seconds\n        if settings.follow.is_some() && observer.pid != 0 && process.is_dead() {\n            // p is dead, tail will also terminate\n            break;\n        }\n\n        // For `-F` we need to poll if an orphan path becomes available during runtime.\n        // If a path becomes an orphan during runtime, it will be added to orphans.\n        // To be able to differentiate between the cases of test_retry8 and test_retry9,\n        // here paths will not be removed from orphans if the path becomes available.\n        if observer.follow_name_retry() {\n            for new_path in &observer.orphans {\n                if new_path.exists() {\n                    let pd = observer.files.get(new_path);\n                    let md = new_path.metadata().unwrap();\n                    if md.is_tailable() && pd.reader.is_none() {\n                        show_error!(\n                            \"{} has appeared;  following new file\",\n                            pd.display_name.quote()\n                        );\n                        observer.files.update_metadata(new_path, Some(md));\n                        observer.files.update_reader(new_path)?;\n                        _read_some = observer.files.tail_file(new_path, settings.verbose)?;\n                        observer\n                            .watcher_rx\n                            .as_mut()\n                            .unwrap()\n                            .watch_with_parent(new_path)?;\n                    }\n                }\n            }\n        }\n\n        // With  -f, sleep for approximately N seconds (default 1.0) between iterations;\n        // We wake up if Notify sends an Event or if we wait more than `sleep_sec`.\n        let rx_result = observer\n            .watcher_rx\n            .as_mut()\n            .unwrap()\n            .receiver\n            .recv_timeout(settings.sleep_sec);\n        if rx_result.is_ok() {\n            timeout_counter = 0;\n        }\n\n        let mut paths = vec![]; // Paths worth checking for new content to print\n        match rx_result {\n            Ok(Ok(event)) => {\n                if let Some(event_path) = event.paths.first() {\n                    if observer.files.contains_key(event_path) {\n                        // Handle Event if it is about a path that we are monitoring\n                        paths = observer.handle_event(&event, settings)?;\n                    }\n                }\n            }\n            Ok(Err(notify::Error {\n                kind: notify::ErrorKind::Io(ref e),\n                paths,\n            })) if e.kind() == std::io::ErrorKind::NotFound => {\n                if let Some(event_path) = paths.first() {\n                    if observer.files.contains_key(event_path) {\n                        let _ = observer\n                            .watcher_rx\n                            .as_mut()\n                            .unwrap()\n                            .watcher\n                            .unwatch(event_path);\n                    }\n                }\n            }\n            Ok(Err(notify::Error {\n                kind: notify::ErrorKind::MaxFilesWatch,\n                ..\n            })) => {\n                return Err(USimpleError::new(\n                    1,\n                    format!(\"{} resources exhausted\", text::BACKEND),\n                ));\n            }\n            Ok(Err(e)) => return Err(USimpleError::new(1, format!(\"NotifyError: {e}\"))),\n            Err(mpsc::RecvTimeoutError::Timeout) => {\n                timeout_counter += 1;\n            }\n            Err(e) => return Err(USimpleError::new(1, format!(\"RecvTimeoutError: {e}\"))),\n        }\n\n        if observer.use_polling && settings.follow.is_some() {\n            // Consider all files to potentially have new content.\n            // This is a workaround because `Notify::PollWatcher`\n            // does not recognize the \"renaming\" of files.\n            paths = observer.files.keys().cloned().collect::<Vec<_>>();\n        }\n\n        // main print loop\n        for path in &paths {\n            _read_some = observer.files.tail_file(path, settings.verbose)?;\n        }\n\n        if timeout_counter == settings.max_unchanged_stats {\n            /*\n            TODO: [2021-10; jhscheer] implement timeout_counter for each file.\n            \u2018--max-unchanged-stats=n\u2019\n            When tailing a file by name, if there have been n (default n=5) consecutive iterations\n            for which the file has not changed, then open/fstat the file to determine if that file\n            name is still associated with the same device/inode-number pair as before. When\n            following a log file that is rotated, this is approximately the number of seconds\n            between when tail prints the last pre-rotation lines and when it prints the lines that\n            have accumulated in the new log file. This option is meaningful only when polling\n            (i.e., without inotify) and when following by name.\n            */\n        }\n    }\n    Ok(())\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\follow\\watch.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n#[cfg(unix)]\npub use self::unix::{\n    Pid,\n    ProcessChecker,\n    //stdin_is_bad_fd, stdin_is_pipe_or_fifo, supports_pid_checks, Pid, ProcessChecker,\n    supports_pid_checks,\n};\n#[cfg(windows)]\npub use self::windows::{Pid, ProcessChecker, supports_pid_checks};\n#[cfg(unix)]\nmod unix;\n#[cfg(windows)]\nmod windows;",
      "file_name": "coreutils/src/uu\\tail\\src\\platform\\mod.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (ToDO) stdlib, ISCHR, GETFD\n// spell-checker:ignore (options) EPERM, ENOSYS\nuse std::io::Error;\npub type Pid = libc::pid_t;\npub struct ProcessChecker {\n    pid: Pid,\n}\nimpl ProcessChecker {\n    pub fn new(process_id: Pid) -> Self {\n        Self { pid: process_id }\n    }\n\n    // Borrowing mutably to be aligned with Windows implementation\n    #[allow(clippy::wrong_self_convention)]\n    pub fn is_dead(&mut self) -> bool {\n        unsafe { libc::kill(self.pid, 0) != 0 && get_errno() != libc::EPERM }\n    }\n}\nimpl Drop for ProcessChecker {\n    fn drop(&mut self) {}\n}\npub fn supports_pid_checks(pid: Pid) -> bool {\n    unsafe { !(libc::kill(pid, 0) != 0 && get_errno() == libc::ENOSYS) }\n}\n#[inline]\nfn get_errno() -> i32 {\n    Error::last_os_error().raw_os_error().unwrap()\n}\n//pub fn stdin_is_bad_fd() -> bool {\n// FIXME: Detect a closed file descriptor, e.g.: `tail <&-`\n// this is never `true`, even with `<&-` because Rust's stdlib is reopening fds as /dev/null\n// see also: https://github.com/uutils/coreutils/issues/2873\n// (gnu/tests/tail-2/follow-stdin.sh fails because of this)\n// unsafe { libc::fcntl(fd, libc::F_GETFD) == -1 && get_errno() == libc::EBADF }\n//false\n//}",
      "file_name": "coreutils/src/uu\\tail\\src\\platform\\unix.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\nuse windows_sys::Win32::Foundation::{BOOL, CloseHandle, HANDLE, WAIT_FAILED, WAIT_OBJECT_0};\nuse windows_sys::Win32::System::Threading::{\n    OpenProcess, PROCESS_SYNCHRONIZE, WaitForSingleObject,\n};\npub type Pid = u32;\npub struct ProcessChecker {\n    dead: bool,\n    handle: HANDLE,\n}\nimpl ProcessChecker {\n    pub fn new(process_id: Pid) -> Self {\n        #[allow(non_snake_case)]\n        let FALSE: BOOL = 0;\n        let h = unsafe { OpenProcess(PROCESS_SYNCHRONIZE, FALSE, process_id) };\n        Self {\n            dead: h.is_null(),\n            handle: h,\n        }\n    }\n\n    #[allow(clippy::wrong_self_convention)]\n    pub fn is_dead(&mut self) -> bool {\n        if !self.dead {\n            self.dead = unsafe {\n                let status = WaitForSingleObject(self.handle, 0);\n                status == WAIT_OBJECT_0 || status == WAIT_FAILED\n            }\n        }\n\n        self.dead\n    }\n}\nimpl Drop for ProcessChecker {\n    fn drop(&mut self) {\n        unsafe {\n            CloseHandle(self.handle);\n        }\n    }\n}\npub fn supports_pid_checks(_pid: Pid) -> bool {\n    true\n}",
      "file_name": "coreutils/src/uu\\tail\\src\\platform\\windows.rs"
    }
  ],
  "truncate": [
    {
      "chunk": "uucore::bin!(uu_truncate);",
      "file_name": "coreutils/src/uu\\truncate\\src\\main.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore (ToDO) RFILE refsize rfilename fsize tsize\nuse clap::{Arg, ArgAction, Command};\nuse std::fs::{OpenOptions, metadata};\nuse std::io::ErrorKind;\n#[cfg(unix)]\nuse std::os::unix::fs::FileTypeExt;\nuse std::path::Path;\nuse uucore::display::Quotable;\nuse uucore::error::{FromIo, UResult, USimpleError, UUsageError};\nuse uucore::parser::parse_size::{ParseSizeError, parse_size_u64};\nuse uucore::{format_usage, help_about, help_section, help_usage};\n#[derive(Debug, Eq, PartialEq)]\nenum TruncateMode {\n    Absolute(u64),\n    Extend(u64),\n    Reduce(u64),\n    AtMost(u64),\n    AtLeast(u64),\n    RoundDown(u64),\n    RoundUp(u64),\n}\nimpl TruncateMode {\n    /// Compute a target size in bytes for this truncate mode.\n    ///\n    /// `fsize` is the size of the reference file, in bytes.\n    ///\n    /// If the mode is [`TruncateMode::Reduce`] and the value to\n    /// reduce by is greater than `fsize`, then this function returns\n    /// 0 (since it cannot return a negative number).\n    ///\n    /// # Examples\n    ///\n    /// Extending a file of 10 bytes by 5 bytes:\n    ///\n    /// ```rust,ignore\n    /// let mode = TruncateMode::Extend(5);\n    /// let fsize = 10;\n    /// assert_eq!(mode.to_size(fsize), 15);\n    /// ```\n    ///\n    /// Reducing a file by more than its size results in 0:\n    ///\n    /// ```rust,ignore\n    /// let mode = TruncateMode::Reduce(5);\n    /// let fsize = 3;\n    /// assert_eq!(mode.to_size(fsize), 0);\n    /// ```\n    fn to_size(&self, fsize: u64) -> u64 {\n        match self {\n            Self::Absolute(size) => *size,\n            Self::Extend(size) => fsize + size,\n            Self::Reduce(size) => {\n                if *size > fsize {\n                    0\n                } else {\n                    fsize - size\n                }\n            }\n            Self::AtMost(size) => fsize.min(*size),\n            Self::AtLeast(size) => fsize.max(*size),\n            Self::RoundDown(size) => fsize - fsize % size,\n            Self::RoundUp(size) => fsize + fsize % size,\n        }\n    }\n}\nconst ABOUT: &str = help_about!(\"truncate.md\");\nconst AFTER_HELP: &str = help_section!(\"after help\", \"truncate.md\");\nconst USAGE: &str = help_usage!(\"truncate.md\");\npub mod options {\n    pub static IO_BLOCKS: &str = \"io-blocks\";\n    pub static NO_CREATE: &str = \"no-create\";\n    pub static REFERENCE: &str = \"reference\";\n    pub static SIZE: &str = \"size\";\n    pub static ARG_FILES: &str = \"files\";\n}\n#[uucore::main]\npub fn uumain(args: impl uucore::Args) -> UResult<()> {\n    let matches = uu_app()\n        .after_help(AFTER_HELP)\n        .try_get_matches_from(args)\n        .map_err(|e| {\n            e.print().expect(\"Error writing clap::Error\");\n            match e.kind() {\n                clap::error::ErrorKind::DisplayHelp | clap::error::ErrorKind::DisplayVersion => 0,\n                _ => 1,\n            }\n        })?;\n\n    let files: Vec<String> = matches\n        .get_many::<String>(options::ARG_FILES)\n        .map(|v| v.map(ToString::to_string).collect())\n        .unwrap_or_default();\n\n    if files.is_empty() {\n        Err(UUsageError::new(1, \"missing file operand\"))\n    } else {\n        let io_blocks = matches.get_flag(options::IO_BLOCKS);\n        let no_create = matches.get_flag(options::NO_CREATE);\n        let reference = matches\n            .get_one::<String>(options::REFERENCE)\n            .map(String::from);\n        let size = matches.get_one::<String>(options::SIZE).map(String::from);\n        truncate(no_create, io_blocks, reference, size, &files)\n    }\n}\npub fn uu_app() -> Command {\n    Command::new(uucore::util_name())\n        .version(uucore::crate_version!())\n        .about(ABOUT)\n        .override_usage(format_usage(USAGE))\n        .infer_long_args(true)\n        .arg(\n            Arg::new(options::IO_BLOCKS)\n                .short('o')\n                .long(options::IO_BLOCKS)\n                .help(\n                    \"treat SIZE as the number of I/O blocks of the file rather than bytes \\\n            (NOT IMPLEMENTED)\",\n                )\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::NO_CREATE)\n                .short('c')\n                .long(options::NO_CREATE)\n                .help(\"do not create files that do not exist\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::REFERENCE)\n                .short('r')\n                .long(options::REFERENCE)\n                .required_unless_present(options::SIZE)\n                .help(\"base the size of each file on the size of RFILE\")\n                .value_name(\"RFILE\")\n                .value_hint(clap::ValueHint::FilePath),\n        )\n        .arg(\n            Arg::new(options::SIZE)\n                .short('s')\n                .long(options::SIZE)\n                .required_unless_present(options::REFERENCE)\n                .help(\n                    \"set or adjust the size of each file according to SIZE, which is in \\\n            bytes unless --io-blocks is specified\",\n                )\n                .value_name(\"SIZE\"),\n        )\n        .arg(\n            Arg::new(options::ARG_FILES)\n                .value_name(\"FILE\")\n                .action(ArgAction::Append)\n                .required(true)\n                .value_hint(clap::ValueHint::FilePath),\n        )\n}\n/// Truncate the named file to the specified size.\n///\n/// If `create` is true, then the file will be created if it does not\n/// already exist. If `size` is larger than the number of bytes in the\n/// file, then the file will be padded with zeros. If `size` is smaller\n/// than the number of bytes in the file, then the file will be\n/// truncated and any bytes beyond `size` will be lost.\n///\n/// # Errors\n///\n/// If the file could not be opened, or there was a problem setting the\n/// size of the file.\nfn file_truncate(filename: &str, create: bool, size: u64) -> UResult<()> {\n    #[cfg(unix)]\n    if let Ok(metadata) = metadata(filename) {\n        if metadata.file_type().is_fifo() {\n            return Err(USimpleError::new(\n                1,\n                format!(\n                    \"cannot open {} for writing: No such device or address\",\n                    filename.quote()\n                ),\n            ));\n        }\n    }\n    let path = Path::new(filename);\n    match OpenOptions::new().write(true).create(create).open(path) {\n        Ok(file) => file.set_len(size),\n        Err(e) if e.kind() == ErrorKind::NotFound && !create => Ok(()),\n        Err(e) => Err(e),\n    }\n    .map_err_context(|| format!(\"cannot open {} for writing\", filename.quote()))\n}\n/// Truncate files to a size relative to a given file.\n///\n/// `rfilename` is the name of the reference file.\n///\n/// `size_string` gives the size relative to the reference file to which\n/// to set the target files. For example, \"+3K\" means \"set each file to\n/// be three kilobytes larger than the size of the reference file\".\n///\n/// If `create` is true, then each file will be created if it does not\n/// already exist.\n///\n/// # Errors\n///\n/// If any file could not be opened, or there was a problem setting\n/// the size of at least one file.\n///\n/// If at least one file is a named pipe (also known as a fifo).\nfn truncate_reference_and_size(\n    rfilename: &str,\n    size_string: &str,\n    filenames: &[String],\n    create: bool,\n) -> UResult<()> {\n    let mode = match parse_mode_and_size(size_string) {\n        Err(e) => return Err(USimpleError::new(1, format!(\"Invalid number: {e}\"))),\n        Ok(TruncateMode::Absolute(_)) => {\n            return Err(USimpleError::new(\n                1,\n                String::from(\"you must specify a relative '--size' with '--reference'\"),\n            ));\n        }\n        Ok(m) => m,\n    };\n    if let TruncateMode::RoundDown(0) | TruncateMode::RoundUp(0) = mode {\n        return Err(USimpleError::new(1, \"division by zero\"));\n    }\n    let metadata = metadata(rfilename).map_err(|e| match e.kind() {\n        ErrorKind::NotFound => USimpleError::new(\n            1,\n            format!(\n                \"cannot stat {}: No such file or directory\",\n                rfilename.quote()\n            ),\n        ),\n        _ => e.map_err_context(String::new),\n    })?;\n    let fsize = metadata.len();\n    let tsize = mode.to_size(fsize);\n    for filename in filenames {\n        file_truncate(filename, create, tsize)?;\n    }\n    Ok(())\n}\n/// Truncate files to match the size of a given reference file.\n///\n/// `rfilename` is the name of the reference file.\n///\n/// If `create` is true, then each file will be created if it does not\n/// already exist.\n///\n/// # Errors\n///\n/// If any file could not be opened, or there was a problem setting\n/// the size of at least one file.\n///\n/// If at least one file is a named pipe (also known as a fifo).\nfn truncate_reference_file_only(\n    rfilename: &str,\n    filenames: &[String],\n    create: bool,\n) -> UResult<()> {\n    let metadata = metadata(rfilename).map_err(|e| match e.kind() {\n        ErrorKind::NotFound => USimpleError::new(\n            1,\n            format!(\n                \"cannot stat {}: No such file or directory\",\n                rfilename.quote()\n            ),\n        ),\n        _ => e.map_err_context(String::new),\n    })?;\n    let tsize = metadata.len();\n    for filename in filenames {\n        file_truncate(filename, create, tsize)?;\n    }\n    Ok(())\n}\n/// Truncate files to a specified size.\n///\n/// `size_string` gives either an absolute size or a relative size. A\n/// relative size adjusts the size of each file relative to its current\n/// size. For example, \"3K\" means \"set each file to be three kilobytes\"\n/// whereas \"+3K\" means \"set each file to be three kilobytes larger than\n/// its current size\".\n///\n/// If `create` is true, then each file will be created if it does not\n/// already exist.\n///\n/// # Errors\n///\n/// If any file could not be opened, or there was a problem setting\n/// the size of at least one file.\n///\n/// If at least one file is a named pipe (also known as a fifo).",
      "file_name": "coreutils/src/uu\\truncate\\src\\truncate.rs"
    },
    {
      "chunk": "fn truncate_size_only(size_string: &str, filenames: &[String], create: bool) -> UResult<()> {\n    let mode = parse_mode_and_size(size_string)\n        .map_err(|e| USimpleError::new(1, format!(\"Invalid number: {e}\")))?;\n    if let TruncateMode::RoundDown(0) | TruncateMode::RoundUp(0) = mode {\n        return Err(USimpleError::new(1, \"division by zero\"));\n    }\n    for filename in filenames {\n        let fsize = match metadata(filename) {\n            Ok(m) => {\n                #[cfg(unix)]\n                if m.file_type().is_fifo() {\n                    return Err(USimpleError::new(\n                        1,\n                        format!(\n                            \"cannot open {} for writing: No such device or address\",\n                            filename.quote()\n                        ),\n                    ));\n                }\n                m.len()\n            }\n            Err(_) => 0,\n        };\n        let tsize = mode.to_size(fsize);\n        // TODO: Fix duplicate call to stat\n        file_truncate(filename, create, tsize)?;\n    }\n    Ok(())\n}\nfn truncate(\n    no_create: bool,\n    _: bool,\n    reference: Option<String>,\n    size: Option<String>,\n    filenames: &[String],\n) -> UResult<()> {\n    let create = !no_create;\n    // There are four possibilities\n    // - reference file given and size given,\n    // - reference file given but no size given,\n    // - no reference file given but size given,\n    // - no reference file given and no size given,\n    match (reference, size) {\n        (Some(rfilename), Some(size_string)) => {\n            truncate_reference_and_size(&rfilename, &size_string, filenames, create)\n        }\n        (Some(rfilename), None) => truncate_reference_file_only(&rfilename, filenames, create),\n        (None, Some(size_string)) => truncate_size_only(&size_string, filenames, create),\n        (None, None) => unreachable!(), // this case cannot happen anymore because it's handled by clap\n    }\n}\n/// Decide whether a character is one of the size modifiers, like '+' or '<'.\nfn is_modifier(c: char) -> bool {\n    c == '+' || c == '-' || c == '<' || c == '>' || c == '/' || c == '%'\n}\n/// Parse a size string with optional modifier symbol as its first character.\n///\n/// A size string is as described in [`parse_size_u64`]. The first character\n/// of `size_string` might be a modifier symbol, like `'+'` or\n/// `'<'`. The first element of the pair returned by this function\n/// indicates which modifier symbol was present, or\n/// [`TruncateMode::Absolute`] if none.\n///\n/// # Panics\n///\n/// If `size_string` is empty, or if no number could be parsed from the\n/// given string (for example, if the string were `\"abc\"`).\n///\n/// # Examples\n///\n/// ```rust,ignore\n/// assert_eq!(parse_mode_and_size(\"+123\"), (TruncateMode::Extend, 123));\n/// ```\nfn parse_mode_and_size(size_string: &str) -> Result<TruncateMode, ParseSizeError> {\n    // Trim any whitespace.\n    let mut size_string = size_string.trim();\n\n    // Get the modifier character from the size string, if any. For\n    // example, if the argument is \"+123\", then the modifier is '+'.\n    if let Some(c) = size_string.chars().next() {\n        if is_modifier(c) {\n            size_string = &size_string[1..];\n        }\n        parse_size_u64(size_string).map(match c {\n            '+' => TruncateMode::Extend,\n            '-' => TruncateMode::Reduce,\n            '<' => TruncateMode::AtMost,\n            '>' => TruncateMode::AtLeast,\n            '/' => TruncateMode::RoundDown,\n            '%' => TruncateMode::RoundUp,\n            _ => TruncateMode::Absolute,\n        })\n    } else {\n        Err(ParseSizeError::ParseFailure(size_string.to_string()))\n    }\n}\n#[cfg(test)]\nmod tests {\n    use crate::TruncateMode;\n    use crate::parse_mode_and_size;\n\n    #[test]\n    fn test_parse_mode_and_size() {\n        assert_eq!(parse_mode_and_size(\"10\"), Ok(TruncateMode::Absolute(10)));\n        assert_eq!(parse_mode_and_size(\"+10\"), Ok(TruncateMode::Extend(10)));\n        assert_eq!(parse_mode_and_size(\"-10\"), Ok(TruncateMode::Reduce(10)));\n        assert_eq!(parse_mode_and_size(\"<10\"), Ok(TruncateMode::AtMost(10)));\n        assert_eq!(parse_mode_and_size(\">10\"), Ok(TruncateMode::AtLeast(10)));\n        assert_eq!(parse_mode_and_size(\"/10\"), Ok(TruncateMode::RoundDown(10)));\n        assert_eq!(parse_mode_and_size(\"%10\"), Ok(TruncateMode::RoundUp(10)));\n    }\n\n    #[test]\n    fn test_to_size() {\n        assert_eq!(TruncateMode::Extend(5).to_size(10), 15);\n        assert_eq!(TruncateMode::Reduce(5).to_size(10), 5);\n        assert_eq!(TruncateMode::Reduce(5).to_size(3), 0);\n    }\n}",
      "file_name": "coreutils/src/uu\\truncate\\src\\truncate.rs"
    }
  ],
  "uniq": [
    {
      "chunk": "uucore::bin!(uu_uniq);",
      "file_name": "coreutils/src/uu\\uniq\\src\\main.rs"
    },
    {
      "chunk": "// This file is part of the uutils coreutils package.\n//\n// For the full copyright and license information, please view the LICENSE\n// file that was distributed with this source code.\n// spell-checker:ignore badoption\nuse clap::{\n    Arg, ArgAction, ArgMatches, Command, builder::ValueParser, error::ContextKind, error::Error,\n    error::ErrorKind,\n};\nuse std::ffi::{OsStr, OsString};\nuse std::fs::File;\nuse std::io::{BufRead, BufReader, BufWriter, Write, stdin, stdout};\nuse std::num::IntErrorKind;\nuse uucore::display::Quotable;\nuse uucore::error::{FromIo, UError, UResult, USimpleError};\nuse uucore::parser::shortcut_value_parser::ShortcutValueParser;\nuse uucore::posix::{OBSOLETE, posix_version};\nuse uucore::{format_usage, help_about, help_section, help_usage};\nconst ABOUT: &str = help_about!(\"uniq.md\");\nconst USAGE: &str = help_usage!(\"uniq.md\");\nconst AFTER_HELP: &str = help_section!(\"after help\", \"uniq.md\");\npub mod options {\n    pub static ALL_REPEATED: &str = \"all-repeated\";\n    pub static CHECK_CHARS: &str = \"check-chars\";\n    pub static COUNT: &str = \"count\";\n    pub static IGNORE_CASE: &str = \"ignore-case\";\n    pub static REPEATED: &str = \"repeated\";\n    pub static SKIP_FIELDS: &str = \"skip-fields\";\n    pub static SKIP_CHARS: &str = \"skip-chars\";\n    pub static UNIQUE: &str = \"unique\";\n    pub static ZERO_TERMINATED: &str = \"zero-terminated\";\n    pub static GROUP: &str = \"group\";\n}\nstatic ARG_FILES: &str = \"files\";\n#[derive(PartialEq, Clone, Copy)]\nenum Delimiters {\n    Append,\n    Prepend,\n    Separate,\n    Both,\n    None,\n}\nstruct Uniq {\n    repeats_only: bool,\n    uniques_only: bool,\n    all_repeated: bool,\n    delimiters: Delimiters,\n    show_counts: bool,\n    skip_fields: Option<usize>,\n    slice_start: Option<usize>,\n    slice_stop: Option<usize>,\n    ignore_case: bool,\n    zero_terminated: bool,\n}\nmacro_rules! write_line_terminator {\n    ($writer:expr, $line_terminator:expr) => {\n        $writer\n            .write_all(&[$line_terminator])\n            .map_err_context(|| \"Could not write line terminator\".to_string())\n    };\n}\nimpl Uniq {\n    pub fn print_uniq(&self, reader: impl BufRead, mut writer: impl Write) -> UResult<()> {\n        let mut first_line_printed = false;\n        let mut group_count = 1;\n        let line_terminator = self.get_line_terminator();\n        let mut lines = reader.split(line_terminator);\n        let mut line = match lines.next() {\n            Some(l) => l?,\n            None => return Ok(()),\n        };\n\n        let writer = &mut writer;\n\n        // compare current `line` with consecutive lines (`next_line`) of the input\n        // and if needed, print `line` based on the command line options provided\n        for next_line in lines {\n            let next_line = next_line?;\n            if self.cmp_keys(&line, &next_line) {\n                if (group_count == 1 && !self.repeats_only)\n                    || (group_count > 1 && !self.uniques_only)\n                {\n                    self.print_line(writer, &line, group_count, first_line_printed)?;\n                    first_line_printed = true;\n                }\n                line = next_line;\n                group_count = 1;\n            } else {\n                if self.all_repeated {\n                    self.print_line(writer, &line, group_count, first_line_printed)?;\n                    first_line_printed = true;\n                    line = next_line;\n                }\n                group_count += 1;\n            }\n        }\n        if (group_count == 1 && !self.repeats_only) || (group_count > 1 && !self.uniques_only) {\n            self.print_line(writer, &line, group_count, first_line_printed)?;\n            first_line_printed = true;\n        }\n        if (self.delimiters == Delimiters::Append || self.delimiters == Delimiters::Both)\n            && first_line_printed\n        {\n            write_line_terminator!(writer, line_terminator)?;\n        }\n        writer.flush().map_err_context(|| \"write error\".into())?;\n        Ok(())\n    }\n\n    fn skip_fields(&self, line: &[u8]) -> Vec<u8> {\n        if let Some(skip_fields) = self.skip_fields {\n            let mut line = line.iter();\n            let mut line_after_skipped_field: Vec<u8>;\n            for _ in 0..skip_fields {\n                if line.all(|u| u.is_ascii_whitespace()) {\n                    return Vec::new();\n                }\n                line_after_skipped_field = line\n                    .by_ref()\n                    .skip_while(|u| !u.is_ascii_whitespace())\n                    .copied()\n                    .collect::<Vec<u8>>();\n\n                if line_after_skipped_field.is_empty() {\n                    return Vec::new();\n                }\n                line = line_after_skipped_field.iter();\n            }\n            line.copied().collect::<Vec<u8>>()\n        } else {\n            line.to_vec()\n        }\n    }\n\n    fn get_line_terminator(&self) -> u8 {\n        if self.zero_terminated { 0 } else { b'\\n' }\n    }\n\n    fn cmp_keys(&self, first: &[u8], second: &[u8]) -> bool {\n        self.cmp_key(first, |first_iter| {\n            self.cmp_key(second, |second_iter| first_iter.ne(second_iter))\n        })\n    }\n\n    fn cmp_key<F>(&self, line: &[u8], mut closure: F) -> bool\n    where\n        F: FnMut(&mut dyn Iterator<Item = char>) -> bool,\n    {\n        let fields_to_check = self.skip_fields(line);\n\n        // Skip self.slice_start bytes (if -s was used).\n        // self.slice_start is how many characters to skip, but historically\n        // uniq\u2019s `-s N` means \u201cskip N *bytes*,\u201d so do that literally:\n        let skip_bytes = self.slice_start.unwrap_or(0);\n        let fields_to_check = if skip_bytes < fields_to_check.len() {\n            &fields_to_check[skip_bytes..]\n        } else {\n            // If skipping beyond end-of-line, leftover is empty => effectively \"\"\n            &[]\n        };\n\n        // Convert the leftover bytes to UTF-8 for character-based -w\n        // If invalid UTF-8, just compare them as individual bytes (fallback).\n        let Ok(string_after_skip) = std::str::from_utf8(fields_to_check) else {\n            // Fallback: if invalid UTF-8, treat them as single-byte \u201cchars\u201d\n            return closure(&mut fields_to_check.iter().map(|&b| b as char));\n        };\n\n        let total_chars = string_after_skip.chars().count();\n\n        // `-w N` => Compare no more than N characters\n        let slice_stop = self.slice_stop.unwrap_or(total_chars);\n        let slice_start = slice_stop.min(total_chars);\n\n        let mut iter = string_after_skip.chars().take(slice_start);\n\n        if self.ignore_case {\n            // We can do ASCII-lowercase or full Unicode-lowercase. For minimal changes, do ASCII:\n            closure(&mut iter.map(|c| c.to_ascii_lowercase()))\n        }\nelse {\n            closure(&mut iter)\n        }\n    }\nfn should_print_delimiter(&self, group_count: usize, first_line_printed: bool) -> bool {\n        // if no delimiter option is selected then no other checks needed\n        self.delimiters != Delimiters::None\n            // print delimiter only before the first line of a group, not between lines of a group\n            && group_count == 1\n            // if at least one line has been output before current group then print delimiter\n            && (first_line_printed\n                // or if we need to prepend delimiter then print it even at the start of the output\n                || self.delimiters == Delimiters::Prepend\n                // the 'both' delimit mode should prepend and append delimiters\n                || self.delimiters == Delimiters::Both)\n    }\nfn print_line(\n        &self,\n        writer: &mut impl Write,\n        line: &[u8],\n        count: usize,\n        first_line_printed: bool,\n    ) -> UResult<()> {\n        let line_terminator = self.get_line_terminator();\n\n        if self.should_print_delimiter(count, first_line_printed) {\n            write_line_terminator!(writer, line_terminator)?;\n        }\n\n        if self.show_counts {\n            let prefix = format!(\"{count:7} \");\n            let out = prefix\n                .as_bytes()\n                .iter()\n                .chain(line.iter())\n                .copied()\n                .collect::<Vec<u8>>();\n            writer.write_all(out.as_slice())\n        } else {\n            writer.write_all(line)\n        }\n        .map_err_context(|| \"write error\".to_string())?;\n\n        write_line_terminator!(writer, line_terminator)\n    }\n}\nfn opt_parsed(opt_name: &str, matches: &ArgMatches) -> UResult<Option<usize>> {\n    match matches.get_one::<String>(opt_name) {\n        Some(arg_str) => match arg_str.parse::<usize>() {\n            Ok(v) => Ok(Some(v)),\n            Err(e) => match e.kind() {\n                IntErrorKind::PosOverflow => Ok(Some(usize::MAX)),\n                _ => Err(USimpleError::new(\n                    1,\n                    format!(\"Invalid argument for {opt_name}: {}\", arg_str.maybe_quote()),\n                )),\n            },\n        },\n        None => Ok(None),\n    }\n}\n/// Extract obsolete shorthands (if any) for skip fields and skip chars options\n/// following GNU `uniq` behavior\n///\n/// Examples for obsolete skip fields option\n/// `uniq -1 file` would equal `uniq -f1 file`\n/// `uniq -1 -2 -3 file` would equal `uniq -f123 file`\n/// `uniq -1 -2 -f5 file` would equal `uniq -f5 file`\n/// `uniq -u20s4 file` would equal `uniq -u -f20 -s4 file`\n/// `uniq -D1w3 -3 file` would equal `uniq -D -f3 -w3 file`\n///\n/// Examples for obsolete skip chars option\n/// `uniq +1 file` would equal `uniq -s1 file`\n/// `uniq +1 -s2 file` would equal `uniq -s2 file`\n/// `uniq -s2 +3 file` would equal `uniq -s3 file`\n///\nfn handle_obsolete(args: impl uucore::Args) -> (Vec<OsString>, Option<usize>, Option<usize>) {\n    let mut skip_fields_old = None;\n    let mut skip_chars_old = None;\n    let mut preceding_long_opt_req_value = false;\n    let mut preceding_short_opt_req_value = false;\n\n    let filtered_args = args\n        .filter_map(|os_slice| {\n            filter_args(\n                os_slice,\n                &mut skip_fields_old,\n                &mut skip_chars_old,\n                &mut preceding_long_opt_req_value,\n                &mut preceding_short_opt_req_value,\n            )\n        })\n        .collect();\n\n    // exacted String values (if any) for skip_fields_old and skip_chars_old\n    // are guaranteed to consist of ascii digit chars only at this point\n    // so, it is safe to parse into usize and collapse Result into Option\n    let skip_fields_old: Option<usize> = skip_fields_old.and_then(|v| v.parse::<usize>().ok());\n    let skip_chars_old: Option<usize> = skip_chars_old.and_then(|v| v.parse::<usize>().ok());\n\n    (filtered_args, skip_fields_old, skip_chars_old)\n}",
      "file_name": "coreutils/src/uu\\uniq\\src\\uniq.rs"
    },
    {
      "chunk": "fn filter_args(\n    os_slice: OsString,\n    skip_fields_old: &mut Option<String>,\n    skip_chars_old: &mut Option<String>,\n    preceding_long_opt_req_value: &mut bool,\n    preceding_short_opt_req_value: &mut bool,\n) -> Option<OsString> {\n    let filter: Option<OsString>;\n    if let Some(slice) = os_slice.to_str() {\n        if should_extract_obs_skip_fields(\n            slice,\n            preceding_long_opt_req_value,\n            preceding_short_opt_req_value,\n        ) {\n            // start of the short option string\n            // that can have obsolete skip fields option value in it\n            filter = handle_extract_obs_skip_fields(slice, skip_fields_old);\n        } else if should_extract_obs_skip_chars(\n            slice,\n            preceding_long_opt_req_value,\n            preceding_short_opt_req_value,\n        ) {\n            // the obsolete skip chars option\n            filter = handle_extract_obs_skip_chars(slice, skip_chars_old);\n        } else {\n            // either not a short option\n            // or a short option that cannot have obsolete lines value in it\n            filter = Some(OsString::from(slice));\n            // Check and reset to None obsolete values extracted so far\n            // if corresponding new/documented options are encountered next.\n            // NOTE: For skip fields - occurrences of corresponding new/documented options\n            // inside combined short options ike '-u20s4' or '-D1w3', etc\n            // are also covered in `handle_extract_obs_skip_fields()` function\n            if slice.starts_with(\"-f\") {\n                *skip_fields_old = None;\n            }\n            if slice.starts_with(\"-s\") {\n                *skip_chars_old = None;\n            }\n        }\n        handle_preceding_options(\n            slice,\n            preceding_long_opt_req_value,\n            preceding_short_opt_req_value,\n        );\n    } else {\n        // Cannot cleanly convert os_slice to UTF-8\n        // Do not process and return as-is\n        // This will cause failure later on, but we should not handle it here\n        // and let clap panic on invalid UTF-8 argument\n        filter = Some(os_slice);\n    }\n    filter\n}\n/// Helper function to [`filter_args`]\n/// Checks if the slice is a true short option (and not hyphen prefixed value of an option)\n/// and if so, a short option that can contain obsolete skip fields value\nfn should_extract_obs_skip_fields(\n    slice: &str,\n    preceding_long_opt_req_value: &bool,\n    preceding_short_opt_req_value: &bool,\n) -> bool {\n    slice.starts_with('-')\n        && !slice.starts_with(\"--\")\n        && !preceding_long_opt_req_value\n        && !preceding_short_opt_req_value\n        && !slice.starts_with(\"-s\")\n        && !slice.starts_with(\"-f\")\n        && !slice.starts_with(\"-w\")\n}\n/// Helper function to [`filter_args`]\n/// Checks if the slice is a true obsolete skip chars short option\nfn should_extract_obs_skip_chars(\n    slice: &str,\n    preceding_long_opt_req_value: &bool,\n    preceding_short_opt_req_value: &bool,\n) -> bool {\n    slice.starts_with('+')\n        && posix_version().is_some_and(|v| v <= OBSOLETE)\n        && !preceding_long_opt_req_value\n        && !preceding_short_opt_req_value\n        && slice.chars().nth(1).is_some_and(|c| c.is_ascii_digit())\n}\n/// Helper function to [`filter_args`]\n/// Captures if current slice is a preceding option\n/// that requires value\nfn handle_preceding_options(\n    slice: &str,\n    preceding_long_opt_req_value: &mut bool,\n    preceding_short_opt_req_value: &mut bool,\n) {\n    // capture if current slice is a preceding long option that requires value and does not use '=' to assign that value\n    // following slice should be treaded as value for this option\n    // even if it starts with '-' (which would be treated as hyphen prefixed value)\n    if slice.starts_with(\"--\") {\n        use options as O;\n        *preceding_long_opt_req_value = &slice[2..] == O::SKIP_CHARS\n            || &slice[2..] == O::SKIP_FIELDS\n            || &slice[2..] == O::CHECK_CHARS\n            || &slice[2..] == O::GROUP\n            || &slice[2..] == O::ALL_REPEATED;\n    }\n    // capture if current slice is a preceding short option that requires value and does not have value in the same slice (value separated by whitespace)\n    // following slice should be treaded as value for this option\n    // even if it starts with '-' (which would be treated as hyphen prefixed value)\n    *preceding_short_opt_req_value = slice == \"-s\" || slice == \"-f\" || slice == \"-w\";\n    // slice is a value\n    // reset preceding option flags\n    if !slice.starts_with('-') {\n        *preceding_short_opt_req_value = false;\n        *preceding_long_opt_req_value = false;\n    }\n}\n/// Helper function to [`filter_args`]\n/// Extracts obsolete skip fields numeric part from argument slice\n/// and filters it out\nfn handle_extract_obs_skip_fields(\n    slice: &str,\n    skip_fields_old: &mut Option<String>,\n) -> Option<OsString> {\n    let mut obs_extracted: Vec<char> = vec![];\n    let mut obs_end_reached = false;\n    let mut obs_overwritten_by_new = false;\n    let filtered_slice: Vec<char> = slice\n        .chars()\n        .filter(|c| {\n            if c.eq(&'f') {\n                // any extracted obsolete skip fields value up to this point should be discarded\n                // as the new/documented option for skip fields was used after it\n                // i.e. in situation like `-u12f3`\n                // The obsolete skip fields value should still be extracted, filtered out\n                // but the skip_fields_old should be set to None instead of Some(String) later on\n                obs_overwritten_by_new = true;\n            }\n            // To correctly process scenario like '-u20s4' or '-D1w3', etc\n            // we need to stop extracting digits once alphabetic character is encountered\n            // after we already have something in obs_extracted\n            if c.is_ascii_digit() && !obs_end_reached {\n                obs_extracted.push(*c);\n                false\n            } else {\n                if !obs_extracted.is_empty() {\n                    obs_end_reached = true;\n                }\n                true\n            }\n        })\n        .collect();\n\n    if obs_extracted.is_empty() {\n        // no obsolete value found/extracted\n        Some(OsString::from(slice))\n    } else {\n        // obsolete value was extracted\n        // unless there was new/documented option for skip fields used after it\n        // set the skip_fields_old value (concatenate to it if there was a value there already)\n        if obs_overwritten_by_new {\n            *skip_fields_old = None;\n        } else {\n            let mut extracted: String = obs_extracted.iter().collect();\n            if let Some(val) = skip_fields_old {\n                extracted.push_str(val);\n            }\n            *skip_fields_old = Some(extracted);\n        }\n        if filtered_slice.get(1).is_some() {\n            // there were some short options in front of or after obsolete lines value\n            // i.e. '-u20s4' or '-D1w3' or similar, which after extraction of obsolete lines value\n            // would look like '-us4' or '-Dw3' or similar\n            let filtered_slice: String = filtered_slice.iter().collect();\n            Some(OsString::from(filtered_slice))\n        } else {\n            None\n        }\n    }\n}\n/// Helper function to [`filter_args`]\n/// Extracts obsolete skip chars numeric part from argument slice\nfn handle_extract_obs_skip_chars(\n    slice: &str,\n    skip_chars_old: &mut Option<String>,\n) -> Option<OsString> {\n    let mut obs_extracted: Vec<char> = vec![];\n    let mut slice_chars = slice.chars();\n    slice_chars.next(); // drop leading '+' character\n    for c in slice_chars {\n        if c.is_ascii_digit() {\n            obs_extracted.push(c);\n        } else {\n            // for obsolete skip chars option the whole value after '+' should be numeric\n            // so, if any non-digit characters are encountered in the slice (i.e. `+1q`, etc)\n            // set skip_chars_old to None and return whole slice back.\n            // It will be parsed by clap and panic with appropriate error message\n            *skip_chars_old = None;\n            return Some(OsString::from(slice));\n        }\n    }\n    if obs_extracted.is_empty() {\n        // no obsolete value found/extracted\n        // i.e. it was just '+' character alone\n        Some(OsString::from(slice))\n    } else {\n        // successfully extracted numeric value\n        // capture it and return None to filter out the whole slice\n        *skip_chars_old = Some(obs_extracted.iter().collect());\n        None\n    }\n}\n/// Maps Clap errors to USimpleError and overrides 3 specific ones\n/// to meet requirements of GNU tests for `uniq`.\n/// Unfortunately these overrides are necessary, since several GNU tests\n/// for `uniq` hardcode and require the exact wording of the error message\n/// and it is not compatible with how Clap formats and displays those error messages.\nfn map_clap_errors(clap_error: Error) -> Box<dyn UError> {\n    let footer = \"Try 'uniq --help' for more information.\";\n    let override_arg_conflict =\n        \"--group is mutually exclusive with -c/-d/-D/-u\\n\".to_string() + footer;\n    let override_group_badoption = \"invalid argument 'badoption' for '--group'\\nValid arguments are:\\n  - 'prepend'\\n  - 'append'\\n  - 'separate'\\n  - 'both'\\n\".to_string() + footer;\n    let override_all_repeated_badoption = \"invalid argument 'badoption' for '--all-repeated'\\nValid arguments are:\\n  - 'none'\\n  - 'prepend'\\n  - 'separate'\\n\".to_string() + footer;\n\n    let error_message = match clap_error.kind() {\n        ErrorKind::ArgumentConflict => override_arg_conflict,\n        ErrorKind::InvalidValue\n            if clap_error\n                .get(ContextKind::InvalidValue)\n                .is_some_and(|v| v.to_string() == \"badoption\")\n                && clap_error\n                    .get(ContextKind::InvalidArg)\n                    .is_some_and(|v| v.to_string().starts_with(\"--group\")) =>\n        {\n            override_group_badoption\n        }\n        ErrorKind::InvalidValue\n            if clap_error\n                .get(ContextKind::InvalidValue)\n                .is_some_and(|v| v.to_string() == \"badoption\")\n                && clap_error\n                    .get(ContextKind::InvalidArg)\n                    .is_some_and(|v| v.to_string().starts_with(\"--all-repeated\")) =>\n        {\n            override_all_repeated_badoption\n        }\n        _ => return clap_error.into(),\n    };\n    USimpleError::new(1, error_message)\n}\n#[uucore::main]\npub fn uumain(args: impl uucore::Args) -> UResult<()> {\n    let (args, skip_fields_old, skip_chars_old) = handle_obsolete(args);\n\n    let matches = uu_app()\n        .try_get_matches_from(args)\n        .map_err(map_clap_errors)?;\n\n    let files = matches.get_many::<OsString>(ARG_FILES);\n\n    let (in_file_name, out_file_name) = files\n        .map(|fi| fi.map(AsRef::as_ref))\n        .map(|mut fi| (fi.next(), fi.next()))\n        .unwrap_or_default();\n\n    let skip_fields_modern: Option<usize> = opt_parsed(options::SKIP_FIELDS, &matches)?;\n    let skip_chars_modern: Option<usize> = opt_parsed(options::SKIP_CHARS, &matches)?;\n\n    let uniq = Uniq {\n        repeats_only: matches.get_flag(options::REPEATED)\n            || matches.contains_id(options::ALL_REPEATED),\n        uniques_only: matches.get_flag(options::UNIQUE),\n        all_repeated: matches.contains_id(options::ALL_REPEATED)\n            || matches.contains_id(options::GROUP),\n        delimiters: get_delimiter(&matches),\n        show_counts: matches.get_flag(options::COUNT),\n        skip_fields: skip_fields_modern.or(skip_fields_old),\n        slice_start: skip_chars_modern.or(skip_chars_old),\n        slice_stop: opt_parsed(options::CHECK_CHARS, &matches)?,\n        ignore_case: matches.get_flag(options::IGNORE_CASE),\n        zero_terminated: matches.get_flag(options::ZERO_TERMINATED),\n    };\n\n    if uniq.show_counts && uniq.all_repeated {\n        return Err(USimpleError::new(\n            1,\n            \"printing all duplicated lines and repeat counts is meaningless\\nTry 'uniq --help' for more information.\",\n        ));\n    }\n\n    uniq.print_uniq(\n        open_input_file(in_file_name)?,\n        open_output_file(out_file_name)?,\n    )\n}",
      "file_name": "coreutils/src/uu\\uniq\\src\\uniq.rs"
    },
    {
      "chunk": "pub fn uu_app() -> Command {\n    Command::new(uucore::util_name())\n        .version(uucore::crate_version!())\n        .about(ABOUT)\n        .override_usage(format_usage(USAGE))\n        .infer_long_args(true)\n        .after_help(AFTER_HELP)\n        .arg(\n            Arg::new(options::ALL_REPEATED)\n                .short('D')\n                .long(options::ALL_REPEATED)\n                .value_parser(ShortcutValueParser::new([\n                    \"none\",\n                    \"prepend\",\n                    \"separate\"\n                ]))\n                .help(\"print all duplicate lines. Delimiting is done with blank lines. [default: none]\")\n                .value_name(\"delimit-method\")\n                .num_args(0..=1)\n                .default_missing_value(\"none\")\n                .require_equals(true),\n        )\n        .arg(\n            Arg::new(options::GROUP)\n                .long(options::GROUP)\n                .value_parser(ShortcutValueParser::new([\n                    \"separate\",\n                    \"prepend\",\n                    \"append\",\n                    \"both\",\n                ]))\n                .help(\"show all items, separating groups with an empty line. [default: separate]\")\n                .value_name(\"group-method\")\n                .num_args(0..=1)\n                .default_missing_value(\"separate\")\n                .require_equals(true)\n                .conflicts_with_all([\n                    options::REPEATED,\n                    options::ALL_REPEATED,\n                    options::UNIQUE,\n                    options::COUNT\n                ]),\n        )\n        .arg(\n            Arg::new(options::CHECK_CHARS)\n                .short('w')\n                .long(options::CHECK_CHARS)\n                .help(\"compare no more than N characters in lines\")\n                .value_name(\"N\"),\n        )\n        .arg(\n            Arg::new(options::COUNT)\n                .short('c')\n                .long(options::COUNT)\n                .help(\"prefix lines by the number of occurrences\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::IGNORE_CASE)\n                .short('i')\n                .long(options::IGNORE_CASE)\n                .help(\"ignore differences in case when comparing\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::REPEATED)\n                .short('d')\n                .long(options::REPEATED)\n                .help(\"only print duplicate lines\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::SKIP_CHARS)\n                .short('s')\n                .long(options::SKIP_CHARS)\n                .help(\"avoid comparing the first N characters\")\n                .value_name(\"N\"),\n        )\n        .arg(\n            Arg::new(options::SKIP_FIELDS)\n                .short('f')\n                .long(options::SKIP_FIELDS)\n                .help(\"avoid comparing the first N fields\")\n                .value_name(\"N\"),\n        )\n        .arg(\n            Arg::new(options::UNIQUE)\n                .short('u')\n                .long(options::UNIQUE)\n                .help(\"only print unique lines\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(options::ZERO_TERMINATED)\n                .short('z')\n                .long(options::ZERO_TERMINATED)\n                .help(\"end lines with 0 byte, not newline\")\n                .action(ArgAction::SetTrue),\n        )\n        .arg(\n            Arg::new(ARG_FILES)\n                .action(ArgAction::Append)\n                .value_parser(ValueParser::os_string())\n                .num_args(0..=2)\n                .hide(true)\n                .value_hint(clap::ValueHint::FilePath),\n        )\n}\nfn get_delimiter(matches: &ArgMatches) -> Delimiters {\n    let value = matches\n        .get_one::<String>(options::ALL_REPEATED)\n        .or_else(|| matches.get_one::<String>(options::GROUP));\n    if let Some(delimiter_arg) = value {\n        match delimiter_arg.as_ref() {\n            \"append\" => Delimiters::Append,\n            \"prepend\" => Delimiters::Prepend,\n            \"separate\" => Delimiters::Separate,\n            \"both\" => Delimiters::Both,\n            \"none\" => Delimiters::None,\n            _ => unreachable!(\"Should have been caught by possible values in clap\"),\n        }\n    } else if matches.contains_id(options::GROUP) {\n        Delimiters::Separate\n    } else {\n        Delimiters::None\n    }\n}\n// None or \"-\" means stdin.\nfn open_input_file(in_file_name: Option<&OsStr>) -> UResult<Box<dyn BufRead>> {\n    Ok(match in_file_name {\n        Some(path) if path != \"-\" => {\n            let in_file = File::open(path)\n                .map_err_context(|| format!(\"Could not open {}\", path.maybe_quote()))?;\n            Box::new(BufReader::new(in_file))\n        }\n        _ => Box::new(stdin().lock()),\n    })\n}\n// None or \"-\" means stdout.\nfn open_output_file(out_file_name: Option<&OsStr>) -> UResult<Box<dyn Write>> {\n    Ok(match out_file_name {\n        Some(path) if path != \"-\" => {\n            let out_file = File::create(path)\n                .map_err_context(|| format!(\"Could not open {}\", path.maybe_quote()))?;\n            Box::new(BufWriter::new(out_file))\n        }\n        _ => Box::new(stdout().lock()),\n    })\n}",
      "file_name": "coreutils/src/uu\\uniq\\src\\uniq.rs"
    }
  ]
}